{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SageMaker Training for Diffusion model\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API을 효과적으로 이용하기 위해 multigpu-distributed 학습을 위한 PyTorch 프레임워크 자체 구현만으로 모델 훈련을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.63.2)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.18.45)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.19.5)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.1.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.17.2)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (20.9)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (4.5.0)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (21.2.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: docker-compose>=1.25.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: urllib3!=1.25,!=1.25.1,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.26.5)\n",
      "Requirement already satisfied: docker==5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.0.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.25.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (0.58.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (1.21.45)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker[local]) (2.8.1)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.19.0)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.0)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: cached-property<2,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.2)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.7.2)\n",
      "Requirement already satisfied: six>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from dockerpty<1,>=0.4.1->docker-compose>=1.25.2->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.10.0.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (0.17.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker[local]) (2.4.7)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.4.7)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (2.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker[local]) (2021.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: bokeh in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.3.3)\n",
      "Requirement already satisfied: smdebug in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.0.12)\n",
      "Requirement already satisfied: sagemaker-experiments in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.1.35)\n",
      "Requirement already satisfied: gdown in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (3.10.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (3.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (8.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (1.19.5)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (5.4.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (20.9)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: pyinstrument==3.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (1.18.45)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (3.17.2)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyinstrument==3.4.2->smdebug) (0.2.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gdown) (4.61.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gdown) (4.9.3)\n",
      "Requirement already satisfied: requests[socks] in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.21.45)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.10.32->smdebug) (1.26.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from Jinja2>=2.9->bokeh) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=16.8->bokeh) (2.4.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from beautifulsoup4->gdown) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.63.2)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.9.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.10.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (20.9)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (4.5.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.18.45)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (3.17.2)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision) (8.3.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.21.45)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "nvidia-docker2 already installed. We are good to go!\n",
      "Stopping docker: \u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "Starting docker:\t.\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "#     !{sys.executable} -m pip install -U split-folders tqdm albumentations crc32c wget\n",
    "    !{sys.executable} -m pip install 'sagemaker[local]' --upgrade\n",
    "    !{sys.executable} -m pip install -U bokeh smdebug sagemaker-experiments gdown\n",
    "    !{sys.executable} -m pip install -U sagemaker torch torchvision\n",
    "    !/bin/bash ./local/local_mode_setup.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 설정\n",
    "\n",
    "<p>Sagemaker 학습에 필요한 기본적인 package를 import 합니다. </p>\n",
    "<p>boto3는 HTTP API 호출을 숨기는 편한 추상화 모델을 가지고 있고, Amazon EC2 인스턴스 및 S3 버켓과 같은 AWS 리소스와 동작하는 파이선 클래스를 제공합니다. </p>\n",
    "<p>sagemaker python sdk는 Amazon SageMaker에서 기계 학습 모델을 교육 및 배포하기 위한 오픈 소스 라이브러리입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "# import splitfolders\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "# import wget\n",
    "# import tarfile\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import strftime\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from sagemaker.debugger import (Rule,\n",
    "                                rule_configs,\n",
    "                                ProfilerConfig, \n",
    "                                FrameworkProfile, \n",
    "                                DetailedProfilingConfig, \n",
    "                                DataloaderProfilingConfig, \n",
    "                                PythonProfilingConfig)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.63.2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[\n",
    "                                              {\n",
    "                                                  'Key': 'multigpu',\n",
    "                                                  'Value': 'yes'\n",
    "                                              },\n",
    "                                              {\n",
    "                                                  'Key': 'multinode',\n",
    "                                                  'Value': 'yes'\n",
    "                                              },\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, set_param, i_type, i_cnt, spot):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    \n",
    "    if set_param['sagemakerdp']:\n",
    "        algo = 'sdp'\n",
    "#     elif set_param['sagemakermp']:\n",
    "#         algo = 'smp'\n",
    "    else:\n",
    "        algo = 'ds'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_tag = 'test'\n",
    "    if i_type == 'ml.p3.16xlarge':\n",
    "        i_tag = 'p3'\n",
    "    elif i_type == 'ml.p3dn.24xlarge':\n",
    "        i_tag = 'p3dn'\n",
    "    elif i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'    \n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'diffusion-sagemaker-211011'\n",
    "code_location = f's3://{bucket}/sm_codes'\n",
    "output_path = f's3://{bucket}/poc_diffusion/output/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "     {'Name': 'train:lr', 'Regex': 'lr - (.*?),'},\n",
    "     {'Name': 'train:Loss', 'Regex': 'loss -(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules=[ \n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'schedule_sampler' : 'uniform',\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    'lr_anneal_steps' : 11,\n",
    "    'batch_size' : 32,\n",
    "    'microbatch' : 4,\n",
    "    'ema_rate' : '0.9999',\n",
    "    'log_interval' : 5,\n",
    "    'save_interval' : 5,\n",
    "#     'resume_checkpoint' : \"/opt/ml/code/resume_ckt/model000100.pt\",\n",
    "    'use_fp16': False,\n",
    "    'fp16_scale_growth' : 1e-3,\n",
    "    'sagemakerdp' : False,\n",
    "    }\n",
    "\n",
    "# mp_parameters = {\n",
    "#         'num_microbatches': 16,\n",
    "#         'num_partitions' : 4,\n",
    "#         'placement_strategy': 'cluster', # cluster , spread\n",
    "#         'pipeline': 'interleaved',\n",
    "#         'optimize': 'speed',\n",
    "#         'memory_weight': 0.2,\n",
    "#         'ddp': True,\n",
    "# }\n",
    "\n",
    "experiment_name = 'diffusion-poc-exp1'\n",
    "instance_type = 'ml.p4d.24xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "instance_type = 'local_gpu'\n",
    "instance_count = 1\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 3*60*60\n",
    "\n",
    "\n",
    "# !gdown https://drive.google.com/uc?id=1vF8Ht0VThpobtmShD52_INhpIgy6eEXq\n",
    "# !gdown https://drive.google.com/uc?id=1kaIqFwTLD7Ml3ib9NQpjoUSD4FUD21-I\n",
    "\n",
    "# !rm -rf dataset\n",
    "# !mkdir dataset\n",
    "# !unzip birds.zip -d dataset/\n",
    "# !tar zxvf CUB_200_2011.tgz -C dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "    from pathlib import Path\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_data_path = 'file:///home/ec2-user/SageMaker/improved-diffusion-sagemaker/datasets/cifar10'\n",
    "    source_dir = f'{Path.cwd()}/scripts'\n",
    "    checkpoint_s3_bucket = None\n",
    "else:\n",
    "    sess = boto3.Session()\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sm = sess.client('sagemaker')\n",
    "    s3_data_path = 's3://dataset-us-west-2-cyj/cifar10'\n",
    "    source_dir = 'scripts'\n",
    "    checkpoint_s3_bucket = f's3://{bucket}/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_job_name : smp-dist \n",
      "train_instance_type : local_gpu \n",
      "train_instance_count : 1 \n",
      "image_uri : None \n",
      "distribution : {'mpi': {'enabled': True}}\n"
     ]
    }
   ],
   "source": [
    "image_uri = None\n",
    "distribution = None\n",
    "train_job_name = 'sagemaker'\n",
    "\n",
    "\n",
    "train_job_name = 'smp-dist'\n",
    "distribution = {}\n",
    "\n",
    "if hyperparameters['sagemakerdp']:\n",
    "    distribution[\"smdistributed\"]={ \n",
    "                        \"dataparallel\": {\n",
    "                            \"enabled\": True\n",
    "                        }\n",
    "                }\n",
    "\n",
    "# elif hyperparameters['sagemakermp']:\n",
    "#     distribution['smdistributed'] = { \"modelparallel\": {\n",
    "#                                               \"enabled\":True,\n",
    "#                                               \"parameters\": {\n",
    "#                                                   \"partitions\": mp_parameters['num_partitions'],\n",
    "#                                                   \"microbatches\": mp_parameters['num_microbatches'],\n",
    "#                                                   \"placement_strategy\": mp_parameters['placement_strategy'],\n",
    "#                                                   \"pipeline\": mp_parameters['pipeline'],\n",
    "#                                                   \"optimize\": mp_parameters['optimize'],\n",
    "#                                                   \"memory_weight\": mp_parameters['memory_weight'],\n",
    "#                                                   \"ddp\": mp_parameters['ddp'],\n",
    "#                                               }\n",
    "#                                           }\n",
    "#                                       }\n",
    "#     distribution[\"mpi\"]={\n",
    "#                         \"enabled\": True,\n",
    "#                         \"processes_per_host\": 8, # Pick your processes_per_host\n",
    "#                         \"custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa \" #  -x SMP_SKIP_GRAPH_VALIDATION=1\n",
    "#                   }\n",
    "\n",
    "else:\n",
    "    distribution[\"mpi\"]={\n",
    "                        \"enabled\": True,\n",
    "    #                     \"processes_per_host\": 8, # Pick your processes_per_host\n",
    "    #                     \"custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "                  }\n",
    "\n",
    "if do_spot_training:\n",
    "    max_wait = max_run\n",
    "\n",
    "print(\"train_job_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {} \\nimage_uri : {} \\ndistribution : {}\".format(train_job_name, instance_type, instance_count, image_uri, distribution))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri='322537213286.dkr.ecr.us-west-2.amazonaws.com/diffusion-sagemaker-smddp:smddp-1.2.2-pt-1.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='image_train.py',\n",
    "    source_dir=source_dir,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.9',\n",
    "    py_version='py38',\n",
    "#     image_uri=image_uri,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=256,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    metric_definitions=metric_definitions,\n",
    "#     rules=rules,\n",
    "    max_run=max_run,\n",
    "    use_spot_instances=do_spot_training,  # spot instance 활용\n",
    "    max_wait=max_wait,\n",
    "#     subnets=['subnet-02e36c042e58264e6'],   ## \tsubnet-05c77affac40aa7f3 (2b)  subnet-02e36c042e58264e6 (2c)\n",
    "#     security_group_ids=['sg-0bc738570daec9015'],\n",
    "    checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "    TrainingInputMode='File' ## FastFile\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lustre preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## https://docs.aws.amazon.com/fsx/latest/LustreGuide/preload-file-contents-hsm.html\n",
    "# # sudo lfs hsm_restore path/to/file\n",
    "# # sudo lfs hsm_action path/to/file\n",
    "# !find /home/ec2-user/SageMaker/dstaset-2a -type f -print0 | xargs -0 -n 1 sudo lfs hsm_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure FSx Input for your SageMaker Training job\n",
    "\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "file_system_directory_path= '/hlz2pbmv/BIRDS'  # '/5n6znbmv'    g4ljfbmv\n",
    " \n",
    "file_system_id='fs-0cd6d9b6c3c7f614e'  # fs-0849611d06d289065  063be12d6ca6d7862\n",
    "\n",
    "file_system_access_mode='rw'\n",
    "file_system_type='FSxLustre'\n",
    "train_fs = FileSystemInput(file_system_id=file_system_id,\n",
    "                                    file_system_type=file_system_type,\n",
    "                                    directory_path=file_system_directory_path,\n",
    "                                    file_system_access_mode=file_system_access_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    inputs = s3_data_path\n",
    "else:\n",
    "    inputs = train_fs\n",
    "    inputs = s3_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: diffusion-poc-exp1-test-1-ds-d-1020-13101634735424\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-vlez3:\n",
      "    command: train\n",
      "    container_name: j4ix5qnav9-algo-1-vlez3\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.9-gpu-py38\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-vlez3\n",
      "    runtime: nvidia\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpa6aamifo/algo-1-vlez3/input:/opt/ml/input\n",
      "    - /tmp/tmpa6aamifo/algo-1-vlez3/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpa6aamifo/algo-1-vlez3/output:/opt/ml/output\n",
      "    - /tmp/tmpa6aamifo/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/improved-diffusion-sagemaker/datasets/cifar10:/opt/ml/input/data/training\n",
      "    - /home/ec2-user/SageMaker/guided-diffusion-sagemaker/scripts:/opt/ml/code\n",
      "    - /tmp/tmpa6aamifo/shared:/opt/ml/shared\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpa6aamifo/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating j4ix5qnav9-algo-1-vlez3 ... \n",
      "Creating j4ix5qnav9-algo-1-vlez3 ... done\n",
      "Attaching to j4ix5qnav9-algo-1-vlez3\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:28,166 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:28,244 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:28,247 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:28,248 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m /opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Collecting blobfile\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Downloading blobfile-1.2.5-py3-none-any.whl (64 kB)\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Requirement already satisfied: urllib3~=1.25 in /opt/conda/lib/python3.8/site-packages (from blobfile->-r requirements.txt (line 1)) (1.26.6)\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Collecting xmltodict~=0.12.0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Collecting filelock~=3.0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Downloading filelock-3.3.1-py3-none-any.whl (9.7 kB)\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Collecting pycryptodomex~=3.8\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Downloading pycryptodomex-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Installing collected packages: xmltodict, pycryptodomex, filelock, blobfile\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Successfully installed blobfile-1.2.5 filelock-3.3.1 pycryptodomex-3.11.0 xmltodict-0.12.0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:31,182 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:31,182 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:31,184 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:31,185 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1-vlez3'] Hosts: ['algo-1-vlez3:8'] process_per_hosts: 8 num_processes: 8\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:31,186 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:10:31,262 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Training Env:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"sagemaker_mpi_enabled\": true,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"sagemaker_mpi_custom_mpi_options\": \"\"\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     },\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     },\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"current_host\": \"algo-1-vlez3\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"algo-1-vlez3\"\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     ],\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"schedule_sampler\": \"uniform\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"lr\": 0.0001,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"weight_decay\": 0.0,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"lr_anneal_steps\": 11,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"batch_size\": 32,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"microbatch\": 4,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"ema_rate\": \"0.9999\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"log_interval\": 5,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"save_interval\": 5,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"use_fp16\": false,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"fp16_scale_growth\": 0.001,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"sagemakerdp\": false\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     },\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"training\": {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         }\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     },\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"job_name\": \"diffusion-poc-exp1-test-1-ds-d-1020-13101634735424\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"master_hostname\": \"algo-1-vlez3\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"module_name\": \"image_train\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"current_host\": \"algo-1-vlez3\",\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m             \"algo-1-vlez3\"\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m         ]\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     },\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m     \"user_entry_point\": \"image_train.py\"\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m }\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Environment variables:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HOSTS=[\"algo-1-vlez3\"]\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HPS={\"batch_size\":32,\"ema_rate\":\"0.9999\",\"fp16_scale_growth\":0.001,\"log_interval\":5,\"lr\":0.0001,\"lr_anneal_steps\":11,\"microbatch\":4,\"sagemakerdp\":false,\"save_interval\":5,\"schedule_sampler\":\"uniform\",\"use_fp16\":false,\"weight_decay\":0.0}\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_USER_ENTRY_POINT=image_train.py\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-vlez3\",\"hosts\":[\"algo-1-vlez3\"]}\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_CURRENT_HOST=algo-1-vlez3\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_MODULE_NAME=image_train\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-vlez3\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-vlez3\"],\"hyperparameters\":{\"batch_size\":32,\"ema_rate\":\"0.9999\",\"fp16_scale_growth\":0.001,\"log_interval\":5,\"lr\":0.0001,\"lr_anneal_steps\":11,\"microbatch\":4,\"sagemakerdp\":false,\"save_interval\":5,\"schedule_sampler\":\"uniform\",\"use_fp16\":false,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp1-test-1-ds-d-1020-13101634735424\",\"log_level\":20,\"master_hostname\":\"algo-1-vlez3\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-vlez3\",\"hosts\":[\"algo-1-vlez3\"]},\"user_entry_point\":\"image_train.py\"}\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"32\",\"--ema_rate\",\"0.9999\",\"--fp16_scale_growth\",\"0.001\",\"--log_interval\",\"5\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"11\",\"--microbatch\",\"4\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"5\",\"--schedule_sampler\",\"uniform\",\"--use_fp16\",\"False\",\"--weight_decay\",\"0.0\"]\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_SCHEDULE_SAMPLER=uniform\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_LR=0.0001\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_WEIGHT_DECAY=0.0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_LR_ANNEAL_STEPS=11\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_BATCH_SIZE=32\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_MICROBATCH=4\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_EMA_RATE=0.9999\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_LOG_INTERVAL=5\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_SAVE_INTERVAL=5\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_USE_FP16=false\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_FP16_SCALE_GROWTH=0.001\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m SM_HP_SAGEMAKERDP=false\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m mpirun --host algo-1-vlez3:8 -np 8 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TRAINING -x SM_HP_SCHEDULE_SAMPLER -x SM_HP_LR -x SM_HP_WEIGHT_DECAY -x SM_HP_LR_ANNEAL_STEPS -x SM_HP_BATCH_SIZE -x SM_HP_MICROBATCH -x SM_HP_EMA_RATE -x SM_HP_LOG_INTERVAL -x SM_HP_SAVE_INTERVAL -x SM_HP_USE_FP16 -x SM_HP_FP16_SCALE_GROWTH -x SM_HP_SAGEMAKERDP -x PYTHONPATH /opt/conda/bin/python3.8 -m mpi4py image_train.py --batch_size 32 --ema_rate 0.9999 --fp16_scale_growth 0.001 --log_interval 5 --lr 0.0001 --lr_anneal_steps 11 --microbatch 4 --sagemakerdp False --save_interval 5 --schedule_sampler uniform --use_fp16 False --weight_decay 0.0\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m Data for JOB [45310,1] offset 0 Total slots allocated 8\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  ========================   JOB MAP   ========================\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  Data for node: algo-1-vlez3\tNum slots: 8\tMax slots: 0\tNum procs: 8\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 0 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 1 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 2 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 3 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 4 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 5 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 6 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  \tProcess OMPI jobid: [45310,1] App: 0 Process rank: 7 Bound: N/A\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m \n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m  =============================================================\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Logging to /tmp/openai-2021-10-20-13-10-36-442179\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:creating model and diffusion...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:creating data loader...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:training...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:36 [0] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:36 [0] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:36 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:36 [0] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:36 [0] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:NCCL version 2.7.8+cuda11.1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:40 [4] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:40 [4] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:38 [2] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:40 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:40 [4] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:40 [4] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:38 [2] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:38 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:38 [2] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:38 [2] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:37 [1] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:37 [1] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:37 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:37 [1] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:37 [1] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:41 [5] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:41 [5] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:41 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:41 [5] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:41 [5] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:39 [3] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:39 [3] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:39 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:39 [3] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:39 [3] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:42 [6] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:42 [6] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:42 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:42 [6] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:42 [6] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:43 [7] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:43 [7] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:43 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:43 [7] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:43 [7] NCCL INFO Using network Socket\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-vlez3:37:665 [1] NCCL INFO comm 0x7f6c08002e10 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:662 [0] NCCL INFO comm 0x7f8aa0002e10 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-vlez3:36:36 [0] NCCL INFO Launch mode Parallel\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-vlez3:38:664 [2] NCCL INFO comm 0x7f9978002e10 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-vlez3:39:667 [3] NCCL INFO comm 0x7fb434002e10 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-vlez3:40:663 [4] NCCL INFO comm 0x7f57c8002e10 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-vlez3:41:666 [5] NCCL INFO comm 0x7f2f34002e10 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-vlez3:42:668 [6] NCCL INFO comm 0x7f511c002e10 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-vlez3:43:669 [7] NCCL INFO comm 0x7f7888002e10 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2021-10-20 13:10:43.922 algo-1-vlez3:41 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2021-10-20 13:10:43.922 algo-1-vlez3:37 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2021-10-20 13:10:43.941 algo-1-vlez3:40 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2021-10-20 13:10:43.942 algo-1-vlez3:42 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2021-10-20 13:10:43.943 algo-1-vlez3:36 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2021-10-20 13:10:43.952 algo-1-vlez3:43 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2021-10-20 13:10:43.958 algo-1-vlez3:38 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2021-10-20 13:10:43.962 algo-1-vlez3:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2021-10-20 13:10:43.963 algo-1-vlez3:37 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2021-10-20 13:10:43.963 algo-1-vlez3:41 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2021-10-20 13:10:43.982 algo-1-vlez3:40 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2021-10-20 13:10:43.982 algo-1-vlez3:42 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2021-10-20 13:10:43.983 algo-1-vlez3:36 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2021-10-20 13:10:43.993 algo-1-vlez3:43 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2021-10-20 13:10:44.000 algo-1-vlez3:38 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2021-10-20 13:10:44.006 algo-1-vlez3:39 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [0][32] Train_Time=5.461, Train_Speed=46.882 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:-------------------------\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm  | 26       |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss       | 0.998    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0    | 0.999    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1    | 0.999    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2    | 0.996    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3    | 1        |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse        | 0.998    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0     | 0.999    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1     | 0.999    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2     | 0.996    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3     | 1        |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm | 196      |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples    | 256      |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step       | 0        |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:-------------------------\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:2,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:3,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:6,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:4,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:5,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:7,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:1,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [1][32] Train_Time=1.223, Train_Speed=209.401 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [2][32] Train_Time=1.135, Train_Speed=225.586 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [3][32] Train_Time=1.116, Train_Speed=229.317 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [4][32] Train_Time=1.117, Train_Speed=229.125 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [5][32] Train_Time=1.113, Train_Speed=230.095 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:-------------------------\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm  | 26.2     |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss       | 0.955    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0    | 0.968    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1    | 0.951    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2    | 0.949    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3    | 0.949    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse        | 0.955    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0     | 0.968    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1     | 0.951    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2     | 0.949    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3     | 0.949    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm | 196      |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples    | 1.54e+03 |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step       | 5        |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:-------------------------\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [6][32] Train_Time=1.105, Train_Speed=231.748 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [7][32] Train_Time=1.119, Train_Speed=228.679 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [8][32] Train_Time=1.116, Train_Speed=229.470 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [9][32] Train_Time=1.114, Train_Speed=229.736 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [10][32] Train_Time=1.109, Train_Speed=230.824 samples/sec,\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:-------------------------\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm  | 26.7     |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss       | 0.894    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0    | 0.909    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1    | 0.889    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2    | 0.89     |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3    | 0.889    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse        | 0.894    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0     | 0.909    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1     | 0.889    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2     | 0.89     |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3     | 0.889    |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm | 196      |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples    | 2.82e+03 |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step       | 10       |\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:-------------------------\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 |\u001b[0m 2021-10-20 13:11:11,383 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mj4ix5qnav9-algo-1-vlez3 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "CPU times: user 1min 15s, sys: 7.15 s, total: 1min 22s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, hyperparameters, instance_type, instance_count, do_spot_training)\n",
    "\n",
    "# Now associate the estimator with the Experiment and Trial\n",
    "estimator.fit(\n",
    "    inputs={'training': inputs}, \n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6fdef9500ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# job_name='dalle-poc-exp5-p4d-2-d-0530-12261622377580'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dalle-poc-exp4-p4d-2-d-0525-03071621912021 --> public\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dalle-poc-exp4-p4d-2-d-0525-03091621912148 --> another private\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# job_name='dalle-poc-exp1-p4d-1-sdp-d-1006-13111633525892'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "job_name=estimator.latest_training_job.name\n",
    "# job_name='dalle-poc-exp5-p4d-2-d-0530-12261622377580'\n",
    "# dalle-poc-exp4-p4d-2-d-0525-03071621912021 --> public\n",
    "# dalle-poc-exp4-p4d-2-d-0525-03091621912148 --> another private\n",
    "# job_name='dalle-poc-exp1-p4d-1-sdp-d-1006-13111633525892'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-20 03:36:05 Starting - Starting the training job..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2c73afeb3d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3675\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3677\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3679\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Amazon SageMaker Experiment Resources\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-cleanup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_boto3(experiment_name):\n",
    "    trials = sm.list_trials(ExperimentName=experiment_name)['TrialSummaries']\n",
    "    print('TrialNames:')\n",
    "    for trial in trials:\n",
    "        trial_name = trial['TrialName']\n",
    "        print(f\"\\n{trial_name}\")\n",
    "\n",
    "        components_in_trial = sm.list_trial_components(TrialName=trial_name)\n",
    "        print('\\tTrialComponentNames:')\n",
    "        for component in components_in_trial['TrialComponentSummaries']:\n",
    "            component_name = component['TrialComponentName']\n",
    "            print(f\"\\t{component_name}\")\n",
    "            sm.disassociate_trial_component(TrialComponentName=component_name, TrialName=trial_name)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                sm.delete_trial_component(TrialComponentName=component_name)\n",
    "            except:\n",
    "                # component is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(.5)\n",
    "        sm.delete_trial(TrialName=trial_name)\n",
    "    sm.delete_experiment(ExperimentName=experiment_name)\n",
    "    print(f\"\\nExperiment {experiment_name} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use experiment name not display name\n",
    "experiment_name = \"dalle-poc-exp4\"\n",
    "cleanup_boto3(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = '/home/ec2-user/SageMaker/lg-ai-research/dalle-sagemaker-dp-mp/test2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform1 = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.RandomResizedCrop(image_size,\n",
    "                        scale=(0.8, 1.),\n",
    "                        ratio=(1., 1.)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    array_img = io.imread(image_file)\n",
    "    image_tensor = image_transform1(array_img)\n",
    "except (PIL.UnidentifiedImageError, OSError, ValueError) as corrupt_image_exceptions:\n",
    "    print(f\"An exception occurred trying to load file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()\n",
    "plt.imshow(trans(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(image_file)\n",
    "rgb_im = im.convert('RGB')\n",
    "rgb_im.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = '/home/ec2-user/SageMaker/lg-ai-research/dalle-sagemaker-dp-mp/test.jpg'\n",
    "image_file = '/home/ec2-user/SageMaker/dataset/BIRDS/CUB_200_2011/images/029.American_Crow/American_Crow_0053_25203.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img = PIL.Image.open(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([\n",
    "    T.RandomResizedCrop(image_size,\n",
    "                        scale=(0.8, 1.),\n",
    "                        ratio=(1., 1.)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "#     piexif.remove(image_file)\n",
    "    array_img = PIL.Image.open(image_file)\n",
    "    array_img = array_img.convert('RGB')\n",
    "    \n",
    "    image_tensor = image_transform(array_img)\n",
    "except (PIL.UnidentifiedImageError, OSError, ValueError) as corrupt_image_exceptions:\n",
    "    print(f\"An exception occurred trying to load file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()\n",
    "plt.imshow(trans(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img.info.get(\"transparency\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if array_img.info.get(\"transparency\", None):\n",
    "    print(f\"[transparency] An exception occurred trying to load file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img = PIL.Image.open(image_file)\n",
    "            img = self.img_convert(array_img)\n",
    "        except (PIL.UnidentifiedImageError, OSError) as corrupt_image_exceptions:\n",
    "            print(f\"An exception occurred trying to load file {image_file}.\")\n",
    "            print(f\"Skipping index {ind}\")\n",
    "            return self.skip_sample(ind)\n",
    "\n",
    "        try:\n",
    "            if img.info.get(\"transparency\", None):"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
