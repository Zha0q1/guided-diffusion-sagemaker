{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SageMaker Training for Diffusion model\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API을 효과적으로 이용하기 위해 multigpu-distributed 학습을 위한 PyTorch 프레임워크 자체 구현만으로 모델 훈련을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.69.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (20.9)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.1.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.17.2)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (4.5.0)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.18.45)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (21.2.0)\n",
      "Requirement already satisfied: docker==5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25,!=1.25.1,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.26.5)\n",
      "Requirement already satisfied: docker-compose>=1.25.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.25.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (0.58.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (1.21.45)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker[local]) (2.8.1)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.0)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.19.0)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: cached-property<2,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.2)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.7.2)\n",
      "Requirement already satisfied: six>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from dockerpty<1,>=0.4.1->docker-compose>=1.25.2->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.10.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (0.17.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker[local]) (2.4.7)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.4.7)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (2.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker[local]) (2021.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: smdebug in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.0.12)\n",
      "Requirement already satisfied: sagemaker-experiments in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.1.35)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (3.17.2)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (1.18.45)\n",
      "Requirement already satisfied: pyinstrument==3.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (20.9)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyinstrument==3.4.2->smdebug) (0.2.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.21.45)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.10.32->smdebug) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->smdebug) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.69.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (20.9)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.18.45)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (3.17.2)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.21.45)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker) (1.26.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "nvidia-docker2 already installed. We are good to go!\n",
      "Stopping docker: \u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "Starting docker:\t.\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "#     !{sys.executable} -m pip install -U split-folders tqdm albumentations crc32c wget\n",
    "    !{sys.executable} -m pip install 'sagemaker[local]' --upgrade\n",
    "    !{sys.executable} -m pip install -U smdebug sagemaker-experiments\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !/bin/bash ./local/local_mode_setup.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 설정\n",
    "\n",
    "<p>Sagemaker 학습에 필요한 기본적인 package를 import 합니다. </p>\n",
    "<p>boto3는 HTTP API 호출을 숨기는 편한 추상화 모델을 가지고 있고, Amazon EC2 인스턴스 및 S3 버켓과 같은 AWS 리소스와 동작하는 파이선 클래스를 제공합니다. </p>\n",
    "<p>sagemaker python sdk는 Amazon SageMaker에서 기계 학습 모델을 교육 및 배포하기 위한 오픈 소스 라이브러리입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "# import splitfolders\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "# import wget\n",
    "# import tarfile\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import strftime\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from sagemaker.debugger import (Rule,\n",
    "                                rule_configs,\n",
    "                                ProfilerConfig, \n",
    "                                FrameworkProfile, \n",
    "                                DetailedProfilingConfig, \n",
    "                                DataloaderProfilingConfig, \n",
    "                                PythonProfilingConfig)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.69.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[\n",
    "                                              {\n",
    "                                                  'Key': 'multigpu',\n",
    "                                                  'Value': 'yes'\n",
    "                                              },\n",
    "                                              {\n",
    "                                                  'Key': 'multinode',\n",
    "                                                  'Value': 'yes'\n",
    "                                              },\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, set_param, i_type, i_cnt, spot):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    \n",
    "    if set_param['sagemakerdp']:\n",
    "        algo = 'sdp'\n",
    "#     elif set_param['sagemakermp']:\n",
    "#         algo = 'smp'\n",
    "    else:\n",
    "        algo = 'ds'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_tag = 'test'\n",
    "    if i_type == 'ml.p3.16xlarge':\n",
    "        i_tag = 'p3'\n",
    "    elif i_type == 'ml.p3dn.24xlarge':\n",
    "        i_tag = 'p3dn'\n",
    "    elif i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'    \n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'diffusion-sagemaker-211011'\n",
    "code_location = f's3://{bucket}/sm_codes'\n",
    "output_path = f's3://{bucket}/poc_diffusion/output' \n",
    "s3_log_path = f's3://{bucket}/tf_logs' \n",
    "# s3_log_path = f'{bucket}/tf_logs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "     {'Name': 'train:lr', 'Regex': 'lr - (.*?),'},\n",
    "     {'Name': 'train:Loss', 'Regex': 'loss -(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules=[ \n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {\n",
    "#     'schedule_sampler' : 'uniform',\n",
    "#     'lr': 1e-4,\n",
    "#     'weight_decay': 0.0,\n",
    "#     'lr_anneal_steps' : 100,\n",
    "#     'batch_size' : 32,\n",
    "#     'microbatch' : -1,\n",
    "#     'ema_rate' : '0.9999',\n",
    "#     'log_interval' : 5,\n",
    "#     'save_interval' : 5,\n",
    "# #     'resume_checkpoint' : \"/opt/ml/code/resume_ckt/model000100.pt\",\n",
    "#     'use_fp16': True,\n",
    "#     'fp16_scale_growth' : 1e-3,\n",
    "#     's3_log_path' : s3_log_path,\n",
    "#     'sagemakerdp' : True,\n",
    "#     }\n",
    "#         \"num_channels\": 256,\n",
    "#         \"num_res_blocks\": 3,\n",
    "#         \"lr\": 1e-05,\n",
    "#         \"num_heads\": 4,\n",
    "#         \"channel_mult\": \"1,1,2,4,4\",\n",
    "#         \"learn_sigma\": true,\n",
    "#         \"diffusion_steps\": 1000,\n",
    "#         \"batch_size\": 16,\n",
    "#         \"class_cond\": false,\n",
    "#         \"weight_decay\": 0.0,\n",
    "#         \"resblock_updown\": true,\n",
    "#         \"image_size\": 128,\n",
    "#         \"noise_schedule\": \"linear\",\n",
    "#         \"use_scale_shift_norm\": true,\n",
    "#         \"log_interval\": 10,\n",
    "#         \"ema_rate\": \"0.999\",\n",
    "#         \"save_interval\": 2000,\n",
    "#         \"attention_resolutions\": \"32,16,8\",\n",
    "#         \"sagemakerdp\": true,\n",
    "#         \"s3_log_path\": \"s3://lgaivision-diffusion/tf_logs\",\n",
    "#         \"use_fp16\": true,\n",
    "#         \"resume_checkpoint\": \"model078000.pt\"\n",
    "\n",
    "hyperparameters = {\n",
    "    'attention_resolutions': '32,16,8',\n",
    "    'class_cond': True,\n",
    "    'diffusion_steps': 1000,\n",
    "    'image_size': 128,\n",
    "    'channel_mult': '1,1.5,2,4,5',\n",
    "    'learn_sigma': True,\n",
    "    'noise_schedule': 'linear',\n",
    "    'num_channels': 256,\n",
    "    'num_heads': 4,\n",
    "    'num_res_blocks': 3,\n",
    "    'resblock_updown': True,\n",
    "    'use_fp16': True,\n",
    "    'use_scale_shift_norm': True,\n",
    "#     'schedule_sampler' : 'uniform',\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'lr_anneal_steps' : 2000,\n",
    "    'batch_size' : 8,\n",
    "#     'microbatch' : -1,\n",
    "    'ema_rate' : '0.9999',\n",
    "    'log_interval' : 10,\n",
    "    'save_interval' : 200,\n",
    "#     'resume_checkpoint' : 'model259000.pt',\n",
    "#     'fp16_scale_growth' : 1e-3,\n",
    "    's3_log_path' : s3_log_path,   ### 로그를 위한 s3_log_path 추가\n",
    "    'sagemakerdp' : True,\n",
    "#     'eps': 1e-8,\n",
    "    }\n",
    "\n",
    "# mp_parameters = {\n",
    "#         'num_microbatches': 16,\n",
    "#         'num_partitions' : 4,\n",
    "#         'placement_strategy': 'cluster', # cluster , spread\n",
    "#         'pipeline': 'interleaved',\n",
    "#         'optimize': 'speed',\n",
    "#         'memory_weight': 0.2,\n",
    "#         'ddp': True,\n",
    "# }\n",
    "\n",
    "experiment_name = 'diffusion-poc-exp2'\n",
    "instance_type = 'ml.p4d.24xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "# instance_type = 'local_gpu'\n",
    "instance_count = 2\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 1*60*60\n",
    "\n",
    "\n",
    "# !gdown https://drive.google.com/uc?id=1vF8Ht0VThpobtmShD52_INhpIgy6eEXq\n",
    "# !gdown https://drive.google.com/uc?id=1kaIqFwTLD7Ml3ib9NQpjoUSD4FUD21-I\n",
    "\n",
    "# !rm -rf dataset\n",
    "# !mkdir dataset\n",
    "# !unzip birds.zip -d dataset/\n",
    "# !tar zxvf CUB_200_2011.tgz -C dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {\n",
    "#     'schedule_sampler' : 'uniform',\n",
    "#     'lr': 1e-4,\n",
    "#     'weight_decay': 0.0,\n",
    "#     'lr_anneal_steps' : 100,\n",
    "#     'batch_size' : 32,\n",
    "#     'microbatch' : -1,\n",
    "#     'ema_rate' : '0.9999',\n",
    "#     'log_interval' : 5,\n",
    "#     'save_interval' : 5,\n",
    "# #     'resume_checkpoint' : \"/opt/ml/code/resume_ckt/model000100.pt\",\n",
    "#     'use_fp16': True,\n",
    "#     'fp16_scale_growth' : 1e-3,\n",
    "#     's3_log_path' : s3_log_path,\n",
    "#     'sagemakerdp' : True,\n",
    "#     }\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'attention_resolutions': '32,16,8',\n",
    "    'class_cond': False,\n",
    "    'diffusion_steps': 1000,\n",
    "    'image_size': 32,\n",
    "    'channel_mult': '1,1,2,4',\n",
    "    'learn_sigma': True,\n",
    "    'noise_schedule': 'linear',\n",
    "    'num_channels': 256,\n",
    "    'num_heads': 1,\n",
    "    'num_res_blocks': 1,\n",
    "    'resblock_updown': True,\n",
    "    'use_fp16': True,\n",
    "    'use_scale_shift_norm': True,\n",
    "#     'schedule_sampler' : 'uniform',\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    'lr_anneal_steps' : 2000,\n",
    "    'batch_size' : 2,\n",
    "#     'microbatch' : -1,\n",
    "    'ema_rate' : '0.9999',\n",
    "    'log_interval' : 10,\n",
    "    'save_interval' : 200,\n",
    "#     'resume_checkpoint' : \"/opt/ml/code/resume_ckt/model000100.pt\",\n",
    "#     'fp16_scale_growth' : 1e-3,\n",
    "    's3_log_path' : s3_log_path,   ### 로그를 위한 s3_log_path 추가\n",
    "    'sagemakerdp' : False,\n",
    "#     'eps': 1e-8,\n",
    "    }\n",
    "\n",
    "# mp_parameters = {\n",
    "#         'num_microbatches': 16,\n",
    "#         'num_partitions' : 4,\n",
    "#         'placement_strategy': 'cluster', # cluster , spread\n",
    "#         'pipeline': 'interleaved',\n",
    "#         'optimize': 'speed',\n",
    "#         'memory_weight': 0.2,\n",
    "#         'ddp': True,\n",
    "# }\n",
    "\n",
    "experiment_name = 'diffusion-poc-exp2'\n",
    "instance_type = 'ml.p4d.24xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "instance_type = 'local_gpu'\n",
    "instance_count = 1\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 1*60*60\n",
    "\n",
    "\n",
    "# !gdown https://drive.google.com/uc?id=1vF8Ht0VThpobtmShD52_INhpIgy6eEXq\n",
    "# !gdown https://drive.google.com/uc?id=1kaIqFwTLD7Ml3ib9NQpjoUSD4FUD21-I\n",
    "\n",
    "# !rm -rf dataset\n",
    "# !mkdir dataset\n",
    "# !unzip birds.zip -d dataset/\n",
    "# !tar zxvf CUB_200_2011.tgz -C dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "    from pathlib import Path\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_data_path = 'file:///home/ec2-user/SageMaker/improved-diffusion-sagemaker/datasets/cifar10'\n",
    "    source_dir = f'{Path.cwd()}/scripts'\n",
    "    checkpoint_s3_bucket = None\n",
    "else:\n",
    "    sess = boto3.Session()\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sm = sess.client('sagemaker')\n",
    "    s3_data_path = 's3://dataset-us-west-2-cyj/cifar10'\n",
    "    source_dir = 'scripts'\n",
    "    checkpoint_s3_bucket = f's3://{bucket}/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_job_name : smp-dist \n",
      "train_instance_type : local_gpu \n",
      "train_instance_count : 1 \n",
      "image_uri : None \n",
      "distribution : {'mpi': {'enabled': True}}\n"
     ]
    }
   ],
   "source": [
    "image_uri = None\n",
    "distribution = None\n",
    "train_job_name = 'sagemaker'\n",
    "\n",
    "\n",
    "train_job_name = 'smp-dist'\n",
    "distribution = {}\n",
    "\n",
    "if hyperparameters['sagemakerdp']:\n",
    "    distribution[\"smdistributed\"]={ \n",
    "                        \"dataparallel\": {\n",
    "                            \"enabled\": True\n",
    "                        }\n",
    "                }\n",
    "\n",
    "# elif hyperparameters['sagemakermp']:\n",
    "#     distribution['smdistributed'] = { \"modelparallel\": {\n",
    "#                                               \"enabled\":True,\n",
    "#                                               \"parameters\": {\n",
    "#                                                   \"partitions\": mp_parameters['num_partitions'],\n",
    "#                                                   \"microbatches\": mp_parameters['num_microbatches'],\n",
    "#                                                   \"placement_strategy\": mp_parameters['placement_strategy'],\n",
    "#                                                   \"pipeline\": mp_parameters['pipeline'],\n",
    "#                                                   \"optimize\": mp_parameters['optimize'],\n",
    "#                                                   \"memory_weight\": mp_parameters['memory_weight'],\n",
    "#                                                   \"ddp\": mp_parameters['ddp'],\n",
    "#                                               }\n",
    "#                                           }\n",
    "#                                       }\n",
    "#     distribution[\"mpi\"]={\n",
    "#                         \"enabled\": True,\n",
    "#                         \"processes_per_host\": 8, # Pick your processes_per_host\n",
    "#                         \"custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa \" #  -x SMP_SKIP_GRAPH_VALIDATION=1\n",
    "#                   }\n",
    "\n",
    "else:\n",
    "    distribution[\"mpi\"]={\n",
    "                        \"enabled\": True,\n",
    "    #                     \"processes_per_host\": 8, # Pick your processes_per_host\n",
    "    #                     \"custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "                  }\n",
    "\n",
    "if do_spot_training:\n",
    "    max_wait = max_run\n",
    "\n",
    "print(\"train_job_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {} \\nimage_uri : {} \\ndistribution : {}\".format(train_job_name, instance_type, instance_count, image_uri, distribution))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_uri='322537213286.dkr.ecr.us-west-2.amazonaws.com/diffusion-sagemaker-smddp:smddp-1.2.2-pt-1.9.0'\n",
    "image_uri='322537213286.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:pytorch-21-10'\n",
    "image_uri='322537213286.dkr.ecr.us-west-2.amazonaws.com/diffusion-sagemaker-smddp:pt110-smddp122'\n",
    "# image_uri='322537213286.dkr.ecr.us-west-2.amazonaws.com/diffusion-sagemaker-smddp:pt110-21-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='image_train.py',\n",
    "    source_dir=source_dir,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.9',\n",
    "    py_version='py38',\n",
    "#     image_uri=image_uri,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=256,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    metric_definitions=metric_definitions,\n",
    "#     rules=rules,\n",
    "    max_run=max_run,\n",
    "    use_spot_instances=do_spot_training,  # spot instance 활용\n",
    "    max_wait=max_wait,\n",
    "    subnets=['subnet-02e36c042e58264e6'],   ## \tsubnet-05c77affac40aa7f3 (2b)  subnet-02e36c042e58264e6 (2c)\n",
    "    security_group_ids=['sg-0bc738570daec9015'],\n",
    "    checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "    TrainingInputMode='File', ## FastFile\n",
    "#     checkpoint_local_path=f'/opt/ml/checkpoints',\n",
    "    max_retry_attempts=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lustre preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## https://docs.aws.amazon.com/fsx/latest/LustreGuide/preload-file-contents-hsm.html\n",
    "# # sudo lfs hsm_restore path/to/file\n",
    "# # sudo lfs hsm_action path/to/file\n",
    "# !find /home/ec2-user/SageMaker/dstaset-2a -type f -print0 | xargs -0 -n 1 sudo lfs hsm_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure FSx Input for your SageMaker Training job\n",
    "\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "file_system_directory_path= '/hlz2pbmv/BIRDS'  # '/5n6znbmv'    g4ljfbmv\n",
    " \n",
    "file_system_id='fs-0cd6d9b6c3c7f614e'  # fs-0849611d06d289065  063be12d6ca6d7862\n",
    "\n",
    "file_system_access_mode='rw'\n",
    "file_system_type='FSxLustre'\n",
    "train_fs = FileSystemInput(file_system_id=file_system_id,\n",
    "                                    file_system_type=file_system_type,\n",
    "                                    directory_path=file_system_directory_path,\n",
    "                                    file_system_access_mode=file_system_access_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure FSx Input for your SageMaker Training job\n",
    "\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "file_system_directory_path= '/bwh3hbmv/cifar10'  # '/5n6znbmv'    g4ljfbmv\n",
    " \n",
    "file_system_id='fs-0ac78e311f71fd34a'  # fs-0849611d06d289065  063be12d6ca6d7862\n",
    "\n",
    "file_system_access_mode='rw'\n",
    "file_system_type='FSxLustre'\n",
    "train_fs = FileSystemInput(file_system_id=file_system_id,\n",
    "                                    file_system_type=file_system_type,\n",
    "                                    directory_path=file_system_directory_path,\n",
    "                                    file_system_access_mode=file_system_access_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configure FSx Input for your SageMaker Training job - cifar10-2\n",
    "\n",
    "# from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "# file_system_directory_path= '/pwa3hbmv/cifar10'  # '/5n6znbmv'    g4ljfbmv\n",
    " \n",
    "# file_system_id='fs-0a50fc761273ae496'  # fs-0849611d06d289065  063be12d6ca6d7862\n",
    "\n",
    "# file_system_access_mode='rw'\n",
    "# file_system_type='FSxLustre'\n",
    "# train_fs = FileSystemInput(file_system_id=file_system_id,\n",
    "#                                     file_system_type=file_system_type,\n",
    "#                                     directory_path=file_system_directory_path,\n",
    "#                                     file_system_access_mode=file_system_access_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    inputs = s3_data_path\n",
    "else:\n",
    "    inputs = train_fs\n",
    "    inputs = s3_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# create_experiment(experiment_name)\n",
    "# job_name = create_trial(experiment_name, hyperparameters, instance_type, instance_count, do_spot_training)\n",
    "\n",
    "# if not instance_type =='local_gpu':\n",
    "#     target_resume_checkpoint=checkpoint_s3_bucket +\"/\"+ job_name  ## model000001.pt만 resume_checkpoint에 추가\n",
    "#     estimator.checkpoint_s3_uri=target_resume_checkpoint\n",
    "\n",
    "# ## checkpoint가 들어있는 S3 위치 --> 새로운 checkpoint S3로 복제\n",
    "# !aws s3 cp 's3://diffusion-sagemaker-211011/checkpoints/diffusion-poc-exp2-p4d-2-sdp-d-1023-10211634984488/model000365.pt' ${target_resume_checkpoint}/model.pt\n",
    "\n",
    "# # Now associate the estimator with the Experiment and Trial\n",
    "# estimator.fit(\n",
    "#     inputs={'training': inputs}, \n",
    "#     job_name=job_name,\n",
    "#     experiment_config={\n",
    "#       'TrialName': job_name,\n",
    "#       'TrialComponentDisplayName': job_name,\n",
    "#     },\n",
    "#     wait=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_jobname = 'diffusion-poc-exp2-p4d-2-sdp-d-1104-01181635988690'\n",
    "checkpoint_id='000031'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 rm s3://diffusion-sagemaker-211011/resume_checkpoint/ --recursive\n",
    "# !aws s3 cp s3://diffusion-sagemaker-211011/checkpoints/{checkpoint_jobname}/model{checkpoint_id}.pt s3://diffusion-sagemaker-211011/resume_checkpoint/\n",
    "# !aws s3 cp s3://diffusion-sagemaker-211011/checkpoints/{checkpoint_jobname}/ema_0.9999_{checkpoint_id}.pt s3://diffusion-sagemaker-211011/resume_checkpoint/\n",
    "# !aws s3 cp s3://diffusion-sagemaker-211011/checkpoints/{checkpoint_jobname}/opt{checkpoint_id}.pt s3://diffusion-sagemaker-211011/resume_checkpoint/                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters['resume_checkpoint']=f\"model{checkpoint_id}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-v8qcv:\n",
      "    command: train\n",
      "    container_name: yhxltv93ae-algo-1-v8qcv\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.9-gpu-py38\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-v8qcv\n",
      "    runtime: nvidia\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpnbb1nqek/algo-1-v8qcv/output:/opt/ml/output\n",
      "    - /tmp/tmpnbb1nqek/algo-1-v8qcv/input:/opt/ml/input\n",
      "    - /tmp/tmpnbb1nqek/algo-1-v8qcv/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpnbb1nqek/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/improved-diffusion-sagemaker/datasets/cifar10:/opt/ml/input/data/training\n",
      "    - /home/ec2-user/SageMaker/guided-diffusion-sagemaker/scripts:/opt/ml/code\n",
      "    - /tmp/tmpnbb1nqek/shared:/opt/ml/shared\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpnbb1nqek/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating yhxltv93ae-algo-1-v8qcv ... \n",
      "Creating yhxltv93ae-algo-1-v8qcv ... done\n",
      "Attaching to yhxltv93ae-algo-1-v8qcv\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:15,145 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:15,222 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:15,224 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:15,225 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m /opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting blobfile==0.11.0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading blobfile-0.11.0-py3-none-any.whl (32 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting nvgpu\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading nvgpu-0.9.0-py2.py3-none-any.whl (9.4 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting xmltodict~=0.12.0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting filelock~=3.0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting pycryptodomex~=3.8\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading pycryptodomex-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: urllib3~=1.25 in /opt/conda/lib/python3.8/site-packages (from blobfile==0.11.0->-r requirements.txt (line 2)) (1.26.6)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: typing-extensions>=3.7.4.1 in /opt/conda/lib/python3.8/site-packages (from blobfile==0.11.0->-r requirements.txt (line 2)) (3.10.0.2)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: flask in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (2.0.2)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting flask-restful\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (1.2.4)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (5.8.0)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting pynvml\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading pynvml-11.0.0-py3-none-any.whl (46 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (2.26.0)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting ansi2html\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading ansi2html-1.6.0-py3-none-any.whl (14 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (1.16.0)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting termcolor\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Preparing metadata (setup.py): started\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Preparing metadata (setup.py): finished with status 'done'\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (0.8.9)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting arrow\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading arrow-1.2.1-py3-none-any.whl (63 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.8/site-packages (from arrow->nvgpu->-r requirements.txt (line 6)) (2.8.2)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (2.0.1)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (2.0.2)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (3.0.2)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (8.0.3)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Collecting aniso8601>=0.82\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from flask-restful->nvgpu->-r requirements.txt (line 6)) (2021.3)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.8/site-packages (from pandas->nvgpu->-r requirements.txt (line 6)) (1.19.1)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2.0.4)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2021.10.8)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2.10)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=3.0->flask->nvgpu->-r requirements.txt (line 6)) (2.0.1)\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Building wheels for collected packages: termcolor\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Building wheel for termcolor (setup.py): started\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=7cb64845b7e38f2e829109e71d8c977488da34dc352b9509eb4983c27d6a6db3\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Successfully built termcolor\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Installing collected packages: aniso8601, xmltodict, termcolor, pynvml, pycryptodomex, flask-restful, filelock, arrow, ansi2html, nvgpu, blobfile\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Successfully installed aniso8601-9.0.1 ansi2html-1.6.0 arrow-1.2.1 blobfile-0.11.0 filelock-3.4.0 flask-restful-0.3.9 nvgpu-0.9.0 pycryptodomex-3.11.0 pynvml-11.0.0 termcolor-1.1.0 xmltodict-0.12.0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:19,466 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:19,466 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:19,469 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:19,469 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1-v8qcv'] Hosts: ['algo-1-v8qcv:8'] process_per_hosts: 8 num_processes: 8\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:19,470 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m 2021-11-23 09:10:19,546 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Training Env:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"sagemaker_mpi_enabled\": true,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"sagemaker_mpi_custom_mpi_options\": \"\"\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     },\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     },\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"current_host\": \"algo-1-v8qcv\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"hosts\": [\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"algo-1-v8qcv\"\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     ],\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"attention_resolutions\": \"32,16,8\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"class_cond\": false,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"diffusion_steps\": 1000,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"image_size\": 32,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"channel_mult\": \"1,1,2,4\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"learn_sigma\": true,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"noise_schedule\": \"linear\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"num_channels\": 256,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"num_heads\": 1,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"num_res_blocks\": 1,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"resblock_updown\": true,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"use_fp16\": true,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"use_scale_shift_norm\": true,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"lr\": 0.0001,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"weight_decay\": 0.0,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"lr_anneal_steps\": 2000,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"batch_size\": 2,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"ema_rate\": \"0.9999\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"log_interval\": 10,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"save_interval\": 200,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"s3_log_path\": \"s3://diffusion-sagemaker-211011/tf_logs\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"sagemakerdp\": false\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     },\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"training\": {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         }\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     },\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"job_name\": \"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"master_hostname\": \"algo-1-v8qcv\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"module_name\": \"image_train\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"current_host\": \"algo-1-v8qcv\",\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         \"hosts\": [\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m             \"algo-1-v8qcv\"\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m         ]\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     },\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m     \"user_entry_point\": \"image_train.py\"\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m }\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Environment variables:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HOSTS=[\"algo-1-v8qcv\"]\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HPS={\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_USER_ENTRY_POINT=image_train.py\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_CURRENT_HOST=algo-1-v8qcv\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_MODULE_NAME=image_train\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_USER_ARGS=[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.9999\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_ATTENTION_RESOLUTIONS=32,16,8\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_CLASS_COND=false\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_DIFFUSION_STEPS=1000\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_IMAGE_SIZE=32\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_CHANNEL_MULT=1,1,2,4\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_LEARN_SIGMA=true\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_NOISE_SCHEDULE=linear\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_NUM_CHANNELS=256\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_NUM_HEADS=1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_NUM_RES_BLOCKS=1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_RESBLOCK_UPDOWN=true\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_USE_FP16=true\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_USE_SCALE_SHIFT_NORM=true\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_LR=0.0001\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_WEIGHT_DECAY=0.0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_LR_ANNEAL_STEPS=2000\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_BATCH_SIZE=2\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_EMA_RATE=0.9999\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_LOG_INTERVAL=10\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_SAVE_INTERVAL=200\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_S3_LOG_PATH=s3://diffusion-sagemaker-211011/tf_logs\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m SM_HP_SAGEMAKERDP=false\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m mpirun --host algo-1-v8qcv:8 -np 8 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TRAINING -x SM_HP_ATTENTION_RESOLUTIONS -x SM_HP_CLASS_COND -x SM_HP_DIFFUSION_STEPS -x SM_HP_IMAGE_SIZE -x SM_HP_CHANNEL_MULT -x SM_HP_LEARN_SIGMA -x SM_HP_NOISE_SCHEDULE -x SM_HP_NUM_CHANNELS -x SM_HP_NUM_HEADS -x SM_HP_NUM_RES_BLOCKS -x SM_HP_RESBLOCK_UPDOWN -x SM_HP_USE_FP16 -x SM_HP_USE_SCALE_SHIFT_NORM -x SM_HP_LR -x SM_HP_WEIGHT_DECAY -x SM_HP_LR_ANNEAL_STEPS -x SM_HP_BATCH_SIZE -x SM_HP_EMA_RATE -x SM_HP_LOG_INTERVAL -x SM_HP_SAVE_INTERVAL -x SM_HP_S3_LOG_PATH -x SM_HP_SAGEMAKERDP -x PYTHONPATH /opt/conda/bin/python3.8 -m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m Data for JOB [31021,1] offset 0 Total slots allocated 8\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  ========================   JOB MAP   ========================\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  Data for node: algo-1-v8qcv\tNum slots: 8\tMax slots: 0\tNum procs: 8\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 0 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 1 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 2 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 3 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 4 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 5 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 6 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  \tProcess OMPI jobid: [31021,1] App: 0 Process rank: 7 Bound: N/A\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m \n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m  =============================================================\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:4,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:4,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '4', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '4', 'OMPI_COMM_WORLD_RANK': '4', 'OMPI_COMM_WORLD_LOCAL_RANK': '4', 'OMPI_COMM_WORLD_NODE_RANK': '4', 'OMPI_MCA_orte_ess_node_rank': '4', 'PMIX_ID': '2032992257.4', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:7,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '7', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '7', 'OMPI_COMM_WORLD_RANK': '7', 'OMPI_COMM_WORLD_LOCAL_RANK': '7', 'OMPI_COMM_WORLD_NODE_RANK': '7', 'OMPI_MCA_orte_ess_node_rank': '7', 'PMIX_ID': '2032992257.7', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:0,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:0,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '0', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '0', 'OMPI_COMM_WORLD_RANK': '0', 'OMPI_COMM_WORLD_LOCAL_RANK': '0', 'OMPI_COMM_WORLD_NODE_RANK': '0', 'OMPI_MCA_orte_ess_node_rank': '0', 'PMIX_ID': '2032992257.0', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:2,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:2,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '2', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '2', 'OMPI_COMM_WORLD_RANK': '2', 'OMPI_COMM_WORLD_LOCAL_RANK': '2', 'OMPI_COMM_WORLD_NODE_RANK': '2', 'OMPI_MCA_orte_ess_node_rank': '2', 'PMIX_ID': '2032992257.2', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:6,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:6,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '6', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '6', 'OMPI_COMM_WORLD_RANK': '6', 'OMPI_COMM_WORLD_LOCAL_RANK': '6', 'OMPI_COMM_WORLD_NODE_RANK': '6', 'OMPI_MCA_orte_ess_node_rank': '6', 'PMIX_ID': '2032992257.6', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:5,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:5,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '5', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '5', 'OMPI_COMM_WORLD_RANK': '5', 'OMPI_COMM_WORLD_LOCAL_RANK': '5', 'OMPI_COMM_WORLD_NODE_RANK': '5', 'OMPI_MCA_orte_ess_node_rank': '5', 'PMIX_ID': '2032992257.5', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:3,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:3,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '3', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '3', 'OMPI_COMM_WORLD_RANK': '3', 'OMPI_COMM_WORLD_LOCAL_RANK': '3', 'OMPI_COMM_WORLD_NODE_RANK': '3', 'OMPI_MCA_orte_ess_node_rank': '3', 'PMIX_ID': '2032992257.3', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:os.environ : environ({'OMPI_VERSION': '4.1.1', 'OMPI_MCA_btl_tcp_if_include': 'eth0', 'OMPI_MCA_oob_tcp_if_include': 'eth0', 'OMPI_MCA_plm_rsh_no_tree_spawn': '1', 'OMPI_MCA_pml': 'ob1', 'OMPI_MCA_btl': '^openib', 'OMPI_MCA_orte_abort_on_non_zero_status': '1', 'OMPI_MCA_btl_vader_single_copy_mechanism': 'none', 'OMPI_MCA_rmaps_base_display_map': '1', 'OMPI_MCA_orte_tag_output': '1', 'OMPI_MCA_hwloc_base_binding_policy': 'none', 'OMPI_MCA_rmaps_base_mapping_policy': 'slot', 'OMPI_MCA_pmix': '^s1,s2,cray,isolated', 'PMIX_MCA_mca_base_component_show_load_errors': '1', 'NCCL_MIN_NRINGS': '4', 'NCCL_SOCKET_IFNAME': 'eth0', 'NCCL_DEBUG': 'INFO', 'LD_LIBRARY_PATH': '/opt/amazon/openmpi/lib:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'PATH': '/opt/amazon/openmpi/bin:/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'LD_PRELOAD': '/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so', 'SM_HOSTS': '[\"algo-1-v8qcv\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0}', 'SM_USER_ENTRY_POINT': 'image_train.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-v8qcv', 'SM_MODULE_NAME': 'image_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-v8qcv\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-v8qcv\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":2,\"channel_mult\":\"1,1,2,4\",\"class_cond\":false,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":32,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":1,\"num_res_blocks\":1,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":false,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\",\"log_level\":20,\"master_hostname\":\"algo-1-v8qcv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-v8qcv\",\"hosts\":[\"algo-1-v8qcv\"]},\"user_entry_point\":\"image_train.py\"}', 'SM_USER_ARGS': '[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"2\",\"--channel_mult\",\"1,1,2,4\",\"--class_cond\",\"False\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.99[1,mpirank:1,algo-1]<stdout>:99\",\"--image_size\",\"32\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"1\",\"--num_res_blocks\",\"1\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"False\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ATTENTION_RESOLUTIONS': '32,16,8', 'SM_HP_CLASS_COND': 'false', 'SM_HP_DIFFUSION_STEPS': '1000', 'SM_HP_IMAGE_SIZE': '32', 'SM_HP_CHANNEL_MULT': '1,1,2,4', 'SM_HP_LEARN_SIGMA': 'true', 'SM_HP_NOISE_SCHEDULE': 'linear', 'SM_HP_NUM_CHANNELS': '256', 'SM_HP_NUM_HEADS': '1', 'SM_HP_NUM_RES_BLOCKS': '1', 'SM_HP_RESBLOCK_UPDOWN': 'true', 'SM_HP_USE_FP16': 'true', 'SM_HP_USE_SCALE_SHIFT_NORM': 'true', 'SM_HP_LR': '0.0001', 'SM_HP_WEIGHT_DECAY': '0.0', 'SM_HP_LR_ANNEAL_STEPS': '2000', 'SM_HP_BATCH_SIZE': '2', 'SM_HP_EMA_RATE': '0.9999', 'SM_HP_LOG_INTERVAL': '10', 'SM_HP_SAVE_INTERVAL': '200', 'SM_HP_S3_LOG_PATH': 's3://diffusion-sagemaker-211011/tf_logs', 'SM_HP_SAGEMAKERDP': 'false', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages', 'OMPI_COMMAND': 'python3.8', 'OMPI_ARGV': '-m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 2 --channel_mult 1,1,2,4 --class_cond False --diffusion_steps 1000 --ema_rate 0.9999 --image_size 32 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 1 --num_res_blocks 1 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp False --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0', 'OMPI_MCA_orte_precondition_transports': '59a5bb7ba09a4f19-2369284c3f16dc0b', 'NVIDIA_VISIBLE_DEVICES': 'all', 'SAGEMAKER_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'PYTHONUNBUFFERED': '1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'HOSTNAME': 'd953101c59f8', 'MASTER_PORT': '7777', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450', 'MANUAL_BUILD': '0', 'NV_ML_REPO_ENABLED': '1', 'BRANCH_OFI': '1.1.3-aws', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'NCCL_VERSION': '2.7.8', 'AWS_REGION': 'us-west-2', 'PWD': '/opt/ml/code', 'RDMAV_FORK_SAFE': '1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'HOROVOD_VERSION': '0.21.3', '_': '/opt/amazon/openmpi/bin/mpirun.real', 'NV_CUDA_CUDART_VERSION': '11.1.74-1', 'HOME': '/root', 'LANG': 'C.UTF-8', 'CUDA_VERSION': '11.1.1', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'DGLBACKEND': 'pytorch', 'MASTER_ADDR': 'algo-1-v8qcv', 'TERM': 'xterm', 'NV_ML_REPO_URL': 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64', 'PYTHONIOENCODING': 'UTF-8', 'SHLVL': '2', 'SAGEMAKER_REGION': 'us-west-2', 'NVARCH': 'x86_64', 'CUDNN_VERSION': '8.0.5.39', 'EFA_VERSION': '1.12.1', 'PYTHONDONTWRITEBYTECODE': '1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-1', 'NCCL_IB_DISABLE': '1', 'TRAINING_JOB_NAME': 'diffusion-poc-exp2-test-1-ds-d-1123-09101637658611', 'CURRENT_HOST': 'algo-1-v8qcv', 'LC_ALL': 'C.UTF-8', 'IPATH_NO_BACKTRACE': '1', 'HFI_NO_BACKTRACE': '1', 'OMPI_MCA_orte_local_daemon_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_orte_hnp_uri': '2032992256.0;tcp://172.18.0.2:38205', 'OMPI_MCA_mpi_oversubscribe': '0', 'OMPI_MCA_orte_app_num': '0', 'OMPI_UNIVERSE_SIZE': '8', 'OMPI_MCA_orte_num_nodes': '1', 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap', 'OMPI_MCA_ess': '^singleton', 'OMPI_MCA_orte_ess_num_procs': '8', 'OMPI_COMM_WORLD_SIZE': '8', 'OMPI_COMM_WORLD_LOCAL_SIZE': '8', 'OMPI_MCA_orte_tmpdir_base': '/tmp', 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.algo-1-v8qcv.0', 'OMPI_[1,mpirank:1,algo-1]<stdout>:MCA_orte_jobfam_session_dir': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'OMPI_NUM_APP_CTX': '1', 'OMPI_FIRST_RANKS': '0', 'OMPI_APP_CTX_NUM_PROCS': '8', 'OMPI_MCA_initial_wdir': '/opt/ml/code', 'OMPI_MCA_orte_launch': '1', 'PMIX_NAMESPACE': '2032992257', 'PMIX_RANK': '1', 'PMIX_SERVER_URI3': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI2': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SERVER_URI21': '2032992256.0;tcp4://127.0.0.1:49363', 'PMIX_SECURITY_MODE': 'native', 'PMIX_PTL_MODULE': 'tcp,usock', 'PMIX_BFROP_BUFFER_TYPE': 'PMIX_BFROP_BUFFER_NON_DESC', 'PMIX_GDS_MODULE': 'ds21,ds12,hash', 'PMIX_SERVER_TMPDIR': '/tmp/ompi.algo-1-v8qcv.0/pid.36', 'PMIX_SYSTEM_TMPDIR': '/tmp', 'PMIX_DSTORE_21_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds21_36', 'PMIX_DSTORE_ESH_BASE_PATH': '/tmp/ompi.algo-1-v8qcv.0/pid.36/pmix_dstor_ds12_36', 'PMIX_HOSTNAME': 'algo-1-v8qcv', 'PMIX_VERSION': '3.2.3', 'OMPI_MCA_ess_base_jobid': '2032992257', 'OMPI_MCA_ess_base_vpid': '1', 'OMPI_COMM_WORLD_RANK': '1', 'OMPI_COMM_WORLD_LOCAL_RANK': '1', 'OMPI_COMM_WORLD_NODE_RANK': '1', 'OMPI_MCA_orte_ess_node_rank': '1', 'PMIX_ID': '2032992257.1', 'OMPI_FILE_LOCATION': '/tmp/ompi.algo-1-v8qcv.0/pid.36/0/0'})\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Logging to /tmp/diffusion-poc-exp2-test-1-ds-d-1123-09101637658611\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:creating model and diffusion...\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:creating data loader...\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:training...\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:40 [0] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:40 [0] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:40 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:40 [0] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:40 [0] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:NCCL version 2.7.8+cuda11.1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:44 [4] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:42 [2] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:44 [4] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:42 [2] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:44 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:42 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:44 [4] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:44 [4] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:42 [2] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:42 [2] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:46 [6] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:46 [6] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:46 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:43 [3] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:46 [6] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:46 [6] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:43 [3] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:43 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:43 [3] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:43 [3] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:41 [1] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:41 [1] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:41 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:41 [1] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:41 [1] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:45 [5] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:45 [5] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:45 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:45 [5] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:45 [5] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:sync_params call\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:47 [7] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:47 [7] ofi_init:1134 NCCL WARN NET/OFI Only EFA provider is supported\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:47 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:47 [7] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:47 [7] NCCL INFO Using network Socket\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:666 [0] NCCL INFO comm 0x7f7884002e10 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-v8qcv:40:40 [0] NCCL INFO Launch mode Parallel\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-v8qcv:41:671 [1] NCCL INFO comm 0x7f8ed0002e10 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-v8qcv:42:668 [2] NCCL INFO comm 0x7f5510002e10 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-v8qcv:43:670 [3] NCCL INFO comm 0x7fcae0002e10 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-v8qcv:46:669 [6] NCCL INFO comm 0x7f92a4002e10 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-v8qcv:44:667 [4] NCCL INFO comm 0x7f5c74002e10 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-v8qcv:47:673 [7] NCCL INFO comm 0x7f7b7c002e10 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-v8qcv:45:672 [5] NCCL INFO comm 0x7f6c54002e10 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2021-11-23 09:10:32.729 algo-1-v8qcv:40 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2021-11-23 09:10:32.753 algo-1-v8qcv:44 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2021-11-23 09:10:32.758 algo-1-v8qcv:42 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2021-11-23 09:10:32.764 algo-1-v8qcv:47 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2021-11-23 09:10:32.769 algo-1-v8qcv:40 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2021-11-23 09:10:32.770 algo-1-v8qcv:46 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2021-11-23 09:10:32.775 algo-1-v8qcv:43 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2021-11-23 09:10:32.775 algo-1-v8qcv:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2021-11-23 09:10:32.775 algo-1-v8qcv:41 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2021-11-23 09:10:32.792 algo-1-v8qcv:44 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2021-11-23 09:10:32.797 algo-1-v8qcv:42 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2021-11-23 09:10:32.806 algo-1-v8qcv:47 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2021-11-23 09:10:32.811 algo-1-v8qcv:46 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2021-11-23 09:10:32.814 algo-1-v8qcv:41 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2021-11-23 09:10:32.816 algo-1-v8qcv:45 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2021-11-23 09:10:32.817 algo-1-v8qcv:43 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [0][2] Train_Time=3.585, Train_Speed=4.462 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.9      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 1        |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 1        |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.996    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.996    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 16       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 0        |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.00762  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00762  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.520\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0...\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stdout>:Save_Time=8.974\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stdout>:Save_Time=8.974\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stdout>:Save_Time=8.974\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stdout>:Save_Time=8.974\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stdout>:Save_Time=8.974\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stdout>:Save_Time=8.978\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stdout>:Save_Time=8.974\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Save_Time=8.446\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:4,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:3,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:6,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:5,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:2,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:7,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:1,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [1][2] Train_Time=0.173, Train_Speed=92.232 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [2][2] Train_Time=0.159, Train_Speed=100.464 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [3][2] Train_Time=0.159, Train_Speed=100.562 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [4][2] Train_Time=0.159, Train_Speed=100.444 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [5][2] Train_Time=0.159, Train_Speed=100.512 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [6][2] Train_Time=0.159, Train_Speed=100.355 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [7][2] Train_Time=0.159, Train_Speed=100.564 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [8][2] Train_Time=0.159, Train_Speed=100.452 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [9][2] Train_Time=0.168, Train_Speed=95.324 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [10][2] Train_Time=0.158, Train_Speed=101.209 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.38     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.817    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.845    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.816    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.82     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.787    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.808    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.832    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.81     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.813    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.777    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 176      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 10       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.0093   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0136   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00603  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00711  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.0103   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.409\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [11][2] Train_Time=0.162, Train_Speed=98.605 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [12][2] Train_Time=0.160, Train_Speed=99.725 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [13][2] Train_Time=0.161, Train_Speed=99.292 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [14][2] Train_Time=0.161, Train_Speed=99.477 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [15][2] Train_Time=0.161, Train_Speed=99.589 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [16][2] Train_Time=0.161, Train_Speed=99.674 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [17][2] Train_Time=0.160, Train_Speed=100.159 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [18][2] Train_Time=0.157, Train_Speed=101.856 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [19][2] Train_Time=0.158, Train_Speed=100.959 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [20][2] Train_Time=0.160, Train_Speed=100.155 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.32     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.482    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.563    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.485    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.435    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.452    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.477    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.556    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.481    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.431    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.446    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 336      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.00516  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00616  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00351  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00464  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.00604  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.461\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [21][2] Train_Time=0.156, Train_Speed=102.391 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [22][2] Train_Time=0.155, Train_Speed=103.004 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [23][2] Train_Time=0.158, Train_Speed=101.120 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [24][2] Train_Time=0.167, Train_Speed=95.639 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [25][2] Train_Time=0.165, Train_Speed=96.781 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [26][2] Train_Time=0.157, Train_Speed=101.637 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [27][2] Train_Time=0.159, Train_Speed=100.438 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [28][2] Train_Time=0.159, Train_Speed=100.515 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [29][2] Train_Time=0.159, Train_Speed=100.629 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [30][2] Train_Time=0.159, Train_Speed=100.579 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.25     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.274    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.412    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.238    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.22     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.255    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.27     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.401    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.236    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.218    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.251    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 496      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 30       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.0041   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0109   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00175  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00197  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.00335  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.403\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [31][2] Train_Time=0.157, Train_Speed=101.698 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [32][2] Train_Time=0.156, Train_Speed=102.542 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [33][2] Train_Time=0.159, Train_Speed=100.783 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [34][2] Train_Time=0.159, Train_Speed=100.827 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [35][2] Train_Time=0.159, Train_Speed=100.645 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [36][2] Train_Time=0.159, Train_Speed=100.706 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [37][2] Train_Time=0.159, Train_Speed=100.730 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [38][2] Train_Time=0.159, Train_Speed=100.620 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [39][2] Train_Time=0.159, Train_Speed=100.867 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [40][2] Train_Time=0.159, Train_Speed=100.640 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.41     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.136    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.202    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.107    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0975   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.115    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.135    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.2      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.106    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0965   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.113    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 656      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 40       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.00165  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00277  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000788 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000994 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.00144  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.388\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [41][2] Train_Time=0.157, Train_Speed=102.035 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [42][2] Train_Time=0.156, Train_Speed=102.832 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [43][2] Train_Time=0.159, Train_Speed=100.875 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [44][2] Train_Time=0.159, Train_Speed=100.812 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [45][2] Train_Time=0.159, Train_Speed=100.754 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [46][2] Train_Time=0.159, Train_Speed=100.659 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [47][2] Train_Time=0.159, Train_Speed=100.702 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [48][2] Train_Time=0.159, Train_Speed=100.876 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [49][2] Train_Time=0.159, Train_Speed=100.714 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [50][2] Train_Time=0.159, Train_Speed=100.769 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 0.829    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.0804   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.164    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0666   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0489   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0424   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.0794   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.161    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0661   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0484   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0419   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 816      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 50       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.00102  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00258  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000495 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000461 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000554 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.361\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [51][2] Train_Time=0.158, Train_Speed=101.084 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [52][2] Train_Time=0.189, Train_Speed=84.551 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [53][2] Train_Time=0.183, Train_Speed=87.581 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [54][2] Train_Time=0.166, Train_Speed=96.379 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [55][2] Train_Time=0.167, Train_Speed=96.074 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [56][2] Train_Time=0.167, Train_Speed=95.991 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [57][2] Train_Time=0.168, Train_Speed=95.332 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [58][2] Train_Time=0.167, Train_Speed=96.062 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [59][2] Train_Time=0.167, Train_Speed=95.881 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [60][2] Train_Time=0.159, Train_Speed=100.788 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 0.598    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.0635   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.157    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0412   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0303   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0265   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.0626   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.155    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0409   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.03     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0261   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 976      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 60       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.000924 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00277  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000309 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000273 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000367 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.354\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Found NaN, decreased lg_loss_scale to 19.061000000000075\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [61][2] Train_Time=0.128, Train_Speed=124.664 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [62][2] Train_Time=0.160, Train_Speed=99.885 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [63][2] Train_Time=0.163, Train_Speed=98.335 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [64][2] Train_Time=0.166, Train_Speed=96.379 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [65][2] Train_Time=0.166, Train_Speed=96.443 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [66][2] Train_Time=0.166, Train_Speed=96.674 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [67][2] Train_Time=0.166, Train_Speed=96.637 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [68][2] Train_Time=0.166, Train_Speed=96.571 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [69][2] Train_Time=0.166, Train_Speed=96.487 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [70][2] Train_Time=0.166, Train_Speed=96.537 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 0.56     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 19.2     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.0952   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.255    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0383   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0182   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0174   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.0907   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.241    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.038    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.018    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0172   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 1.14e+03 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 70       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.0045   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0144   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000284 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000186 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000231 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.434\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [71][2] Train_Time=0.158, Train_Speed=101.230 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [72][2] Train_Time=0.158, Train_Speed=100.959 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [73][2] Train_Time=0.165, Train_Speed=96.911 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [74][2] Train_Time=0.166, Train_Speed=96.580 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [75][2] Train_Time=0.165, Train_Speed=96.727 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [76][2] Train_Time=0.166, Train_Speed=96.548 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [77][2] Train_Time=0.166, Train_Speed=96.516 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [78][2] Train_Time=0.165, Train_Speed=96.790 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [79][2] Train_Time=0.166, Train_Speed=96.530 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [80][2] Train_Time=0.166, Train_Speed=96.570 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| grad_norm     | 0.361    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 19.1     |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss          | 0.0771   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.163    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0301   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0197   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0155   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse           | 0.075    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.158    |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0298   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0196   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0153   |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| param_norm    | 218      |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| samples       | 1.3e+03  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| step          | 80       |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb            | 0.00202  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00476  |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000215 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000165 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000195 |\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:----------------------------\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.463\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [81][2] Train_Time=0.159, Train_Speed=100.572 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [82][2] Train_Time=0.159, Train_Speed=100.892 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [83][2] Train_Time=0.166, Train_Speed=96.539 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [84][2] Train_Time=0.166, Train_Speed=96.626 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [85][2] Train_Time=0.166, Train_Speed=96.541 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [86][2] Train_Time=0.166, Train_Speed=96.599 samples/sec,\n",
      "\u001b[36myhxltv93ae-algo-1-v8qcv |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Step: [87][2] Train_Time=0.166, Train_Speed=96.281 samples/sec,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \"\"\"\n\u001b[1;32m   1467\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# data that was just mounted to the container.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mdirs_to_delete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_to_delete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Print our Job Complete line to have a similar experience to training on SageMaker where\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_cleanup\u001b[0;34m(self, dirs_to_delete)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhosts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0mcontainer_config_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0m_delete_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_config_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_delete_tree\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \"\"\"\n\u001b[1;32m    955\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# on Linux, when docker writes to any mounted volume, it uses the container's user. In most\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    424\u001b[0m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, hyperparameters, instance_type, instance_count, do_spot_training)\n",
    "\n",
    "if not instance_type =='local_gpu':\n",
    "    target_resume_checkpoint=checkpoint_s3_bucket +\"/\"+ job_name  ## model000001.pt만 resume_checkpoint에 추가\n",
    "    estimator.checkpoint_s3_uri=target_resume_checkpoint\n",
    "    \n",
    "inputs2 = 's3://diffusion-sagemaker-211011/resume_checkpoint/'\n",
    "# Now associate the estimator with the Experiment and Trial\n",
    "estimator.fit(\n",
    "    inputs={'training': inputs}, \n",
    "#     inputs={'training': inputs, 'checkpoint' : inputs2}, \n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-7536d84dcb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# job_name='dalle-poc-exp5-p4d-2-d-0530-12261622377580'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dalle-poc-exp4-p4d-2-d-0525-03071621912021 --> public\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dalle-poc-exp4-p4d-2-d-0525-03091621912148 --> another private\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# job_name='dalle-poc-exp1-p4d-1-sdp-d-1006-13111633525892'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "job_name=estimator.latest_training_job.name\n",
    "# job_name='dalle-poc-exp5-p4d-2-d-0530-12261622377580'\n",
    "# dalle-poc-exp4-p4d-2-d-0525-03071621912021 --> public\n",
    "# dalle-poc-exp4-p4d-2-d-0525-03091621912148 --> another private\n",
    "# job_name='dalle-poc-exp1-p4d-1-sdp-d-1006-13111633525892'\n",
    "\n",
    "# job_name = 'diffusion-poc-exp2-p4d-2-ds-d-1119-01441637286264'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:40:15 Starting - Preparing the instances for training\n",
      "2021-11-22 14:40:15 Downloading - Downloading input data\n",
      "2021-11-22 14:40:15 Training - Training image download completed. Training in progress.\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:16,380 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:16,462 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:15,912 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:15,994 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:19,018 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:19,018 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:19,453 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:19,488 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:19,488 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:19,917 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mCollecting blobfile==0.11.0\u001b[0m\n",
      "\u001b[35mDownloading blobfile-0.11.0-py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[35mCollecting nvgpu\u001b[0m\n",
      "\u001b[35mDownloading nvgpu-0.9.0-py2.py3-none-any.whl (9.4 kB)\u001b[0m\n",
      "\u001b[35mCollecting pycryptodomex~=3.8\u001b[0m\n",
      "\u001b[35mDownloading pycryptodomex-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\u001b[0m\n",
      "\u001b[35mCollecting xmltodict~=0.12.0\u001b[0m\n",
      "\u001b[35mDownloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions>=3.7.4.1 in /opt/conda/lib/python3.8/site-packages (from blobfile==0.11.0->-r requirements.txt (line 2)) (3.10.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3~=1.25 in /opt/conda/lib/python3.8/site-packages (from blobfile==0.11.0->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[35mCollecting filelock~=3.0\u001b[0m\n",
      "\u001b[35mDownloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\u001b[0m\n",
      "\u001b[35mCollecting flask-restful\u001b[0m\n",
      "\u001b[35mDownloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (2.26.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (1.2.4)\u001b[0m\n",
      "\u001b[35mCollecting termcolor\u001b[0m\n",
      "\u001b[35mDownloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mCollecting blobfile==0.11.0\u001b[0m\n",
      "\u001b[34mDownloading blobfile-0.11.0-py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvgpu\u001b[0m\n",
      "\u001b[34mDownloading nvgpu-0.9.0-py2.py3-none-any.whl (9.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting xmltodict~=0.12.0\u001b[0m\n",
      "\u001b[34mDownloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting pycryptodomex~=3.8\u001b[0m\n",
      "\u001b[34mDownloading pycryptodomex-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting filelock~=3.0\u001b[0m\n",
      "\u001b[34mDownloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.1 in /opt/conda/lib/python3.8/site-packages (from blobfile==0.11.0->-r requirements.txt (line 2)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3~=1.25 in /opt/conda/lib/python3.8/site-packages (from blobfile==0.11.0->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[34mCollecting termcolor\u001b[0m\n",
      "\u001b[34mDownloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: flask in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (2.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[35mCollecting ansi2html\u001b[0m\n",
      "\u001b[35mDownloading ansi2html-1.6.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (0.8.9)\u001b[0m\n",
      "\u001b[35mCollecting arrow\u001b[0m\n",
      "\u001b[35mDownloading arrow-1.2.1-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (5.8.0)\u001b[0m\n",
      "\u001b[35mCollecting pynvml\u001b[0m\n",
      "\u001b[35mDownloading pynvml-11.0.0-py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.8/site-packages (from arrow->nvgpu->-r requirements.txt (line 6)) (2.8.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (3.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (8.0.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (2.0.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (2.0.2)\u001b[0m\n",
      "\u001b[35mCollecting aniso8601>=0.82\u001b[0m\n",
      "\u001b[35mDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from flask-restful->nvgpu->-r requirements.txt (line 6)) (2021.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.8/site-packages (from pandas->nvgpu->-r requirements.txt (line 6)) (1.19.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2.10)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2.0.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2021.10.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=3.0->flask->nvgpu->-r requirements.txt (line 6)) (2.0.1)\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: termcolor\u001b[0m\n",
      "\u001b[35mBuilding wheel for termcolor (setup.py): started\u001b[0m\n",
      "\u001b[35mBuilding wheel for termcolor (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCreated wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=df3a58b9a665183d62d6befc73067d1f3719bf938562d3b6e1216245fecfd9de\u001b[0m\n",
      "\u001b[35mStored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\u001b[0m\n",
      "\u001b[35mSuccessfully built termcolor\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting ansi2html\u001b[0m\n",
      "\u001b[34mDownloading ansi2html-1.6.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting pynvml\u001b[0m\n",
      "\u001b[34mDownloading pynvml-11.0.0-py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34mCollecting flask-restful\u001b[0m\n",
      "\u001b[34mDownloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (5.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flask in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting arrow\u001b[0m\n",
      "\u001b[34mDownloading arrow-1.2.1-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.8/site-packages (from arrow->nvgpu->-r requirements.txt (line 6)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 6)) (3.0.2)\u001b[0m\n",
      "\u001b[34mCollecting aniso8601>=0.82\u001b[0m\n",
      "\u001b[34mDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from flask-restful->nvgpu->-r requirements.txt (line 6)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.8/site-packages (from pandas->nvgpu->-r requirements.txt (line 6)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->nvgpu->-r requirements.txt (line 6)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=3.0->flask->nvgpu->-r requirements.txt (line 6)) (2.0.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: termcolor\u001b[0m\n",
      "\u001b[34mBuilding wheel for termcolor (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for termcolor (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=ee7d560999ab14d893a815a50d70b6933e12aa0cde8f818a9e8a69423e9f05b7\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\u001b[0m\n",
      "\u001b[34mSuccessfully built termcolor\u001b[0m\n",
      "\u001b[35mInstalling collected packages: aniso8601, xmltodict, termcolor, pynvml, pycryptodomex, flask-restful, filelock, arrow, ansi2html, nvgpu, blobfile\u001b[0m\n",
      "\u001b[34mInstalling collected packages: aniso8601, xmltodict, termcolor, pynvml, pycryptodomex, flask-restful, filelock, arrow, ansi2html, nvgpu, blobfile\u001b[0m\n",
      "\u001b[35mSuccessfully installed aniso8601-9.0.1 ansi2html-1.6.0 arrow-1.2.1 blobfile-0.11.0 filelock-3.4.0 flask-restful-0.3.9 nvgpu-0.9.0 pycryptodomex-3.11.0 pynvml-11.0.0 termcolor-1.1.0 xmltodict-0.12.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:23,358 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:23,358 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:23,360 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:23,360 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.48.15\u001b[0m\n",
      "\u001b[34mSuccessfully installed aniso8601-9.0.1 ansi2html-1.6.0 arrow-1.2.1 blobfile-0.11.0 filelock-3.4.0 flask-restful-0.3.9 nvgpu-0.9.0 pycryptodomex-3.11.0 pynvml-11.0.0 termcolor-1.1.0 xmltodict-0.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:23,846 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:23,846 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:23,850 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:23,851 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:23,851 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:24,373 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:24,454 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:24,454 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:24,454 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:24,454 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:24,458 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,861 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,942 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,942 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,942 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,942 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,942 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,942 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:24,943 sagemaker-training-toolkit INFO     instance type: ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34m2021-11-22 14:40:25,024 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p4d.24xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"num_channels\": 256,\n",
      "        \"num_res_blocks\": 3,\n",
      "        \"lr\": 0.0001,\n",
      "        \"num_heads\": 4,\n",
      "        \"channel_mult\": \"1,1.5,2,4,5\",\n",
      "        \"learn_sigma\": true,\n",
      "        \"diffusion_steps\": 1000,\n",
      "        \"lr_anneal_steps\": 2000,\n",
      "        \"batch_size\": 8,\n",
      "        \"class_cond\": true,\n",
      "        \"weight_decay\": 0.0001,\n",
      "        \"resblock_updown\": true,\n",
      "        \"image_size\": 128,\n",
      "        \"noise_schedule\": \"linear\",\n",
      "        \"use_scale_shift_norm\": true,\n",
      "        \"log_interval\": 10,\n",
      "        \"ema_rate\": \"0.9999\",\n",
      "        \"save_interval\": 200,\n",
      "        \"attention_resolutions\": \"32,16,8\",\n",
      "        \"sagemakerdp\": true,\n",
      "        \"s3_log_path\": \"s3://diffusion-sagemaker-211011/tf_logs\",\n",
      "        \"use_fp16\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"diffusion-poc-exp2-p4d-2-sdp-d-1122-14241637591074\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://diffusion-sagemaker-211011/sm_codes/diffusion-poc-exp2-p4d-2-sdp-d-1122-14241637591074/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"image_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"image_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"attention_resolutions\":\"32,16,8\",\"batch_size\":8,\"channel_mult\":\"1,1.5,2,4,5\",\"class_cond\":true,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":128,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":4,\"num_res_blocks\":3,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":true,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=image_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=image_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://diffusion-sagemaker-211011/sm_codes/diffusion-poc-exp2-p4d-2-sdp-d-1122-14241637591074/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"attention_resolutions\":\"32,16,8\",\"batch_size\":8,\"channel_mult\":\"1,1.5,2,4,5\",\"class_cond\":true,\"diffusion_steps\":1000,\"ema_rate\":\"0.9999\",\"image_size\":128,\"learn_sigma\":true,\"log_interval\":10,\"lr\":0.0001,\"lr_anneal_steps\":2000,\"noise_schedule\":\"linear\",\"num_channels\":256,\"num_heads\":4,\"num_res_blocks\":3,\"resblock_updown\":true,\"s3_log_path\":\"s3://diffusion-sagemaker-211011/tf_logs\",\"sagemakerdp\":true,\"save_interval\":200,\"use_fp16\":true,\"use_scale_shift_norm\":true,\"weight_decay\":0.0001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"diffusion-poc-exp2-p4d-2-sdp-d-1122-14241637591074\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://diffusion-sagemaker-211011/sm_codes/diffusion-poc-exp2-p4d-2-sdp-d-1122-14241637591074/source/sourcedir.tar.gz\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"image_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--attention_resolutions\",\"32,16,8\",\"--batch_size\",\"8\",\"--channel_mult\",\"1,1.5,2,4,5\",\"--class_cond\",\"True\",\"--diffusion_steps\",\"1000\",\"--ema_rate\",\"0.9999\",\"--image_size\",\"128\",\"--learn_sigma\",\"True\",\"--log_interval\",\"10\",\"--lr\",\"0.0001\",\"--lr_anneal_steps\",\"2000\",\"--noise_schedule\",\"linear\",\"--num_channels\",\"256\",\"--num_heads\",\"4\",\"--num_res_blocks\",\"3\",\"--resblock_updown\",\"True\",\"--s3_log_path\",\"s3://diffusion-sagemaker-211011/tf_logs\",\"--sagemakerdp\",\"True\",\"--save_interval\",\"200\",\"--use_fp16\",\"True\",\"--use_scale_shift_norm\",\"True\",\"--weight_decay\",\"0.0001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_CHANNELS=256\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_RES_BLOCKS=3\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_HEADS=4\u001b[0m\n",
      "\u001b[34mSM_HP_CHANNEL_MULT=1,1.5,2,4,5\u001b[0m\n",
      "\u001b[34mSM_HP_LEARN_SIGMA=true\u001b[0m\n",
      "\u001b[34mSM_HP_DIFFUSION_STEPS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_LR_ANNEAL_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_COND=true\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_RESBLOCK_UPDOWN=true\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGE_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_NOISE_SCHEDULE=linear\u001b[0m\n",
      "\u001b[34mSM_HP_USE_SCALE_SHIFT_NORM=true\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_INTERVAL=10\u001b[0m\n",
      "\u001b[34mSM_HP_EMA_RATE=0.9999\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_INTERVAL=200\u001b[0m\n",
      "\u001b[34mSM_HP_ATTENTION_RESOLUTIONS=32,16,8\u001b[0m\n",
      "\u001b[34mSM_HP_SAGEMAKERDP=true\u001b[0m\n",
      "\u001b[34mSM_HP_S3_LOG_PATH=s3://diffusion-sagemaker-211011/tf_logs\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FP16=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p4d.24xlarge smddprun /opt/conda/bin/python3.8 -m mpi4py image_train.py --attention_resolutions 32,16,8 --batch_size 8 --channel_mult 1,1.5,2,4,5 --class_cond True --diffusion_steps 1000 --ema_rate 0.9999 --image_size 128 --learn_sigma True --log_interval 10 --lr 0.0001 --lr_anneal_steps 2000 --noise_schedule linear --num_channels 256 --num_heads 4 --num_res_blocks 3 --resblock_updown True --s3_log_path s3://diffusion-sagemaker-211011/tf_logs --sagemakerdp True --save_interval 200 --use_fp16 True --use_scale_shift_norm True --weight_decay 0.0001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.0.50.211' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:26,463 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=59, name='orted', status='sleeping', started='14:40:25')]\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:26,463 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=59, name='orted', status='sleeping', started='14:40:25')]\u001b[0m\n",
      "\u001b[35m2021-11-22 14:40:26,463 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=59, name='orted', status='sleeping', started='14:40:25')]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.50.211<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.48.15<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Trees [0] 4/-1/-1->3->2|2->3->4/-1/-1 [1] 4/-1/-1->3->2|2->3->4/-1/-1 [2] 4/-1/-1->3->2|2->3->4/-1/-1 [3] 4/-1/-1->3->2|2->3->4/-1/-1 [4] 4/-1/-1->3->2|2->3->4/-1/-1 [5] 4/-1/-1->3->2|2->3->4/-1/-1 [6] 4/-1/-1->3->2|2->3->4/-1/-1 [7] 4/-1/-1->3->2|2->3->4/-1/-1 [8] 4/-1/-1->3->2|2->3->4/-1/-1 [9] 4/-1/-1->3->2|2->3->4/-1/-1 [10] 4/-1/-1->3->2|2->3->4/-1/-1 [11] 4/-1/-1->3->2|2->3->4/-1/-1 [12] 4/-1/-1->3->2|2->3->4/-1/-1 [13] 4/-1/-1->3->2|2->3->4/-1/-1 [14] 4/-1/-1->3->2|2->3->4/-1/-1 [15] 4/-1/-1->3->2|2->3->4/-1/-1 [16] 4/-1/-1->3->2|2->3->4/-1/-1 [17] 4/-1/-1->3->2|2->3->4/-1/-1 [18] 4/-1/-1->3->2|2->3->4/-1/-1 [19] 4/-1/-1->3->2|2->3->4/-1/-1 [20] 4/-1/-1->3->2|2->3->4/-1/-1 [21] 4/-1/-1->3->2|2->3->4/-1/-1 [22] 4/-1/-1->3->2|2->3->4/-1/-1 [23] 4/-1/-1->3->2|2->3->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Setting affinity for GPU 3 to fc,00000000,00fc0000\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Trees [0] 3/-1/-1->2->1|1->2->3/-1/-1 [1] 3/-1/-1->2->1|1->2->3/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] 3/-1/-1->2->1|1->2->3/-1/-1 [5] 3/-1/-1->2->1|1->2->3/-1/-1 [6] 3/-1/-1->2->1|1->2->3/-1/-1 [7] 3/-1/-1->2->1|1->2->3/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] 3/-1/-1->2->1|1->2->3/-1/-1 [11] 3/-1/-1->2->1|1->2->3/-1/-1 [12] 3/-1/-1->2->1|1->2->3/-1/-1 [13] 3/-1/-1->2->1|1->2->3/-1/-1 [14] 3/-1/-1->2->1|1->2->3/-1/-1 [15] 3/-1/-1->2->1|1->2->3/-1/-1 [16] 3/-1/-1->2->1|1->2->3/-1/-1 [17] 3/-1/-1->2->1|1->2->3/-1/-1 [18] 3/-1/-1->2->1|1->2->3/-1/-1 [19] 3/-1/-1->2->1|1->2->3/-1/-1 [20] 3/-1/-1->2->1|1->2->3/-1/-1 [21] 3/-1/-1->2->1|1->2->3/-1/-1 [22] 3/-1/-1->2->1|1->2->3/-1/-1 [23] 3/-1/-1->2->1|1->2->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Setting affinity for GPU 2 to 03,f0000000,0003f000\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Trees [0] 2/-1/-1->1->0|0->1->2/-1/-1 [1] 2/-1/-1->1->0|0->1->2/-1/-1 [2] 2/-1/-1->1->0|0->1->2/-1/-1 [3] 2/-1/-1->1->0|0->1->2/-1/-1 [4] 2/-1/-1->1->0|0->1->2/-1/-1 [5] 2/-1/-1->1->0|0->1->2/-1/-1 [6] 2/-1/-1->1->0|0->1->2/-1/-1 [7] 2/-1/-1->1->0|0->1->2/-1/-1 [8] 2/-1/-1->1->0|0->1->2/-1/-1 [9] 2/-1/-1->1->0|0->1->2/-1/-1 [10] 2/-1/-1->1->0|0->1->2/-1/-1 [11] 2/-1/-1->1->0|0->1->2/-1/-1 [12] 2/-1/-1->1->0|0->1->2/-1/-1 [13] 2/-1/-1->1->0|0->1->2/-1/-1 [14] 2/-1/-1->1->0|0->1->2/-1/-1 [15] 2/-1/-1->1->0|0->1->2/-1/-1 [16] 2/-1/-1->1->0|0->1->2/-1/-1 [17] 2/-1/-1->1->0|0->1->2/-1/-1 [18] 2/-1/-1->1->0|0->1->2/-1/-1 [19] 2/-1/-1->1->0|0->1->2/-1/-1 [20] 2/-1/-1->1->0|0->1->2/-1/-1 [21] 2/-1/-1->1->0|0->1->2/-1/-1 [22] 2/-1/-1->1->0|0->1->2/-1/-1 [23] 2/-1/-1->1->0|0->1->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Setting affinity for GPU 1 to 0fc00000,00000fc0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Trees [0] 5/-1/-1->4->3|3->4->5/-1/-1 [1] 5/-1/-1->4->3|3->4->5/-1/-1 [2] 5/-1/-1->4->3|3->4->5/-1/-1 [3] 5/-1/-1->4->3|3->4->5/-1/-1 [4] 5/-1/-1->4->3|3->4->5/-1/-1 [5] 5/-1/-1->4->3|3->4->5/-1/-1 [6] 5/-1/-1->4->3|3->4->5/-1/-1 [7] 5/-1/-1->4->3|3->4->5/-1/-1 [8] 5/-1/-1->4->3|3->4->5/-1/-1 [9] 5/-1/-1->4->3|3->4->5/-1/-1 [10] 5/-1/-1->4->3|3->4->5/-1/-1 [11] 5/-1/-1->4->3|3->4->5/-1/-1 [12] 5/-1/-1->4->3|3->4->5/-1/-1 [13] 5/-1/-1->4->3|3->4->5/-1/-1 [14] 5/-1/-1->4->3|3->4->5/-1/-1 [15] 5/-1/-1->4->3|3->4->5/-1/-1 [16] 5/-1/-1->4->3|3->4->5/-1/-1 [17] 5/-1/-1->4->3|3->4->5/-1/-1 [18] 5/-1/-1->4->3|3->4->5/-1/-1 [19] 5/-1/-1->4->3|3->4->5/-1/-1 [20] 5/-1/-1->4->3|3->4->5/-1/-1 [21] 5/-1/-1->4->3|3->4->5/-1/-1 [22] 5/-1/-1->4->3|3->4->5/-1/-1 [23] 5/-1/-1->4->3|3->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Setting affinity for GPU 4 to 3f00,00000000,3f000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 7/-1/-1->6->5|5->6->7/-1/-1 [3] 7/-1/-1->6->5|5->6->7/-1/-1 [4] 7/-1/-1->6->5|5->6->7/-1/-1 [5] 7/-1/-1->6->5|5->6->7/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 7/-1/-1->6->5|5->6->7/-1/-1 [9] 7/-1/-1->6->5|5->6->7/-1/-1 [10] 7/-1/-1->6->5|5->6->7/-1/-1 [11] 7/-1/-1->6->5|5->6->7/-1/-1 [12] 7/-1/-1->6->5|5->6->7/-1/-1 [13] 7/-1/-1->6->5|5->6->7/-1/-1 [14] 7/-1/-1->6->5|5->6->7/-1/-1 [15] 7/-1/-1->6->5|5->6->7/-1/-1 [16] 7/-1/-1->6->5|5->6->7/-1/-1 [17] 7/-1/-1->6->5|5->6->7/-1/-1 [18] 7/-1/-1->6->5|5->6->7/-1/-1 [19] 7/-1/-1->6->5|5->6->7/-1/-1 [20] 7/-1/-1->6->5|5->6->7/-1/-1 [21] 7/-1/-1->6->5|5->6->7/-1/-1 [22] 7/-1/-1->6->5|5->6->7/-1/-1 [23] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Setting affinity for GPU 6 to 03f00000,000003f0,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Trees [0] 6/-1/-1->5->4|4->5->6/-1/-1 [1] 6/-1/-1->5->4|4->5->6/-1/-1 [2] 6/-1/-1->5->4|4->5->6/-1/-1 [3] 6/-1/-1->5->4|4->5->6/-1/-1 [4] 6/-1/-1->5->4|4->5->6/-1/-1 [5] 6/-1/-1->5->4|4->5->6/-1/-1 [6] 6/-1/-1->5->4|4->5->6/-1/-1 [7] 6/-1/-1->5->4|4->5->6/-1/-1 [8] 6/-1/-1->5->4|4->5->6/-1/-1 [9] 6/-1/-1->5->4|4->5->6/-1/-1 [10] 6/-1/-1->5->4|4->5->6/-1/-1 [11] 6/-1/-1->5->4|4->5->6/-1/-1 [12] 6/-1/-1->5->4|4->5->6/-1/-1 [13] 6/-1/-1->5->4|4->5->6/-1/-1 [14] 6/-1/-1->5->4|4->5->6/-1/-1 [15] 6/-1/-1->5->4|4->5->6/-1/-1 [16] 6/-1/-1->5->4|4->5->6/-1/-1 [17] 6/-1/-1->5->4|4->5->6/-1/-1 [18] 6/-1/-1->5->4|4->5->6/-1/-1 [19] 6/-1/-1->5->4|4->5->6/-1/-1 [20] 6/-1/-1->5->4|4->5->6/-1/-1 [21] 6/-1/-1->5->4|4->5->6/-1/-1 [22] 6/-1/-1->5->4|4->5->6/-1/-1 [23] 6/-1/-1->5->4|4->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Setting affinity for GPU 5 to 0fc000,0000000f,c0000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Trees [0] -1/-1/-1->7->6|6->7->-1/-1/-1 [1] -1/-1/-1->7->6|6->7->-1/-1/-1 [2] -1/-1/-1->7->6|6->7->-1/-1/-1 [3] -1/-1/-1->7->6|6->7->-1/-1/-1 [4] -1/-1/-1->7->6|6->7->-1/-1/-1 [5] -1/-1/-1->7->6|6->7->-1/-1/-1 [6] -1/-1/-1->7->6|6->7->-1/-1/-1 [7] -1/-1/-1->7->6|6->7->-1/-1/-1 [8] -1/-1/-1->7->6|6->7->-1/-1/-1 [9] -1/-1/-1->7->6|6->7->-1/-1/-1 [10] -1/-1/-1->7->6|6->7->-1/-1/-1 [11] -1/-1/-1->7->6|6->7->-1/-1/-1 [12] -1/-1/-1->7->6|6->7->-1/-1/-1 [13] -1/-1/-1->7->6|6->7->-1/-1/-1 [14] -1/-1/-1->7->6|6->7->-1/-1/-1 [15] -1/-1/-1->7->6|6->7->-1/-1/-1 [16] -1/-1/-1->7->6|6->7->-1/-1/-1 [17] -1/-1/-1->7->6|6->7->-1/-1/-1 [18] -1/-1/-1->7->6|6->7->-1/-1/-1 [19] -1/-1/-1->7->6|6->7->-1/-1/-1 [20] -1/-1/-1->7->6|6->7->-1/-1/-1 [21] -1/-1/-1->7->6|6->7->-1/-1/-1 [22] -1/-1/-1->7->6|6->7->-1/-1/-1 [23] -1/-1/-1->7->6|6->7->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Setting affinity for GPU 7 to fc000000,0000fc00,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1 [2] 1/-1/-1->0->-1|-1->0->1/-1/-1 [3] 1/-1/-1->0->-1|-1->0->1/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 1/-1/-1->0->-1|-1->0->1/-1/-1 [6] 1/-1/-1->0->-1|-1->0->1/-1/-1 [7] 1/-1/-1->0->-1|-1->0->1/-1/-1 [8] 1/-1/-1->0->-1|-1->0->1/-1/-1 [9] 1/-1/-1->0->-1|-1->0->1/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 1/-1/-1->0->-1|-1->0->1/-1/-1 [12] 1/-1/-1->0->-1|-1->0->1/-1/-1 [13] 1/-1/-1->0->-1|-1->0->1/-1/-1 [14] 1/-1/-1->0->-1|-1->0->1/-1/-1 [15] 1/-1/-1->0->-1|-1->0->1/-1/-1 [16] 1/-1/-1->0->-1|-1->0->1/-1/-1 [17] 1/-1/-1->0->-1|-1->0->1/-1/-1 [18] 1/-1/-1->0->-1|-1->0->1/-1/-1 [19] 1/-1/-1->0->-1|-1->0->1/-1/-1 [20] 1/-1/-1->0->-1|-1->0->1/-1/-1 [21] 1/-1/-1->0->-1|-1->0->1/-1/-1 [22] 1/-1/-1->0->-1|-1->0->1/-1/-1 [23] 1/-1/-1->0->-1|-1->0->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Setting affinity for GPU 0 to 3f0000,0000003f\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Trees [0] 3/-1/-1->2->1|1->2->3/-1/-1 [1] 3/-1/-1->2->1|1->2->3/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] 3/-1/-1->2->1|1->2->3/-1/-1 [5] 3/-1/-1->2->1|1->2->3/-1/-1 [6] 3/-1/-1->2->1|1->2->3/-1/-1 [7] 3/-1/-1->2->1|1->2->3/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] 3/-1/-1->2->1|1->2->3/-1/-1 [11] 3/-1/-1->2->1|1->2->3/-1/-1 [12] 3/-1/-1->2->1|1->2->3/-1/-1 [13] 3/-1/-1->2->1|1->2->3/-1/-1 [14] 3/-1/-1->2->1|1->2->3/-1/-1 [15] 3/-1/-1->2->1|1->2->3/-1/-1 [16] 3/-1/-1->2->1|1->2->3/-1/-1 [17] 3/-1/-1->2->1|1->2->3/-1/-1 [18] 3/-1/-1->2->1|1->2->3/-1/-1 [19] 3/-1/-1->2->1|1->2->3/-1/-1 [20] 3/-1/-1->2->1|1->2->3/-1/-1 [21] 3/-1/-1->2->1|1->2->3/-1/-1 [22] 3/-1/-1->2->1|1->2->3/-1/-1 [23] 3/-1/-1->2->1|1->2->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Setting affinity for GPU 2 to 03,f0000000,0003f000\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Trees [0] 4/-1/-1->3->2|2->3->4/-1/-1 [1] 4/-1/-1->3->2|2->3->4/-1/-1 [2] 4/-1/-1->3->2|2->3->4/-1/-1 [3] 4/-1/-1->3->2|2->3->4/-1/-1 [4] 4/-1/-1->3->2|2->3->4/-1/-1 [5] 4/-1/-1->3->2|2->3->4/-1/-1 [6] 4/-1/-1->3->2|2->3->4/-1/-1 [7] 4/-1/-1->3->2|2->3->4/-1/-1 [8] 4/-1/-1->3->2|2->3->4/-1/-1 [9] 4/-1/-1->3->2|2->3->4/-1/-1 [10] 4/-1/-1->3->2|2->3->4/-1/-1 [11] 4/-1/-1->3->2|2->3->4/-1/-1 [12] 4/-1/-1->3->2|2->3->4/-1/-1 [13] 4/-1/-1->3->2|2->3->4/-1/-1 [14] 4/-1/-1->3->2|2->3->4/-1/-1 [15] 4/-1/-1->3->2|2->3->4/-1/-1 [16] 4/-1/-1->3->2|2->3->4/-1/-1 [17] 4/-1/-1->3->2|2->3->4/-1/-1 [18] 4/-1/-1->3->2|2->3->4/-1/-1 [19] 4/-1/-1->3->2|2->3->4/-1/-1 [20] 4/-1/-1->3->2|2->3->4/-1/-1 [21] 4/-1/-1->3->2|2->3->4/-1/-1 [22] 4/-1/-1->3->2|2->3->4/-1/-1 [23] 4/-1/-1->3->2|2->3->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Setting affinity for GPU 3 to fc,00000000,00fc0000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 7/-1/-1->6->5|5->6->7/-1/-1 [3] 7/-1/-1->6->5|5->6->7/-1/-1 [4] 7/-1/-1->6->5|5->6->7/-1/-1 [5] 7/-1/-1->6->5|5->6->7/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 7/-1/-1->6->5|5->6->7/-1/-1 [9] 7/-1/-1->6->5|5->6->7/-1/-1 [10] 7/-1/-1->6->5|5->6->7/-1/-1 [11] 7/-1/-1->6->5|5->6->7/-1/-1 [12] 7/-1/-1->6->5|5->6->7/-1/-1 [13] 7/-1/-1->6->5|5->6->7/-1/-1 [14] 7/-1/-1->6->5|5->6->7/-1/-1 [15] 7/-1/-1->6->5|5->6->7/-1/-1 [16] 7/-1/-1->6->5|5->6->7/-1/-1 [17] 7/-1/-1->6->5|5->6->7/-1/-1 [18] 7/-1/-1->6->5|5->6->7/-1/-1 [19] 7/-1/-1->6->5|5->6->7/-1/-1 [20] 7/-1/-1->6->5|5->6->7/-1/-1 [21] 7/-1/-1->6->5|5->6->7/-1/-1 [22] 7/-1/-1->6->5|5->6->7/-1/-1 [23] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Trees [0] 6/-1/-1->5->4|4->5->6/-1/-1 [1] 6/-1/-1->5->4|4->5->6/-1/-1 [2] 6/-1/-1->5->4|4->5->6/-1/-1 [3] 6/-1/-1->5->4|4->5->6/-1/-1 [4] 6/-1/-1->5->4|4->5->6/-1/-1 [5] 6/-1/-1->5->4|4->5->6/-1/-1 [6] 6/-1/-1->5->4|4->5->6/-1/-1 [7] 6/-1/-1->5->4|4->5->6/-1/-1 [8] 6/-1/-1->5->4|4->5->6/-1/-1 [9] 6/-1/-1->5->4|4->5->6/-1/-1 [10] 6/-1/-1->5->4|4->5->6/-1/-1 [11] 6/-1/-1->5->4|4->5->6/-1/-1 [12] 6/-1/-1->5->4|4->5->6/-1/-1 [13] 6/-1/-1->5->4|4->5->6/-1/-1 [14] 6/-1/-1->5->4|4->5->6/-1/-1 [15] 6/-1/-1->5->4|4->5->6/-1/-1 [16] 6/-1/-1->5->4|4->5->6/-1/-1 [17] 6/-1/-1->5->4|4->5->6/-1/-1 [18] 6/-1/-1->5->4|4->5->6/-1/-1 [19] 6/-1/-1->5->4|4->5->6/-1/-1 [20] 6/-1/-1->5->4|4->5->6/-1/-1 [21] 6/-1/-1->5->4|4->5->6/-1/-1 [22] 6/-1/-1->5->4|4->5->6/-1/-1 [23] 6/-1/-1->5->4|4->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Setting affinity for GPU 5 to 0fc000,0000000f,c0000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Trees [0] 5/-1/-1->4->3|3->4->5/-1/-1 [1] 5/-1/-1->4->3|3->4->5/-1/-1 [2] 5/-1/-1->4->3|3->4->5/-1/-1 [3] 5/-1/-1->4->3|3->4->5/-1/-1 [4] 5/-1/-1->4->3|3->4->5/-1/-1 [5] 5/-1/-1->4->3|3->4->5/-1/-1 [6] 5/-1/-1->4->3|3->4->5/-1/-1 [7] 5/-1/-1->4->3|3->4->5/-1/-1 [8] 5/-1/-1->4->3|3->4->5/-1/-1 [9] 5/-1/-1->4->3|3->4->5/-1/-1 [10] 5/-1/-1->4->3|3->4->5/-1/-1 [11] 5/-1/-1->4->3|3->4->5/-1/-1 [12] 5/-1/-1->4->3|3->4->5/-1/-1 [13] 5/-1/-1->4->3|3->4->5/-1/-1 [14] 5/-1/-1->4->3|3->4->5/-1/-1 [15] 5/-1/-1->4->3|3->4->5/-1/-1 [16] 5/-1/-1->4->3|3->4->5/-1/-1 [17] 5/-1/-1->4->3|3->4->5/-1/-1 [18] 5/-1/-1->4->3|3->4->5/-1/-1 [19] 5/-1/-1->4->3|3->4->5/-1/-1 [20] 5/-1/-1->4->3|3->4->5/-1/-1 [21] 5/-1/-1->4->3|3->4->5/-1/-1 [22] 5/-1/-1->4->3|3->4->5/-1/-1 [23] 5/-1/-1->4->3|3->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Setting affinity for GPU 4 to 3f00,00000000,3f000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Setting affinity for GPU 6 to 03f00000,000003f0,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Trees [0] -1/-1/-1->7->6|6->7->-1/-1/-1 [1] -1/-1/-1->7->6|6->7->-1/-1/-1 [2] -1/-1/-1->7->6|6->7->-1/-1/-1 [3] -1/-1/-1->7->6|6->7->-1/-1/-1 [4] -1/-1/-1->7->6|6->7->-1/-1/-1 [5] -1/-1/-1->7->6|6->7->-1/-1/-1 [6] -1/-1/-1->7->6|6->7->-1/-1/-1 [7] -1/-1/-1->7->6|6->7->-1/-1/-1 [8] -1/-1/-1->7->6|6->7->-1/-1/-1 [9] -1/-1/-1->7->6|6->7->-1/-1/-1 [10] -1/-1/-1->7->6|6->7->-1/-1/-1 [11] -1/-1/-1->7->6|6->7->-1/-1/-1 [12] -1/-1/-1->7->6|6->7->-1/-1/-1 [13] -1/-1/-1->7->6|6->7->-1/-1/-1 [14] -1/-1/-1->7->6|6->7->-1/-1/-1 [15] -1/-1/-1->7->6|6->7->-1/-1/-1 [16] -1/-1/-1->7->6|6->7->-1/-1/-1 [17] -1/-1/-1->7->6|6->7->-1/-1/-1 [18] -1/-1/-1->7->6|6->7->-1/-1/-1 [19] -1/-1/-1->7->6|6->7->-1/-1/-1 [20] -1/-1/-1->7->6|6->7->-1/-1/-1 [21] -1/-1/-1->7->6|6->7->-1/-1/-1 [22] -1/-1/-1->7->6|6->7->-1/-1/-1 [23] -1/-1/-1->7->6|6->7->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Setting affinity for GPU 7 to fc000000,0000fc00,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Trees [0] 2/-1/-1->1->0|0->1->2/-1/-1 [1] 2/-1/-1->1->0|0->1->2/-1/-1 [2] 2/-1/-1->1->0|0->1->2/-1/-1 [3] 2/-1/-1->1->0|0->1->2/-1/-1 [4] 2/-1/-1->1->0|0->1->2/-1/-1 [5] 2/-1/-1->1->0|0->1->2/-1/-1 [6] 2/-1/-1->1->0|0->1->2/-1/-1 [7] 2/-1/-1->1->0|0->1->2/-1/-1 [8] 2/-1/-1->1->0|0->1->2/-1/-1 [9] 2/-1/-1->1->0|0->1->2/-1/-1 [10] 2/-1/-1->1->0|0->1->2/-1/-1 [11] 2/-1/-1->1->0|0->1->2/-1/-1 [12] 2/-1/-1->1->0|0->1->2/-1/-1 [13] 2/-1/-1->1->0|0->1->2/-1/-1 [14] 2/-1/-1->1->0|0->1->2/-1/-1 [15] 2/-1/-1->1->0|0->1->2/-1/-1 [16] 2/-1/-1->1->0|0->1->2/-1/-1 [17] 2/-1/-1->1->0|0->1->2/-1/-1 [18] 2/-1/-1->1->0|0->1->2/-1/-1 [19] 2/-1/-1->1->0|0->1->2/-1/-1 [20] 2/-1/-1->1->0|0->1->2/-1/-1 [21] 2/-1/-1->1->0|0->1->2/-1/-1 [22] 2/-1/-1->1->0|0->1->2/-1/-1 [23] 2/-1/-1->1->0|0->1->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Setting affinity for GPU 1 to 0fc00000,00000fc0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1 [2] 1/-1/-1->0->-1|-1->0->1/-1/-1 [3] 1/-1/-1->0->-1|-1->0->1/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 1/-1/-1->0->-1|-1->0->1/-1/-1 [6] 1/-1/-1->0->-1|-1->0->1/-1/-1 [7] 1/-1/-1->0->-1|-1->0->1/-1/-1 [8] 1/-1/-1->0->-1|-1->0->1/-1/-1 [9] 1/-1/-1->0->-1|-1->0->1/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 1/-1/-1->0->-1|-1->0->1/-1/-1 [12] 1/-1/-1->0->-1|-1->0->1/-1/-1 [13] 1/-1/-1->0->-1|-1->0->1/-1/-1 [14] 1/-1/-1->0->-1|-1->0->1/-1/-1 [15] 1/-1/-1->0->-1|-1->0->1/-1/-1 [16] 1/-1/-1->0->-1|-1->0->1/-1/-1 [17] 1/-1/-1->0->-1|-1->0->1/-1/-1 [18] 1/-1/-1->0->-1|-1->0->1/-1/-1 [19] 1/-1/-1->0->-1|-1->0->1/-1/-1 [20] 1/-1/-1->0->-1|-1->0->1/-1/-1 [21] 1/-1/-1->0->-1|-1->0->1/-1/-1 [22] 1/-1/-1->0->-1|-1->0->1/-1/-1 [23] 1/-1/-1->0->-1|-1->0->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Setting affinity for GPU 0 to 3f0000,0000003f\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO comm 0x556f33606900 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO comm 0x558346680190 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO comm 0x55a8a4d6d920 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO comm 0x55cff10a75b0 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO comm 0x5623d9f8f440 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO comm 0x564cb7c1c270 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO comm 0x56505dce7d80 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO comm 0x560d4e230990 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO comm 0x562499540b10 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO comm 0x564a60b825a0 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO comm 0x5562c0a8fed0 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO comm 0x55d77f978250 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO comm 0x55f11054e350 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO comm 0x556898e4e350 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO comm 0x56205705a9a0 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO comm 0x55d8411fb9b0 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] graph/search.cc:765 NCCL WARN Could not find a path for pattern 4, falling back to simple order\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Trees [0] 3/-1/-1->2->1|1->2->3/-1/-1 [1] 3/-1/-1->2->1|1->2->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Trees [0] 2/8/-1->1->0|0->1->2/8/-1 [1] 2/-1/-1->1->0|0->1->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Setting affinity for GPU 1 to 0fc00000,00000fc0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Trees [0] 4/-1/-1->3->2|2->3->4/-1/-1 [1] 4/-1/-1->3->2|2->3->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Setting affinity for GPU 3 to fc,00000000,00fc0000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Setting affinity for GPU 2 to 03,f0000000,0003f000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Setting affinity for GPU 6 to 03f00000,000003f0,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Trees [0] -1/-1/-1->7->6|6->7->-1/-1/-1 [1] -1/-1/-1->7->6|6->7->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Setting affinity for GPU 7 to fc000000,0000fc00,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Trees [0] 6/-1/-1->5->4|4->5->6/-1/-1 [1] 6/-1/-1->5->4|4->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Setting affinity for GPU 5 to 0fc000,0000000f,c0000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Trees [0] 5/-1/-1->4->3|3->4->5/-1/-1 [1] 5/-1/-1->4->3|3->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Setting affinity for GPU 4 to 3f00,00000000,3f000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Trees [0] 11/-1/-1->10->9|9->10->11/-1/-1 [1] 11/-1/-1->10->9|9->10->11/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Setting affinity for GPU 2 to 03,f0000000,0003f000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Trees [0] 10/-1/-1->9->8|8->9->10/-1/-1 [1] 10/0/-1->9->8|8->9->10/0/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Setting affinity for GPU 1 to 0fc00000,00000fc0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Trees [0] 9/-1/-1->8->1|1->8->9/-1/-1 [1] 9/-1/-1->8->-1|-1->8->9/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Setting affinity for GPU 0 to 3f0000,0000003f\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Trees [0] 12/-1/-1->11->10|10->11->12/-1/-1 [1] 12/-1/-1->11->10|10->11->12/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Setting affinity for GPU 3 to fc,00000000,00fc0000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->9|9->0->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Trees [0] 13/-1/-1->12->11|11->12->13/-1/-1 [1] 13/-1/-1->12->11|11->12->13/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Setting affinity for GPU 4 to 3f00,00000000,3f000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Setting affinity for GPU 0 to 3f0000,0000003f\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Trees [0] -1/-1/-1->15->14|14->15->-1/-1/-1 [1] -1/-1/-1->15->14|14->15->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Setting affinity for GPU 7 to fc000000,0000fc00,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Trees [0] 15/-1/-1->14->13|13->14->15/-1/-1 [1] 15/-1/-1->14->13|13->14->15/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Setting affinity for GPU 6 to 03f00000,000003f0,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Trees [0] 14/-1/-1->13->12|12->13->14/-1/-1 [1] 14/-1/-1->13->12|12->13->14/-1/-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Setting affinity for GPU 5 to 0fc000,0000000f,c0000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 00 : 15[a01d0] -> 0[101c0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 00 : 7[a01d0] -> 8[101c0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 00 : 9[101d0] -> 10[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 00 : 13[901d0] -> 14[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 00 : 11[201d0] -> 12[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 00 : 12[901c0] -> 13[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 00 : 10[201c0] -> 11[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 00 : 14[a01c0] -> 15[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 00 : 7[a01d0] -> 8[101c0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 00 : 15[a01d0] -> 0[101c0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 00 : 13[901d0] -> 12[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 00 : 11[201d0] -> 10[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 00 : 14[a01c0] -> 13[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 00 : 12[901c0] -> 11[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 00 : 10[201c0] -> 9[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 01 : 13[901d0] -> 14[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 01 : 11[201d0] -> 12[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 01 : 12[901c0] -> 13[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO Channel 01 : 12[901c0] -> 11[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 00 : 8[101c0] -> 9[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 00 : 9[101d0] -> 8[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 01 : 10[201c0] -> 11[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 00 : 8[101c0] -> 1[101d0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO Channel 01 : 11[201d0] -> 10[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 00 : 15[a01d0] -> 14[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 01 : 14[a01c0] -> 15[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 01 : 7[a01d0] -> 8[101c0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 01 : 15[a01d0] -> 0[101c0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO Channel 01 : 13[901d0] -> 12[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO Channel 01 : 14[a01c0] -> 13[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:142:142 [4] NCCL INFO comm 0x55d83b5d6cc0 rank 4 nranks 16 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:152:152 [4] NCCL INFO comm 0x56505a4ceed0 rank 12 nranks 16 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:143:143 [5] NCCL INFO comm 0x55689201aae0 rank 5 nranks 16 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:151:151 [5] NCCL INFO comm 0x560d451af430 rank 13 nranks 16 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 01 : 9[101d0] -> 10[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01 : 15[a01d0] -> 0[101c0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 00 : 8[101c0] -> 1[101d0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:149:149 [3] NCCL INFO comm 0x5623d6c95130 rank 11 nranks 16 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO Channel 01 : 10[201c0] -> 9[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO Channel 01 : 15[a01d0] -> 14[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:147:147 [7] NCCL INFO comm 0x556f2db30700 rank 15 nranks 16 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:148:148 [6] NCCL INFO comm 0x564cb6c34ea0 rank 14 nranks 16 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 00 : 1[101d0] -> 8[101c0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 00 : 1[101d0] -> 8[101c0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 01 : 7[a01d0] -> 8[101c0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO Channel 01 : 8[101c0] -> 9[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:146:146 [2] NCCL INFO comm 0x55a8a1744320 rank 10 nranks 16 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:144:144 [3] NCCL INFO comm 0x55f10cce96d0 rank 3 nranks 16 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 01 : 0[101c0] -> 9[101d0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:140:140 [7] NCCL INFO comm 0x5624929343d0 rank 7 nranks 16 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:145:145 [6] NCCL INFO comm 0x55d77bfa0fd0 rank 6 nranks 16 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01 : 0[101c0] -> 9[101d0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:139:139 [2] NCCL INFO comm 0x564a5d0f71b0 rank 2 nranks 16 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:141:141 [1] NCCL INFO comm 0x56205018edd0 rank 1 nranks 16 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 01 : 9[101d0] -> 8[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:167 [0] NCCL INFO comm 0x558345698d30 rank 8 nranks 16 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO Channel 01 : 9[101d0] -> 0[101c0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO Channel 01 : 9[101d0] -> 0[101c0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:150:150 [1] NCCL INFO comm 0x55cfed80d2b0 rank 9 nranks 16 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:159 [0] NCCL INFO comm 0x5562b964c460 rank 0 nranks 16 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.2.0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Logging to /tmp/diffusion-poc-exp2-p4d-2-sdp-d-1122-14241637591074\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:creating model and diffusion...\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:creating data loader...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:training...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:469 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:******** find_resume_checkpoint : None ***********\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [0][8] Train_Time=15.127, Train_Speed=8.462 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.81     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 1.01     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 1.02     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 1.01     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 1        |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 1.02     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 1        |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 1.01     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.998    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.993    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 1.01     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 128      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 0        |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00962  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0108   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00732  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00896  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.0121   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.413\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.436\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=28.385\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=28.800\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=28.800\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=28.800\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=28.796\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=28.874\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=28.868\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=28.817\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=28.705\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=28.706\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.269\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=28.705\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=28.790\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=28.711\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=28.704\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=28.791\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:159:462 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:167:458 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1][8] Train_Time=1.287, Train_Speed=99.485 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [2][8] Train_Time=0.663, Train_Speed=192.923 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [3][8] Train_Time=0.670, Train_Speed=190.984 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [4][8] Train_Time=0.658, Train_Speed=194.384 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [5][8] Train_Time=0.665, Train_Speed=192.461 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [6][8] Train_Time=0.661, Train_Speed=193.505 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [7][8] Train_Time=0.660, Train_Speed=193.895 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [8][8] Train_Time=0.660, Train_Speed=193.906 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [9][8] Train_Time=0.670, Train_Speed=191.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [10][8] Train_Time=0.654, Train_Speed=195.719 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 9.29e+06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.834    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.907    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.815    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.837    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.783    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.818    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.867    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.809    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.829    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.773    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.41e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 10       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.016    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.04     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00602  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00781  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.00993  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.359\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.372\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [11][8] Train_Time=0.564, Train_Speed=226.868 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [12][8] Train_Time=0.641, Train_Speed=199.725 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [13][8] Train_Time=0.664, Train_Speed=192.913 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [14][8] Train_Time=0.665, Train_Speed=192.427 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [15][8] Train_Time=0.649, Train_Speed=197.270 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [16][8] Train_Time=0.633, Train_Speed=202.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [17][8] Train_Time=0.629, Train_Speed=203.491 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [18][8] Train_Time=0.666, Train_Speed=192.235 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [19][8] Train_Time=0.611, Train_Speed=209.570 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [20][8] Train_Time=0.648, Train_Speed=197.539 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.32e+06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.481    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.504    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.451    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.462    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.49     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.474    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.495    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.448    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.458    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.484    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.69e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00608  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00917  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.00332  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00429  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.00628  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.311\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.377\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [21][8] Train_Time=0.553, Train_Speed=231.465 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [22][8] Train_Time=0.645, Train_Speed=198.584 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [23][8] Train_Time=0.646, Train_Speed=198.019 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [24][8] Train_Time=0.630, Train_Speed=203.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [25][8] Train_Time=0.612, Train_Speed=209.297 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [26][8] Train_Time=0.640, Train_Speed=200.062 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [27][8] Train_Time=0.631, Train_Speed=202.820 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [28][8] Train_Time=0.643, Train_Speed=198.949 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [29][8] Train_Time=0.633, Train_Speed=202.089 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [30][8] Train_Time=0.662, Train_Speed=193.309 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.98e+06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.252    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.295    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.219    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.231    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.242    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.242    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.27     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.218    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.229    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.239    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.97e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 30       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00978  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0252   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.0016   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.00222  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.0031   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.306\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.478\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [31][8] Train_Time=0.588, Train_Speed=217.851 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [32][8] Train_Time=0.671, Train_Speed=190.763 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [33][8] Train_Time=0.643, Train_Speed=199.107 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [34][8] Train_Time=0.650, Train_Speed=196.873 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [35][8] Train_Time=0.730, Train_Speed=175.376 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [36][8] Train_Time=0.667, Train_Speed=191.960 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [37][8] Train_Time=0.666, Train_Speed=192.272 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [38][8] Train_Time=0.662, Train_Speed=193.315 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [39][8] Train_Time=0.663, Train_Speed=193.043 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [40][8] Train_Time=0.664, Train_Speed=192.827 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3e+06    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0981   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.116    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0978   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0909   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0849   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.097    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.115    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0971   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.09     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0838   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.25e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 40       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00113  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00165  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000716 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000857 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.00107  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.328\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [41][8] Train_Time=0.582, Train_Speed=219.882 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [42][8] Train_Time=0.642, Train_Speed=199.364 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [43][8] Train_Time=0.648, Train_Speed=197.532 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [44][8] Train_Time=0.652, Train_Speed=196.241 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [45][8] Train_Time=0.641, Train_Speed=199.555 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [46][8] Train_Time=0.656, Train_Speed=195.100 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [47][8] Train_Time=0.649, Train_Speed=197.340 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [48][8] Train_Time=0.662, Train_Speed=193.484 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [49][8] Train_Time=0.664, Train_Speed=192.769 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [50][8] Train_Time=0.671, Train_Speed=190.723 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.55e+06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0433   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0722   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0329   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0292   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0336   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0421   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0687   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0327   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0289   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0332   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.53e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 50       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00122  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00348  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000244 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000264 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000418 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.316\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.426\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [51][8] Train_Time=0.585, Train_Speed=218.797 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [52][8] Train_Time=0.665, Train_Speed=192.479 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [53][8] Train_Time=0.655, Train_Speed=195.356 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [54][8] Train_Time=0.634, Train_Speed=201.990 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [55][8] Train_Time=0.627, Train_Speed=203.994 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [56][8] Train_Time=0.658, Train_Speed=194.618 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [57][8] Train_Time=0.667, Train_Speed=191.843 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [58][8] Train_Time=0.660, Train_Speed=194.070 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [59][8] Train_Time=0.662, Train_Speed=193.497 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [60][8] Train_Time=0.650, Train_Speed=196.823 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.2e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0224   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0417   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0183   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0133   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0117   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.022    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0404   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0182   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0132   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0115   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.81e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 60       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000469 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00124  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000136 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 0.000125 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000147 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.352\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.422\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [61][8] Train_Time=0.556, Train_Speed=230.199 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [62][8] Train_Time=0.655, Train_Speed=195.426 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [63][8] Train_Time=0.659, Train_Speed=194.136 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [64][8] Train_Time=0.660, Train_Speed=193.865 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [65][8] Train_Time=0.661, Train_Speed=193.679 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [66][8] Train_Time=0.659, Train_Speed=194.168 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [67][8] Train_Time=0.667, Train_Speed=191.958 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [68][8] Train_Time=0.665, Train_Speed=192.522 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [69][8] Train_Time=0.664, Train_Speed=192.828 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [70][8] Train_Time=0.662, Train_Speed=193.274 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.31e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0241   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0553   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.016    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00898  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00797  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0222   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0493   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0159   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0089   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00787  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 70       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00189  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00606  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 0.000117 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 8.5e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 0.000102 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.330\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.405\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [71][8] Train_Time=0.582, Train_Speed=220.043 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [72][8] Train_Time=0.667, Train_Speed=191.813 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [73][8] Train_Time=0.668, Train_Speed=191.656 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [74][8] Train_Time=0.669, Train_Speed=191.352 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [75][8] Train_Time=0.665, Train_Speed=192.594 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [76][8] Train_Time=0.666, Train_Speed=192.207 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [77][8] Train_Time=0.668, Train_Speed=191.746 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [78][8] Train_Time=0.665, Train_Speed=192.525 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [79][8] Train_Time=0.664, Train_Speed=192.659 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [80][8] Train_Time=0.646, Train_Speed=198.216 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.47e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.018    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0467   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.012    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00823  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00657  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0174   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0443   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.012    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00815  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00648  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.04e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 80       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000618 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00233  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 9.03e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 7.47e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 8.71e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.359\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.379\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [81][8] Train_Time=0.575, Train_Speed=222.510 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [82][8] Train_Time=0.638, Train_Speed=200.541 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [83][8] Train_Time=0.667, Train_Speed=192.045 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [84][8] Train_Time=0.664, Train_Speed=192.863 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [85][8] Train_Time=0.645, Train_Speed=198.452 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [86][8] Train_Time=0.644, Train_Speed=198.753 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [87][8] Train_Time=0.665, Train_Speed=192.477 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [88][8] Train_Time=0.646, Train_Speed=198.111 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [89][8] Train_Time=0.628, Train_Speed=203.737 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [90][8] Train_Time=0.642, Train_Speed=199.286 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.04e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0172   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0407   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0112   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00615  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0056   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.016    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0367   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0111   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0061   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00553  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.16e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 90       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00115  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00401  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 8.2e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 5.81e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.15e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.358\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.428\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [91][8] Train_Time=0.658, Train_Speed=194.463 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [92][8] Train_Time=0.677, Train_Speed=189.038 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [93][8] Train_Time=0.672, Train_Speed=190.376 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [94][8] Train_Time=0.664, Train_Speed=192.709 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [95][8] Train_Time=0.666, Train_Speed=192.174 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [96][8] Train_Time=0.665, Train_Speed=192.394 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [97][8] Train_Time=0.614, Train_Speed=208.626 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [98][8] Train_Time=0.647, Train_Speed=197.696 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [99][8] Train_Time=0.647, Train_Speed=197.868 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [100][8] Train_Time=0.612, Train_Speed=209.183 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.04e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0143   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0398   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0105   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00606  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00466  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0136   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0371   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0104   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00601  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0046   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.29e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 100      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000671 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00276  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 7.7e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 5.57e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.84e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.356\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.379\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [101][8] Train_Time=0.537, Train_Speed=238.240 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [102][8] Train_Time=0.609, Train_Speed=210.149 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [103][8] Train_Time=0.613, Train_Speed=208.649 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [104][8] Train_Time=0.656, Train_Speed=195.197 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [105][8] Train_Time=0.612, Train_Speed=209.204 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [106][8] Train_Time=0.633, Train_Speed=202.090 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [107][8] Train_Time=0.652, Train_Speed=196.392 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [108][8] Train_Time=0.633, Train_Speed=202.127 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [109][8] Train_Time=0.639, Train_Speed=200.325 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [110][8] Train_Time=0.609, Train_Speed=210.255 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.77e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0122   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0238   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00983  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00498  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00385  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.012    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0232   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00976  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00493  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0038   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.42e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 110      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000216 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000546 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 7.16e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 4.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.88e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.306\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.384\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [111][8] Train_Time=0.542, Train_Speed=236.206 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [112][8] Train_Time=0.634, Train_Speed=201.967 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [113][8] Train_Time=0.666, Train_Speed=192.231 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [114][8] Train_Time=0.662, Train_Speed=193.306 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [115][8] Train_Time=0.664, Train_Speed=192.643 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [116][8] Train_Time=0.664, Train_Speed=192.881 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [117][8] Train_Time=0.653, Train_Speed=196.053 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [118][8] Train_Time=0.647, Train_Speed=197.909 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [119][8] Train_Time=0.649, Train_Speed=197.116 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [120][8] Train_Time=0.647, Train_Speed=197.699 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.28e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0123   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0301   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0088   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00417  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00324  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0119   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0287   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00873  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00413  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0032   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.55e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 120      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000394 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 6.5e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 3.93e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.08e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.494\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.516\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [121][8] Train_Time=0.577, Train_Speed=222.000 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [122][8] Train_Time=0.665, Train_Speed=192.391 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [123][8] Train_Time=0.665, Train_Speed=192.361 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [124][8] Train_Time=0.654, Train_Speed=195.680 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [125][8] Train_Time=0.666, Train_Speed=192.074 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [126][8] Train_Time=0.663, Train_Speed=192.935 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [127][8] Train_Time=0.664, Train_Speed=192.875 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [128][8] Train_Time=0.665, Train_Speed=192.622 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [129][8] Train_Time=0.665, Train_Speed=192.400 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [130][8] Train_Time=0.668, Train_Speed=191.570 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.67e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00898  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0209   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00872  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00354  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00244  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00867  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0198   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00865  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00351  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00241  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.68e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 130      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00031  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00106  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 6.47e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 3.37e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.373\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.419\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [131][8] Train_Time=0.583, Train_Speed=219.407 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [132][8] Train_Time=0.682, Train_Speed=187.751 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [133][8] Train_Time=0.679, Train_Speed=188.464 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [134][8] Train_Time=0.678, Train_Speed=188.760 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [135][8] Train_Time=0.679, Train_Speed=188.386 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [136][8] Train_Time=0.681, Train_Speed=188.019 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [137][8] Train_Time=0.679, Train_Speed=188.541 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [138][8] Train_Time=0.671, Train_Speed=190.748 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [139][8] Train_Time=0.668, Train_Speed=191.738 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [140][8] Train_Time=0.668, Train_Speed=191.752 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.45e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0353   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.114    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00695  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0035   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00193  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0143   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0406   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0069   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00347  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0019   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.8e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 140      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.021    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0731   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 5.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 3.07e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 2.45e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.386\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.441\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [141][8] Train_Time=0.565, Train_Speed=226.376 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [142][8] Train_Time=0.650, Train_Speed=197.048 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [143][8] Train_Time=0.662, Train_Speed=193.283 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [144][8] Train_Time=0.664, Train_Speed=192.648 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [145][8] Train_Time=0.667, Train_Speed=191.955 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [146][8] Train_Time=0.660, Train_Speed=193.965 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [147][8] Train_Time=0.658, Train_Speed=194.497 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [148][8] Train_Time=0.667, Train_Speed=191.913 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [149][8] Train_Time=0.637, Train_Speed=200.981 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [150][8] Train_Time=0.653, Train_Speed=195.977 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.63e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0128   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0344   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00667  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00279  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00153  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0118   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0311   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00662  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00277  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.93e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 150      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000974 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0033   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.91e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 2.52e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.94e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.460\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.503\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [151][8] Train_Time=0.590, Train_Speed=216.920 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [152][8] Train_Time=0.641, Train_Speed=199.811 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [153][8] Train_Time=0.640, Train_Speed=199.933 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [154][8] Train_Time=0.621, Train_Speed=206.104 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [155][8] Train_Time=0.645, Train_Speed=198.420 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [156][8] Train_Time=0.640, Train_Speed=200.059 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [157][8] Train_Time=0.635, Train_Speed=201.516 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [158][8] Train_Time=0.641, Train_Speed=199.643 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [159][8] Train_Time=0.614, Train_Speed=208.341 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [160][8] Train_Time=0.663, Train_Speed=192.962 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.26e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00747  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0179   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00598  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00234  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00117  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00734  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0176   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00594  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00231  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00115  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.06e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 160      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00013  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000374 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.43e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 2.12e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.47e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.421\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.540\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [161][8] Train_Time=0.592, Train_Speed=216.083 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [162][8] Train_Time=0.617, Train_Speed=207.614 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [163][8] Train_Time=0.641, Train_Speed=199.553 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [164][8] Train_Time=0.642, Train_Speed=199.447 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [165][8] Train_Time=0.653, Train_Speed=195.877 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [166][8] Train_Time=0.644, Train_Speed=198.673 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [167][8] Train_Time=0.627, Train_Speed=204.109 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [168][8] Train_Time=0.648, Train_Speed=197.546 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [169][8] Train_Time=0.648, Train_Speed=197.551 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [170][8] Train_Time=0.614, Train_Speed=208.369 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.49e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00751  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0264   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00574  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00247  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00105  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00722  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.025    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0057   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00245  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00104  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.19e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 170      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000292 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00145  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 2.21e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.515\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.560\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [171][8] Train_Time=0.559, Train_Speed=228.966 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [172][8] Train_Time=0.675, Train_Speed=189.576 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [173][8] Train_Time=0.666, Train_Speed=192.196 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [174][8] Train_Time=0.668, Train_Speed=191.624 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [175][8] Train_Time=0.665, Train_Speed=192.432 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [176][8] Train_Time=0.649, Train_Speed=197.086 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [177][8] Train_Time=0.636, Train_Speed=201.258 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [178][8] Train_Time=0.650, Train_Speed=197.013 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [179][8] Train_Time=0.650, Train_Speed=196.803 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [180][8] Train_Time=0.646, Train_Speed=198.289 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.59e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0058   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0172   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00623  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00201  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000942 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00567  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0167   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00619  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00199  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00093  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.32e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 180      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000134 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000573 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.85e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.21e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.439\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.730\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [181][8] Train_Time=0.577, Train_Speed=221.981 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [182][8] Train_Time=0.664, Train_Speed=192.660 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [183][8] Train_Time=0.666, Train_Speed=192.325 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [184][8] Train_Time=0.667, Train_Speed=191.801 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [185][8] Train_Time=0.668, Train_Speed=191.701 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [186][8] Train_Time=0.667, Train_Speed=191.815 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [187][8] Train_Time=0.667, Train_Speed=191.801 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [188][8] Train_Time=0.653, Train_Speed=195.882 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [189][8] Train_Time=0.631, Train_Speed=202.987 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [190][8] Train_Time=0.645, Train_Speed=198.363 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.75e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0267   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.116    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00556  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00204  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000922 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00795  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.028    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00551  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00202  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00091  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.44e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 190      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0187   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0881   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.11e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.85e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.462\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.504\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [191][8] Train_Time=0.591, Train_Speed=216.622 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [192][8] Train_Time=0.647, Train_Speed=197.960 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [193][8] Train_Time=0.645, Train_Speed=198.544 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [194][8] Train_Time=0.644, Train_Speed=198.723 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [195][8] Train_Time=0.663, Train_Speed=192.928 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [196][8] Train_Time=0.607, Train_Speed=210.850 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [197][8] Train_Time=0.602, Train_Speed=212.680 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [198][8] Train_Time=0.610, Train_Speed=209.887 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [199][8] Train_Time=0.656, Train_Speed=195.038 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [200][8] Train_Time=0.657, Train_Speed=194.706 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.48e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0088   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0246   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00608  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00209  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000855 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00811  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0219   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00604  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00207  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000844 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.57e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 200      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000687 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00266  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.46e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.86e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.08e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.352\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.494\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=29.024\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.518\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.518\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.518\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.518\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=29.166\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [201][8] Train_Time=0.593, Train_Speed=215.690 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [202][8] Train_Time=0.659, Train_Speed=194.357 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [203][8] Train_Time=0.656, Train_Speed=195.089 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [204][8] Train_Time=0.666, Train_Speed=192.154 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [205][8] Train_Time=0.661, Train_Speed=193.527 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [206][8] Train_Time=0.647, Train_Speed=197.749 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [207][8] Train_Time=0.645, Train_Speed=198.543 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [208][8] Train_Time=0.665, Train_Speed=192.589 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [209][8] Train_Time=0.695, Train_Speed=184.042 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [210][8] Train_Time=0.675, Train_Speed=189.661 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.13e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00646  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0154   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00569  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.002    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000857 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00636  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.015    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00565  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00198  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000846 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.7e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 210      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000103 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00032  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.16e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.83e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.08e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.476\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.508\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [211][8] Train_Time=0.630, Train_Speed=203.160 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [212][8] Train_Time=0.679, Train_Speed=188.504 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [213][8] Train_Time=0.671, Train_Speed=190.878 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [214][8] Train_Time=0.612, Train_Speed=209.062 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [215][8] Train_Time=0.642, Train_Speed=199.250 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [216][8] Train_Time=0.663, Train_Speed=193.137 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [217][8] Train_Time=0.663, Train_Speed=193.089 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [218][8] Train_Time=0.663, Train_Speed=192.935 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [219][8] Train_Time=0.666, Train_Speed=192.153 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [220][8] Train_Time=0.664, Train_Speed=192.633 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.76e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.01     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0294   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00579  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00179  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000865 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00859  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0244   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00575  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00177  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000854 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.83e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 220      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00141  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00507  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.68e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.14e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.412\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.528\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [221][8] Train_Time=0.586, Train_Speed=218.542 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [222][8] Train_Time=0.666, Train_Speed=192.140 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [223][8] Train_Time=0.666, Train_Speed=192.088 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [224][8] Train_Time=0.638, Train_Speed=200.607 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [225][8] Train_Time=0.635, Train_Speed=201.609 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [226][8] Train_Time=0.662, Train_Speed=193.360 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [227][8] Train_Time=0.666, Train_Speed=192.161 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [228][8] Train_Time=0.667, Train_Speed=191.940 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [229][8] Train_Time=0.668, Train_Speed=191.665 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [230][8] Train_Time=0.665, Train_Speed=192.514 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.93e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00858  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0275   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00566  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00199  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00079  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00805  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0254   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00562  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00197  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00078  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 2.96e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 230      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000535 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00218  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.8e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 9.82e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.417\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.552\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [231][8] Train_Time=0.572, Train_Speed=223.770 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [232][8] Train_Time=0.665, Train_Speed=192.383 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [233][8] Train_Time=0.666, Train_Speed=192.136 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [234][8] Train_Time=0.663, Train_Speed=193.062 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [235][8] Train_Time=0.663, Train_Speed=192.973 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [236][8] Train_Time=0.655, Train_Speed=195.509 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [237][8] Train_Time=0.614, Train_Speed=208.414 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [238][8] Train_Time=0.636, Train_Speed=201.217 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [239][8] Train_Time=0.608, Train_Speed=210.607 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [240][8] Train_Time=0.642, Train_Speed=199.356 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.52e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00806  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0232   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00516  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00204  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000794 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00759  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0215   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00512  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00202  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000784 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.08e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 240      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000472 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00174  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.8e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.82e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.02e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.494\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.551\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [241][8] Train_Time=0.528, Train_Speed=242.364 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [242][8] Train_Time=0.660, Train_Speed=194.035 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [243][8] Train_Time=0.618, Train_Speed=207.257 samples/sec,[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [244][8] Train_Time=0.622, Train_Speed=205.726 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [245][8] Train_Time=0.629, Train_Speed=203.559 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [246][8] Train_Time=0.663, Train_Speed=193.130 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [247][8] Train_Time=0.660, Train_Speed=193.851 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [248][8] Train_Time=0.623, Train_Speed=205.530 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [249][8] Train_Time=0.623, Train_Speed=205.318 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [250][8] Train_Time=0.620, Train_Speed=206.468 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.31e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0106   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0332   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00538  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00203  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000707 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00869  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0258   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00534  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00201  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000698 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.21e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 250      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00187  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00741  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.96e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.8e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 8.65e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.392\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.489\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [251][8] Train_Time=0.545, Train_Speed=234.818 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [252][8] Train_Time=0.608, Train_Speed=210.385 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [253][8] Train_Time=0.631, Train_Speed=202.745 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [254][8] Train_Time=0.643, Train_Speed=199.121 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [255][8] Train_Time=0.645, Train_Speed=198.534 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [256][8] Train_Time=0.647, Train_Speed=197.770 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [257][8] Train_Time=0.649, Train_Speed=197.124 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [258][8] Train_Time=0.678, Train_Speed=188.737 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [259][8] Train_Time=0.662, Train_Speed=193.372 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [260][8] Train_Time=0.639, Train_Speed=200.444 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.4e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00816  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0189   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00611  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00186  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000782 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00775  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0177   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00607  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00185  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000773 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.34e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 260      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000407 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00116  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.51e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.68e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 9.83e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.485\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.575\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [261][8] Train_Time=0.576, Train_Speed=222.300 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [262][8] Train_Time=0.668, Train_Speed=191.492 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [263][8] Train_Time=0.666, Train_Speed=192.093 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [264][8] Train_Time=0.667, Train_Speed=191.901 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [265][8] Train_Time=0.675, Train_Speed=189.744 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [266][8] Train_Time=0.670, Train_Speed=191.046 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [267][8] Train_Time=0.666, Train_Speed=192.128 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [268][8] Train_Time=0.663, Train_Speed=193.007 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [269][8] Train_Time=0.663, Train_Speed=193.169 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [270][8] Train_Time=0.662, Train_Speed=193.292 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.11e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00838  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.019    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00472  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00177  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000731 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00808  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0183   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00469  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00175  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000722 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.47e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 270      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000297 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000784 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.48e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.6e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 9.16e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.505\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.552\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [271][8] Train_Time=0.583, Train_Speed=219.476 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [272][8] Train_Time=0.666, Train_Speed=192.056 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [273][8] Train_Time=0.664, Train_Speed=192.895 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [274][8] Train_Time=0.662, Train_Speed=193.211 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [275][8] Train_Time=0.650, Train_Speed=196.951 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [276][8] Train_Time=0.650, Train_Speed=197.065 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [277][8] Train_Time=0.665, Train_Speed=192.373 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [278][8] Train_Time=0.663, Train_Speed=192.984 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [279][8] Train_Time=0.663, Train_Speed=193.105 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [280][8] Train_Time=0.650, Train_Speed=196.861 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.57e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00764  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0188   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00507  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00182  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000683 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00744  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0181   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00503  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00181  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000674 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.6e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 280      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000203 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000604 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.7e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.66e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 8.63e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.401\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.463\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [281][8] Train_Time=0.537, Train_Speed=238.392 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [282][8] Train_Time=0.647, Train_Speed=197.939 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [283][8] Train_Time=0.665, Train_Speed=192.445 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [284][8] Train_Time=0.634, Train_Speed=201.763 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [285][8] Train_Time=0.656, Train_Speed=195.073 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [286][8] Train_Time=0.667, Train_Speed=191.768 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [287][8] Train_Time=0.639, Train_Speed=200.386 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [288][8] Train_Time=0.631, Train_Speed=202.939 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [289][8] Train_Time=0.650, Train_Speed=196.810 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [290][8] Train_Time=0.646, Train_Speed=198.275 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.03e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00646  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0177   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00453  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0017   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000636 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00632  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0172   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0045   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00169  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000628 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.72e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 290      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00014  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000462 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.57e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.99e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.472\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.525\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [291][8] Train_Time=0.633, Train_Speed=202.234 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [292][8] Train_Time=0.668, Train_Speed=191.752 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [293][8] Train_Time=0.667, Train_Speed=192.045 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [294][8] Train_Time=0.664, Train_Speed=192.794 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [295][8] Train_Time=0.663, Train_Speed=192.957 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [296][8] Train_Time=0.632, Train_Speed=202.540 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [297][8] Train_Time=0.610, Train_Speed=209.969 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [298][8] Train_Time=0.609, Train_Speed=210.232 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [299][8] Train_Time=0.663, Train_Speed=192.961 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [300][8] Train_Time=0.663, Train_Speed=193.034 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.92e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0132   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0409   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00485  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.002    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000835 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0101   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0295   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00481  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00198  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000825 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.85e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 300      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00315  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0114   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.56e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.79e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 1.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.476\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.571\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [301][8] Train_Time=0.583, Train_Speed=219.382 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [302][8] Train_Time=0.647, Train_Speed=197.692 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [303][8] Train_Time=0.604, Train_Speed=211.936 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [304][8] Train_Time=0.603, Train_Speed=212.170 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [305][8] Train_Time=0.663, Train_Speed=193.152 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [306][8] Train_Time=0.643, Train_Speed=199.003 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [307][8] Train_Time=0.633, Train_Speed=202.250 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [308][8] Train_Time=0.601, Train_Speed=213.080 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [309][8] Train_Time=0.664, Train_Speed=192.629 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [310][8] Train_Time=0.650, Train_Speed=197.020 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.03e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00579  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0162   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00543  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00201  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000759 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00568  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0158   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00539  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.002    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00075  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 3.98e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 310      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00011  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000448 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.97e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.77e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 9.54e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.354\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.544\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [311][8] Train_Time=0.542, Train_Speed=236.053 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [312][8] Train_Time=0.677, Train_Speed=188.940 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [313][8] Train_Time=0.674, Train_Speed=189.980 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [314][8] Train_Time=0.664, Train_Speed=192.667 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [315][8] Train_Time=0.661, Train_Speed=193.592 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [316][8] Train_Time=0.631, Train_Speed=202.888 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [317][8] Train_Time=0.661, Train_Speed=193.741 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [318][8] Train_Time=0.666, Train_Speed=192.303 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [319][8] Train_Time=0.666, Train_Speed=192.296 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [320][8] Train_Time=0.664, Train_Speed=192.847 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.18e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00634  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0176   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00531  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00206  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000707 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00621  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0171   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00527  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00204  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000698 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.11e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 320      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000129 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00047  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.91e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.79e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 8.73e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.421\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.497\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [321][8] Train_Time=0.643, Train_Speed=199.134 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [322][8] Train_Time=0.646, Train_Speed=198.002 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [323][8] Train_Time=0.637, Train_Speed=200.798 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [324][8] Train_Time=0.636, Train_Speed=201.291 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [325][8] Train_Time=0.628, Train_Speed=203.930 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [326][8] Train_Time=0.627, Train_Speed=204.238 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [327][8] Train_Time=0.656, Train_Speed=195.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [328][8] Train_Time=0.664, Train_Speed=192.627 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [329][8] Train_Time=0.626, Train_Speed=204.390 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [330][8] Train_Time=0.639, Train_Speed=200.205 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.72e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00554  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0144   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00524  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00167  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000675 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00543  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.014    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0052   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00165  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000666 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.24e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 330      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000114 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000393 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.91e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.53e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 8.43e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.394\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.476\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [331][8] Train_Time=0.580, Train_Speed=220.686 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [332][8] Train_Time=0.636, Train_Speed=201.227 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [333][8] Train_Time=0.649, Train_Speed=197.309 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [334][8] Train_Time=0.648, Train_Speed=197.578 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [335][8] Train_Time=0.650, Train_Speed=196.856 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [336][8] Train_Time=0.609, Train_Speed=210.301 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [337][8] Train_Time=0.633, Train_Speed=202.199 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [338][8] Train_Time=0.625, Train_Speed=204.654 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [339][8] Train_Time=0.649, Train_Speed=197.326 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [340][8] Train_Time=0.657, Train_Speed=194.767 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.26e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00725  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0287   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00502  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00137  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000609 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00596  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0219   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00499  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000601 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.36e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 340      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00129  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00678  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.68e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.61e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.429\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.567\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [341][8] Train_Time=0.564, Train_Speed=226.972 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [342][8] Train_Time=0.648, Train_Speed=197.564 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [343][8] Train_Time=0.646, Train_Speed=198.154 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [344][8] Train_Time=0.665, Train_Speed=192.343 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [345][8] Train_Time=0.644, Train_Speed=198.695 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [346][8] Train_Time=0.661, Train_Speed=193.754 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [347][8] Train_Time=0.648, Train_Speed=197.611 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [348][8] Train_Time=0.608, Train_Speed=210.506 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [349][8] Train_Time=0.646, Train_Speed=198.262 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [350][8] Train_Time=0.666, Train_Speed=192.182 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.89e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00884  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0256   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00489  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00159  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000606 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0083   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0237   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00485  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00157  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000599 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.49e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 350      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000546 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00193  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.43e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.32e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.404\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.707\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [351][8] Train_Time=0.584, Train_Speed=219.179 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [352][8] Train_Time=0.667, Train_Speed=191.844 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [353][8] Train_Time=0.670, Train_Speed=191.026 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [354][8] Train_Time=0.669, Train_Speed=191.400 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [355][8] Train_Time=0.666, Train_Speed=192.082 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [356][8] Train_Time=0.670, Train_Speed=191.136 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [357][8] Train_Time=0.665, Train_Speed=192.515 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [358][8] Train_Time=0.646, Train_Speed=198.269 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [359][8] Train_Time=0.650, Train_Speed=197.041 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [360][8] Train_Time=0.644, Train_Speed=198.634 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.29e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0233   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.155    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00511  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00188  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000703 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0067   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0343   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00508  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00187  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000694 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.62e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 360      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0166   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.12     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.82e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.7e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 8.78e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.439\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.504\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [361][8] Train_Time=0.586, Train_Speed=218.425 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [362][8] Train_Time=0.668, Train_Speed=191.706 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [363][8] Train_Time=0.667, Train_Speed=191.858 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [364][8] Train_Time=0.660, Train_Speed=194.081 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [365][8] Train_Time=0.667, Train_Speed=191.829 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [366][8] Train_Time=0.635, Train_Speed=201.549 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [367][8] Train_Time=0.633, Train_Speed=202.105 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [368][8] Train_Time=0.656, Train_Speed=195.049 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [369][8] Train_Time=0.666, Train_Speed=192.324 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [370][8] Train_Time=0.644, Train_Speed=198.616 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.73e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00991  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0234   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00543  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00194  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000738 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00815  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0184   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0054   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00193  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000729 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.75e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 370      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00177  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00501  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.99e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.72e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 9.08e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.363\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.561\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [371][8] Train_Time=0.558, Train_Speed=229.211 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [372][8] Train_Time=0.640, Train_Speed=199.923 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [373][8] Train_Time=0.660, Train_Speed=194.027 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [374][8] Train_Time=0.667, Train_Speed=191.983 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [375][8] Train_Time=0.668, Train_Speed=191.727 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [376][8] Train_Time=0.666, Train_Speed=192.050 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [377][8] Train_Time=0.669, Train_Speed=191.363 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [378][8] Train_Time=0.621, Train_Speed=206.040 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [379][8] Train_Time=0.644, Train_Speed=198.783 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [380][8] Train_Time=0.648, Train_Speed=197.647 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.4e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0089   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0198   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00441  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00135  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000578 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00766  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0166   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00438  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00057  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 4.88e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 380      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00123  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00326  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.22e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.47e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.470\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.507\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [381][8] Train_Time=0.578, Train_Speed=221.330 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [382][8] Train_Time=0.666, Train_Speed=192.306 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [383][8] Train_Time=0.629, Train_Speed=203.560 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [384][8] Train_Time=0.650, Train_Speed=196.850 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [385][8] Train_Time=0.637, Train_Speed=201.000 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [386][8] Train_Time=0.647, Train_Speed=197.825 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [387][8] Train_Time=0.638, Train_Speed=200.778 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [388][8] Train_Time=0.620, Train_Speed=206.460 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [389][8] Train_Time=0.631, Train_Speed=202.925 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [390][8] Train_Time=0.627, Train_Speed=204.288 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.93e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00595  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0185   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00504  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0013   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000561 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0058   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0178   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.005    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00129  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000553 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5e+04    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 390      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000158 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000664 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.72e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.13e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.453\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.590\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [391][8] Train_Time=0.554, Train_Speed=230.914 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [392][8] Train_Time=0.649, Train_Speed=197.156 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [393][8] Train_Time=0.670, Train_Speed=191.134 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [394][8] Train_Time=0.666, Train_Speed=192.171 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [395][8] Train_Time=0.667, Train_Speed=191.794 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [396][8] Train_Time=0.668, Train_Speed=191.486 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [397][8] Train_Time=0.669, Train_Speed=191.427 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [398][8] Train_Time=0.664, Train_Speed=192.897 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [399][8] Train_Time=0.665, Train_Speed=192.593 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [400][8] Train_Time=0.664, Train_Speed=192.812 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.19e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00685  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0237   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00522  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00209  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000553 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00631  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0211   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00518  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00207  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000546 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.13e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 400      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000542 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00263  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.83e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.82e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.07e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.440\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.544\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=28.630\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.070\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.070\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.071\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.526\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [401][8] Train_Time=0.584, Train_Speed=219.263 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [402][8] Train_Time=0.646, Train_Speed=198.237 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [403][8] Train_Time=0.650, Train_Speed=196.970 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [404][8] Train_Time=0.631, Train_Speed=202.932 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [405][8] Train_Time=0.647, Train_Speed=197.700 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [406][8] Train_Time=0.670, Train_Speed=191.030 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [407][8] Train_Time=0.673, Train_Speed=190.272 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [408][8] Train_Time=0.671, Train_Speed=190.737 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [409][8] Train_Time=0.677, Train_Speed=189.126 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [410][8] Train_Time=0.664, Train_Speed=192.875 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.13e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00582  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0164   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00452  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00168  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000543 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00565  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0158   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00448  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00166  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000536 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.26e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 410      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000171 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000602 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.5e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.91e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.433\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.471\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [411][8] Train_Time=0.584, Train_Speed=219.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [412][8] Train_Time=0.669, Train_Speed=191.425 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [413][8] Train_Time=0.663, Train_Speed=193.116 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [414][8] Train_Time=0.651, Train_Speed=196.486 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [415][8] Train_Time=0.644, Train_Speed=198.651 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [416][8] Train_Time=0.651, Train_Speed=196.585 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [417][8] Train_Time=0.632, Train_Speed=202.684 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [418][8] Train_Time=0.664, Train_Speed=192.898 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [419][8] Train_Time=0.665, Train_Speed=192.557 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [420][8] Train_Time=0.650, Train_Speed=196.858 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.32e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0041   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0114   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00502  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00154  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000558 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00406  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0113   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00499  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00152  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000551 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.39e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 420      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 3.76e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000121 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.7e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.4e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.8e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.559\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.586\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [421][8] Train_Time=0.580, Train_Speed=220.811 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [422][8] Train_Time=0.646, Train_Speed=198.053 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [423][8] Train_Time=0.668, Train_Speed=191.620 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [424][8] Train_Time=0.667, Train_Speed=191.790 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [425][8] Train_Time=0.692, Train_Speed=184.887 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [426][8] Train_Time=0.679, Train_Speed=188.588 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [427][8] Train_Time=0.669, Train_Speed=191.343 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [428][8] Train_Time=0.655, Train_Speed=195.285 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [429][8] Train_Time=0.643, Train_Speed=199.159 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [430][8] Train_Time=0.669, Train_Speed=191.373 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.56e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0259   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.136    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00483  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00166  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00054  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0074   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.03     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0048   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00164  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000533 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.52e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 430      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0185   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.106    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.56e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.44e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.84e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.398\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.479\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [431][8] Train_Time=0.583, Train_Speed=219.462 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [432][8] Train_Time=0.672, Train_Speed=190.339 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [433][8] Train_Time=0.673, Train_Speed=190.162 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [434][8] Train_Time=0.673, Train_Speed=190.169 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [435][8] Train_Time=0.670, Train_Speed=190.976 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [436][8] Train_Time=0.678, Train_Speed=188.657 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [437][8] Train_Time=0.671, Train_Speed=190.621 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [438][8] Train_Time=0.670, Train_Speed=191.066 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [439][8] Train_Time=0.661, Train_Speed=193.521 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [440][8] Train_Time=0.666, Train_Speed=192.128 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 9.54e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00662  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0152   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00369  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00195  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000577 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0065   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0149   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00366  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00194  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00057  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.64e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 440      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000117 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000312 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.72e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.69e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.98e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.473\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.502\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [441][8] Train_Time=0.576, Train_Speed=222.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [442][8] Train_Time=0.627, Train_Speed=204.217 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [443][8] Train_Time=0.645, Train_Speed=198.419 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [444][8] Train_Time=0.647, Train_Speed=197.761 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [445][8] Train_Time=0.655, Train_Speed=195.482 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [446][8] Train_Time=0.623, Train_Speed=205.449 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [447][8] Train_Time=0.616, Train_Speed=207.866 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [448][8] Train_Time=0.639, Train_Speed=200.236 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [449][8] Train_Time=0.644, Train_Speed=198.901 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [450][8] Train_Time=0.662, Train_Speed=193.403 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.2e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00671  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0174   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00446  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00159  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000565 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00653  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0169   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00443  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00158  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000558 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.77e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 450      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000182 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000567 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.45e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 7.13e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.461\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.497\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [451][8] Train_Time=0.578, Train_Speed=221.270 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [452][8] Train_Time=0.624, Train_Speed=205.135 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [453][8] Train_Time=0.667, Train_Speed=191.845 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [454][8] Train_Time=0.666, Train_Speed=192.063 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [455][8] Train_Time=0.669, Train_Speed=191.288 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [456][8] Train_Time=0.630, Train_Speed=203.186 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [457][8] Train_Time=0.663, Train_Speed=192.964 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [458][8] Train_Time=0.663, Train_Speed=192.959 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [459][8] Train_Time=0.663, Train_Speed=192.993 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [460][8] Train_Time=0.671, Train_Speed=190.781 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.47e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00519  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00451  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00189  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00056  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00507  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0134   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00447  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00188  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000553 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 5.9e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 460      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000113 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000395 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.69e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.89e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.514\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.527\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [461][8] Train_Time=0.599, Train_Speed=213.779 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [462][8] Train_Time=0.665, Train_Speed=192.346 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [463][8] Train_Time=0.665, Train_Speed=192.531 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [464][8] Train_Time=0.670, Train_Speed=191.169 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [465][8] Train_Time=0.667, Train_Speed=191.888 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [466][8] Train_Time=0.653, Train_Speed=196.140 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [467][8] Train_Time=0.654, Train_Speed=195.738 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [468][8] Train_Time=0.999, Train_Speed=128.064 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [469][8] Train_Time=0.652, Train_Speed=196.446 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [470][8] Train_Time=0.651, Train_Speed=196.562 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.37e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00816  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0193   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00499  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00144  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000545 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00784  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0184   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00495  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00143  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000538 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.03e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 470      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000325 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000924 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.68e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.62e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.478\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.486\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [471][8] Train_Time=0.572, Train_Speed=223.774 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [472][8] Train_Time=0.666, Train_Speed=192.116 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [473][8] Train_Time=0.664, Train_Speed=192.631 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [474][8] Train_Time=0.666, Train_Speed=192.217 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [475][8] Train_Time=0.666, Train_Speed=192.284 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [476][8] Train_Time=0.666, Train_Speed=192.150 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [477][8] Train_Time=0.668, Train_Speed=191.514 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [478][8] Train_Time=0.665, Train_Speed=192.460 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [479][8] Train_Time=0.675, Train_Speed=189.648 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [480][8] Train_Time=0.678, Train_Speed=188.733 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.67e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00535  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.014    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00432  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00158  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000516 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00527  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00429  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00157  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00051  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.16e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 480      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 8.09e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000249 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.43e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.45e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.450\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.496\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [481][8] Train_Time=0.635, Train_Speed=201.595 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [482][8] Train_Time=0.681, Train_Speed=187.893 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [483][8] Train_Time=0.678, Train_Speed=188.869 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [484][8] Train_Time=0.674, Train_Speed=189.938 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [485][8] Train_Time=0.650, Train_Speed=196.793 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [486][8] Train_Time=0.653, Train_Speed=196.023 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [487][8] Train_Time=0.671, Train_Speed=190.785 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [488][8] Train_Time=0.664, Train_Speed=192.735 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [489][8] Train_Time=0.664, Train_Speed=192.671 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [490][8] Train_Time=0.665, Train_Speed=192.611 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.73e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00581  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0151   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00466  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00147  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000534 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0057   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0147   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00463  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00146  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000527 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.28e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 490      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000114 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000367 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.47e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.33e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.66e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.389\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.509\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [491][8] Train_Time=0.582, Train_Speed=220.017 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [492][8] Train_Time=0.666, Train_Speed=192.295 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [493][8] Train_Time=0.669, Train_Speed=191.406 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [494][8] Train_Time=0.670, Train_Speed=191.165 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [495][8] Train_Time=0.665, Train_Speed=192.471 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [496][8] Train_Time=0.654, Train_Speed=195.834 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [497][8] Train_Time=0.645, Train_Speed=198.429 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [498][8] Train_Time=0.639, Train_Speed=200.259 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [499][8] Train_Time=0.625, Train_Speed=204.779 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [500][8] Train_Time=0.632, Train_Speed=202.544 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.22e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00629  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0145   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00469  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00141  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000532 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00611  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0139   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00465  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000525 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.41e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 500      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000177 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000523 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.47e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.24e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.68e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.604\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.639\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [501][8] Train_Time=0.589, Train_Speed=217.350 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [502][8] Train_Time=0.634, Train_Speed=201.951 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [503][8] Train_Time=0.632, Train_Speed=202.408 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [504][8] Train_Time=0.643, Train_Speed=199.153 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [505][8] Train_Time=0.667, Train_Speed=191.936 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [506][8] Train_Time=0.656, Train_Speed=195.081 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [507][8] Train_Time=0.674, Train_Speed=190.049 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [508][8] Train_Time=0.671, Train_Speed=190.645 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [509][8] Train_Time=0.672, Train_Speed=190.577 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [510][8] Train_Time=0.671, Train_Speed=190.812 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.19e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00666  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0178   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00524  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0014   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000508 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00636  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0167   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00521  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000501 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.54e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 510      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000303 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00105  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.86e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.28e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.53e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.457\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.518\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [511][8] Train_Time=0.584, Train_Speed=219.280 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [512][8] Train_Time=0.650, Train_Speed=196.987 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [513][8] Train_Time=0.647, Train_Speed=197.725 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [514][8] Train_Time=0.646, Train_Speed=198.019 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [515][8] Train_Time=0.665, Train_Speed=192.471 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [516][8] Train_Time=0.662, Train_Speed=193.458 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [517][8] Train_Time=0.644, Train_Speed=198.705 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [518][8] Train_Time=0.669, Train_Speed=191.240 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [519][8] Train_Time=0.672, Train_Speed=190.516 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [520][8] Train_Time=0.670, Train_Speed=190.993 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.96e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00806  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0202   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00439  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00181  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000485 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00755  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0187   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00436  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00179  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000479 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.67e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 520      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000502 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00146  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.59e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.98e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.533\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.713\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [521][8] Train_Time=0.585, Train_Speed=218.618 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [522][8] Train_Time=0.671, Train_Speed=190.626 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [523][8] Train_Time=0.673, Train_Speed=190.201 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [524][8] Train_Time=0.670, Train_Speed=190.966 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [525][8] Train_Time=0.659, Train_Speed=194.279 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [526][8] Train_Time=0.668, Train_Speed=191.524 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [527][8] Train_Time=0.666, Train_Speed=192.072 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [528][8] Train_Time=0.668, Train_Speed=191.652 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [529][8] Train_Time=0.649, Train_Speed=197.272 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [530][8] Train_Time=0.634, Train_Speed=202.027 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.65e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0084   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0322   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00502  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00138  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000514 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00651  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0234   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00498  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00137  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000508 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.8e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 530      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00189  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00883  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.68e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.4e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.509\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.520\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [531][8] Train_Time=0.562, Train_Speed=227.670 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [532][8] Train_Time=0.607, Train_Speed=210.736 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [533][8] Train_Time=0.612, Train_Speed=209.114 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [534][8] Train_Time=0.629, Train_Speed=203.581 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [535][8] Train_Time=0.627, Train_Speed=204.120 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [536][8] Train_Time=0.645, Train_Speed=198.308 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [537][8] Train_Time=0.649, Train_Speed=197.198 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [538][8] Train_Time=0.643, Train_Speed=199.145 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [539][8] Train_Time=0.653, Train_Speed=195.937 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [540][8] Train_Time=0.664, Train_Speed=192.865 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.91e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00542  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0172   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00495  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00146  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000449 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00508  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0155   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00491  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00145  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000443 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 6.92e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 540      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000346 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00165  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.64e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.32e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.76e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.498\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.508\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [541][8] Train_Time=0.585, Train_Speed=218.676 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [542][8] Train_Time=0.668, Train_Speed=191.595 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [543][8] Train_Time=0.669, Train_Speed=191.201 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [544][8] Train_Time=0.669, Train_Speed=191.264 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [545][8] Train_Time=0.656, Train_Speed=195.091 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [546][8] Train_Time=0.621, Train_Speed=206.282 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [547][8] Train_Time=0.646, Train_Speed=198.071 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [548][8] Train_Time=0.654, Train_Speed=195.795 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [549][8] Train_Time=0.608, Train_Speed=210.527 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [550][8] Train_Time=0.610, Train_Speed=209.961 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.13e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.5     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00568  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0141   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00559  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000476 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00558  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00555  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00133  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00047  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.05e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 550      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000101 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000338 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.12e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.25e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.97e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.448\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.605\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [551][8] Train_Time=0.527, Train_Speed=242.868 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [552][8] Train_Time=0.645, Train_Speed=198.331 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [553][8] Train_Time=0.652, Train_Speed=196.462 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [554][8] Train_Time=0.672, Train_Speed=190.367 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [555][8] Train_Time=0.628, Train_Speed=203.889 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [556][8] Train_Time=0.603, Train_Speed=212.327 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [557][8] Train_Time=0.619, Train_Speed=206.928 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [558][8] Train_Time=0.646, Train_Speed=198.245 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [559][8] Train_Time=0.651, Train_Speed=196.483 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [560][8] Train_Time=0.647, Train_Speed=197.788 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.64e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00726  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0222   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0039   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00147  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000466 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00675  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0203   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00387  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00146  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00046  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.18e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 560      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000506 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00188  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.87e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.35e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.92e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.539\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.558\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [561][8] Train_Time=0.577, Train_Speed=221.894 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [562][8] Train_Time=0.636, Train_Speed=201.237 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [563][8] Train_Time=0.665, Train_Speed=192.452 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [564][8] Train_Time=0.671, Train_Speed=190.771 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [565][8] Train_Time=0.663, Train_Speed=192.949 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [566][8] Train_Time=0.624, Train_Speed=205.172 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [567][8] Train_Time=0.634, Train_Speed=202.011 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [568][8] Train_Time=0.665, Train_Speed=192.570 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [569][8] Train_Time=0.667, Train_Speed=191.974 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [570][8] Train_Time=0.664, Train_Speed=192.724 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.55e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00632  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.024    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00409  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00137  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000454 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00586  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0216   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00406  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000448 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.31e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 570      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000463 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00239  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.01e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.25e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.68e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.471\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.513\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [571][8] Train_Time=0.567, Train_Speed=225.603 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [572][8] Train_Time=0.606, Train_Speed=211.185 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [573][8] Train_Time=0.608, Train_Speed=210.612 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [574][8] Train_Time=0.666, Train_Speed=192.191 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [575][8] Train_Time=0.665, Train_Speed=192.512 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [576][8] Train_Time=0.649, Train_Speed=197.206 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [577][8] Train_Time=0.661, Train_Speed=193.547 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [578][8] Train_Time=0.650, Train_Speed=196.916 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [579][8] Train_Time=0.644, Train_Speed=198.903 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [580][8] Train_Time=0.664, Train_Speed=192.721 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.22e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00633  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0156   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00514  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00153  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000436 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00616  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0151   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00511  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00152  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000431 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.44e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 580      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000165 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000506 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.79e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.35e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.4e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.462\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.482\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [581][8] Train_Time=0.584, Train_Speed=219.253 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [582][8] Train_Time=0.651, Train_Speed=196.689 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [583][8] Train_Time=0.661, Train_Speed=193.639 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [584][8] Train_Time=0.662, Train_Speed=193.483 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [585][8] Train_Time=0.662, Train_Speed=193.208 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [586][8] Train_Time=0.657, Train_Speed=194.882 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [587][8] Train_Time=0.632, Train_Speed=202.491 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [588][8] Train_Time=0.638, Train_Speed=200.485 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [589][8] Train_Time=0.635, Train_Speed=201.549 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [590][8] Train_Time=0.655, Train_Speed=195.531 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.39e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00979  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0308   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00438  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00137  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000491 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00795  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0238   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00435  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000485 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.56e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 590      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00184  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00696  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.25e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6e-06    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.547\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.585\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [591][8] Train_Time=0.613, Train_Speed=208.968 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [592][8] Train_Time=0.649, Train_Speed=197.173 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [593][8] Train_Time=0.624, Train_Speed=204.973 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [594][8] Train_Time=0.612, Train_Speed=209.317 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [595][8] Train_Time=0.607, Train_Speed=210.808 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [596][8] Train_Time=0.621, Train_Speed=206.188 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [597][8] Train_Time=0.618, Train_Speed=206.979 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [598][8] Train_Time=0.665, Train_Speed=192.392 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [599][8] Train_Time=0.666, Train_Speed=192.114 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [600][8] Train_Time=0.667, Train_Speed=191.819 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.42e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00624  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0175   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00382  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00152  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000501 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00588  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0163   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00379  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000495 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.69e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 600      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000365 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00123  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.8e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.38e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.33e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.626\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.660\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=29.000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.622\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.628\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.628\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.627\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.967\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.628\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [601][8] Train_Time=0.606, Train_Speed=211.124 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [602][8] Train_Time=0.672, Train_Speed=190.494 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [603][8] Train_Time=0.667, Train_Speed=191.898 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [604][8] Train_Time=0.669, Train_Speed=191.221 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [605][8] Train_Time=0.660, Train_Speed=193.849 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [606][8] Train_Time=0.632, Train_Speed=202.618 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [607][8] Train_Time=0.643, Train_Speed=199.005 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [608][8] Train_Time=0.634, Train_Speed=201.872 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [609][8] Train_Time=0.642, Train_Speed=199.496 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [610][8] Train_Time=0.655, Train_Speed=195.294 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.16e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00662  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0244   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00469  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00159  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00049  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00526  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.018    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00466  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00157  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000484 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.82e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 610      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00634  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.44e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.4e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.16e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.459\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.574\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [611][8] Train_Time=0.588, Train_Speed=217.633 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [612][8] Train_Time=0.670, Train_Speed=191.087 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [613][8] Train_Time=0.668, Train_Speed=191.704 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [614][8] Train_Time=0.667, Train_Speed=191.948 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [615][8] Train_Time=0.653, Train_Speed=196.003 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [616][8] Train_Time=0.644, Train_Speed=198.672 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [617][8] Train_Time=0.652, Train_Speed=196.313 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [618][8] Train_Time=0.631, Train_Speed=203.012 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [619][8] Train_Time=0.641, Train_Speed=199.639 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [620][8] Train_Time=0.665, Train_Speed=192.582 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.58e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00766  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0191   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00475  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00179  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000458 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00739  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0183   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00471  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00178  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000452 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 7.95e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 620      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000272 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000826 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.53e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.57e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.85e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.572\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.573\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [621][8] Train_Time=0.582, Train_Speed=220.022 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [622][8] Train_Time=0.655, Train_Speed=195.429 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [623][8] Train_Time=0.667, Train_Speed=191.789 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [624][8] Train_Time=0.650, Train_Speed=196.908 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [625][8] Train_Time=0.663, Train_Speed=192.969 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [626][8] Train_Time=0.662, Train_Speed=193.412 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [627][8] Train_Time=0.663, Train_Speed=192.932 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [628][8] Train_Time=0.674, Train_Speed=189.996 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [629][8] Train_Time=0.659, Train_Speed=194.095 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [630][8] Train_Time=0.647, Train_Speed=197.712 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.07e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00653  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0187   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00486  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00157  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000497 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00628  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0177   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00483  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00155  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000491 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.08e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 630      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000256 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000963 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.4e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 6.17e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.425\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.521\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [631][8] Train_Time=0.559, Train_Speed=229.034 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [632][8] Train_Time=0.668, Train_Speed=191.580 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [633][8] Train_Time=0.660, Train_Speed=193.861 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [634][8] Train_Time=0.664, Train_Speed=192.771 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [635][8] Train_Time=0.663, Train_Speed=193.191 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [636][8] Train_Time=0.630, Train_Speed=203.282 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [637][8] Train_Time=0.663, Train_Speed=192.946 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [638][8] Train_Time=0.667, Train_Speed=192.005 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [639][8] Train_Time=0.665, Train_Speed=192.347 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [640][8] Train_Time=0.665, Train_Speed=192.597 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.48e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00753  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0227   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00473  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000446 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00702  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0207   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0047   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0015   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000441 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.2e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 640      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000511 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00198  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.44e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.36e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.4e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.600\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.625\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [641][8] Train_Time=0.598, Train_Speed=214.017 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [642][8] Train_Time=0.671, Train_Speed=190.816 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [643][8] Train_Time=0.667, Train_Speed=191.962 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [644][8] Train_Time=0.669, Train_Speed=191.467 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [645][8] Train_Time=0.655, Train_Speed=195.455 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [646][8] Train_Time=0.668, Train_Speed=191.593 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [647][8] Train_Time=0.638, Train_Speed=200.525 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [648][8] Train_Time=0.670, Train_Speed=191.050 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [649][8] Train_Time=0.630, Train_Speed=203.181 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [650][8] Train_Time=0.625, Train_Speed=204.730 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.23e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.6     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00513  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0132   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00486  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00153  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000467 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00499  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0127   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00483  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000461 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.33e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 650      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000139 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000497 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.36e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.79e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.383\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.586\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [651][8] Train_Time=0.553, Train_Speed=231.355 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [652][8] Train_Time=0.617, Train_Speed=207.307 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [653][8] Train_Time=0.627, Train_Speed=204.124 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [654][8] Train_Time=0.632, Train_Speed=202.414 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [655][8] Train_Time=0.662, Train_Speed=193.308 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [656][8] Train_Time=0.664, Train_Speed=192.762 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [657][8] Train_Time=0.655, Train_Speed=195.530 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [658][8] Train_Time=0.646, Train_Speed=198.283 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [659][8] Train_Time=0.631, Train_Speed=202.968 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [660][8] Train_Time=0.628, Train_Speed=203.682 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.65e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00483  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.017    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00424  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00177  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000398 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00473  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0165   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00421  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00175  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000393 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.46e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 660      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000101 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000469 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.08e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.54e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.09e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.536\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.557\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [661][8] Train_Time=0.613, Train_Speed=208.646 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [662][8] Train_Time=0.666, Train_Speed=192.331 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [663][8] Train_Time=0.632, Train_Speed=202.517 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [664][8] Train_Time=0.639, Train_Speed=200.213 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [665][8] Train_Time=0.645, Train_Speed=198.304 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [666][8] Train_Time=0.640, Train_Speed=199.994 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [667][8] Train_Time=0.638, Train_Speed=200.725 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [668][8] Train_Time=0.644, Train_Speed=198.626 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [669][8] Train_Time=0.642, Train_Speed=199.476 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [670][8] Train_Time=0.652, Train_Speed=196.397 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.77e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0256   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0979   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00346  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000425 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00752  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0257   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00343  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00133  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00042  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.59e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 670      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0181   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0722   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.54e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.17e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.564\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.575\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [671][8] Train_Time=0.582, Train_Speed=219.977 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [672][8] Train_Time=0.655, Train_Speed=195.297 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [673][8] Train_Time=0.642, Train_Speed=199.237 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [674][8] Train_Time=0.630, Train_Speed=203.320 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [675][8] Train_Time=0.665, Train_Speed=192.575 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [676][8] Train_Time=0.632, Train_Speed=202.536 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [677][8] Train_Time=0.631, Train_Speed=202.848 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [678][8] Train_Time=0.611, Train_Speed=209.614 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [679][8] Train_Time=0.633, Train_Speed=202.290 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [680][8] Train_Time=0.630, Train_Speed=203.266 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.08e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00732  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0252   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00455  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00161  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000389 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00699  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0238   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00452  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0016   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000384 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.72e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 680      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000326 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.38e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.41e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5e-06    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.449\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.666\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [681][8] Train_Time=0.566, Train_Speed=226.193 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [682][8] Train_Time=0.645, Train_Speed=198.334 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [683][8] Train_Time=0.644, Train_Speed=198.886 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [684][8] Train_Time=0.640, Train_Speed=200.036 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [685][8] Train_Time=0.671, Train_Speed=190.693 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [686][8] Train_Time=0.671, Train_Speed=190.886 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [687][8] Train_Time=0.667, Train_Speed=191.840 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [688][8] Train_Time=0.669, Train_Speed=191.422 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [689][8] Train_Time=0.671, Train_Speed=190.798 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [690][8] Train_Time=0.670, Train_Speed=190.912 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.8e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00472  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0139   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00565  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00156  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000427 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00463  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0136   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00561  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00154  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000421 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.84e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 690      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 8.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000351 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.37e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.37e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.550\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.578\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [691][8] Train_Time=0.609, Train_Speed=210.300 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [692][8] Train_Time=0.669, Train_Speed=191.375 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [693][8] Train_Time=0.670, Train_Speed=191.123 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [694][8] Train_Time=0.670, Train_Speed=191.165 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [695][8] Train_Time=0.669, Train_Speed=191.294 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [696][8] Train_Time=0.665, Train_Speed=192.392 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [697][8] Train_Time=0.649, Train_Speed=197.104 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [698][8] Train_Time=0.664, Train_Speed=192.746 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [699][8] Train_Time=0.649, Train_Speed=197.094 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [700][8] Train_Time=0.636, Train_Speed=201.208 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.11e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00846  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0273   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00496  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00156  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000403 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0075   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0234   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00492  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00155  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000398 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 8.97e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 700      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000958 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00397  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.64e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.38e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.09e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.513\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.578\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [701][8] Train_Time=0.613, Train_Speed=208.971 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [702][8] Train_Time=0.650, Train_Speed=197.030 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [703][8] Train_Time=0.643, Train_Speed=199.009 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [704][8] Train_Time=0.639, Train_Speed=200.430 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [705][8] Train_Time=0.632, Train_Speed=202.381 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [706][8] Train_Time=0.661, Train_Speed=193.543 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [707][8] Train_Time=0.663, Train_Speed=192.992 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [708][8] Train_Time=0.646, Train_Speed=198.152 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [709][8] Train_Time=0.648, Train_Speed=197.660 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [710][8] Train_Time=0.667, Train_Speed=191.949 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.38e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00516  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0143   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00471  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00135  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000419 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00504  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0139   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00467  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000414 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.1e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 710      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000119 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000461 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.44e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.16e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.457\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.483\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [711][8] Train_Time=0.602, Train_Speed=212.452 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [712][8] Train_Time=0.647, Train_Speed=197.694 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [713][8] Train_Time=0.622, Train_Speed=205.670 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [714][8] Train_Time=0.672, Train_Speed=190.343 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [715][8] Train_Time=0.623, Train_Speed=205.355 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [716][8] Train_Time=0.619, Train_Speed=206.922 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [717][8] Train_Time=0.631, Train_Speed=202.851 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [718][8] Train_Time=0.637, Train_Speed=201.059 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [719][8] Train_Time=0.640, Train_Speed=199.896 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [720][8] Train_Time=0.655, Train_Speed=195.347 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.17e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00602  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0185   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00429  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00154  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000357 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00584  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0178   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00426  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00153  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000352 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.23e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 720      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00018  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000701 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.39e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.66e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.516\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.522\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [721][8] Train_Time=0.595, Train_Speed=215.290 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [722][8] Train_Time=0.632, Train_Speed=202.640 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [723][8] Train_Time=0.644, Train_Speed=198.783 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [724][8] Train_Time=0.624, Train_Speed=205.000 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [725][8] Train_Time=0.642, Train_Speed=199.451 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [726][8] Train_Time=0.636, Train_Speed=201.228 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [727][8] Train_Time=0.627, Train_Speed=204.148 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [728][8] Train_Time=0.668, Train_Speed=191.718 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [729][8] Train_Time=0.659, Train_Speed=194.191 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [730][8] Train_Time=0.663, Train_Speed=193.111 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.09e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00414  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0127   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00426  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00145  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000398 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00409  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0125   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00423  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00144  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000393 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.36e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 730      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 5.21e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00022  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.13e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.28e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.1e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.518\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.588\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [731][8] Train_Time=0.580, Train_Speed=220.692 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [732][8] Train_Time=0.663, Train_Speed=192.931 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [733][8] Train_Time=0.641, Train_Speed=199.533 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [734][8] Train_Time=0.635, Train_Speed=201.700 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [735][8] Train_Time=0.668, Train_Speed=191.595 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [736][8] Train_Time=0.665, Train_Speed=192.612 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [737][8] Train_Time=0.656, Train_Speed=195.267 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [738][8] Train_Time=0.649, Train_Speed=197.180 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [739][8] Train_Time=0.660, Train_Speed=193.836 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [740][8] Train_Time=0.664, Train_Speed=192.871 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.62e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00518  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0139   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00414  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00123  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000399 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00509  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0136   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00411  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00122  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000394 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.48e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 740      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 9.16e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000293 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.14e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.89e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.631\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.644\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [741][8] Train_Time=0.597, Train_Speed=214.296 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [742][8] Train_Time=0.675, Train_Speed=189.639 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [743][8] Train_Time=0.674, Train_Speed=189.942 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [744][8] Train_Time=0.675, Train_Speed=189.613 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [745][8] Train_Time=0.667, Train_Speed=191.767 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [746][8] Train_Time=0.668, Train_Speed=191.620 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [747][8] Train_Time=0.637, Train_Speed=201.047 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [748][8] Train_Time=0.634, Train_Speed=201.958 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [749][8] Train_Time=0.649, Train_Speed=197.292 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [750][8] Train_Time=0.652, Train_Speed=196.429 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.42e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.7     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00345  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0112   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.004    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00165  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000407 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0034   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.011    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00397  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00164  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000402 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.61e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 750      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 4.22e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000187 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.92e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.45e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.98e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.498\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.564\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [751][8] Train_Time=0.561, Train_Speed=227.979 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [752][8] Train_Time=0.653, Train_Speed=196.034 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [753][8] Train_Time=0.653, Train_Speed=195.924 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [754][8] Train_Time=0.667, Train_Speed=191.999 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [755][8] Train_Time=0.655, Train_Speed=195.569 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [756][8] Train_Time=0.659, Train_Speed=194.215 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [757][8] Train_Time=0.637, Train_Speed=200.813 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [758][8] Train_Time=0.642, Train_Speed=199.255 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [759][8] Train_Time=0.648, Train_Speed=197.615 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [760][8] Train_Time=0.662, Train_Speed=193.330 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.1e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00539  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0142   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00456  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00129  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000423 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00529  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0139   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00453  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00128  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000418 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.74e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 760      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000102 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000327 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.36e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.02e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.461\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.514\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [761][8] Train_Time=0.573, Train_Speed=223.215 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [762][8] Train_Time=0.678, Train_Speed=188.784 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [763][8] Train_Time=0.674, Train_Speed=190.017 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [764][8] Train_Time=0.647, Train_Speed=197.927 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [765][8] Train_Time=0.669, Train_Speed=191.263 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [766][8] Train_Time=0.647, Train_Speed=197.876 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [767][8] Train_Time=0.666, Train_Speed=192.150 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [768][8] Train_Time=0.677, Train_Speed=189.084 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [769][8] Train_Time=0.682, Train_Speed=187.762 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [770][8] Train_Time=0.680, Train_Speed=188.200 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.76e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00614  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0218   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00433  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00161  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000415 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00556  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0189   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0043   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00159  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00041  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 9.87e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 770      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000584 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00285  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.4e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.28e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.591\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.610\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [771][8] Train_Time=0.614, Train_Speed=208.488 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [772][8] Train_Time=0.679, Train_Speed=188.468 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [773][8] Train_Time=0.680, Train_Speed=188.213 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [774][8] Train_Time=0.680, Train_Speed=188.262 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [775][8] Train_Time=0.680, Train_Speed=188.255 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [776][8] Train_Time=0.681, Train_Speed=187.987 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [777][8] Train_Time=0.682, Train_Speed=187.608 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [778][8] Train_Time=0.679, Train_Speed=188.592 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [779][8] Train_Time=0.681, Train_Speed=187.845 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [780][8] Train_Time=0.673, Train_Speed=190.226 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.68e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00441  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00461  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00118  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000465 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00432  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0134   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00458  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00117  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000459 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1e+05    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 780      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 8.82e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000375 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.4e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.07e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.59e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.459\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.680\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [781][8] Train_Time=0.542, Train_Speed=236.241 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [782][8] Train_Time=0.663, Train_Speed=193.074 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [783][8] Train_Time=0.670, Train_Speed=191.092 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [784][8] Train_Time=0.669, Train_Speed=191.325 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [785][8] Train_Time=0.670, Train_Speed=191.050 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [786][8] Train_Time=0.669, Train_Speed=191.236 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [787][8] Train_Time=0.667, Train_Speed=191.834 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [788][8] Train_Time=0.668, Train_Speed=191.623 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [789][8] Train_Time=0.670, Train_Speed=191.176 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [790][8] Train_Time=0.664, Train_Speed=192.633 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8e+04    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.025    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.103    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00499  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00162  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000351 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00646  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0212   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00495  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0016   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000347 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.01e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 790      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0185   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0821   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.66e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.4e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.43e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.465\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.505\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [791][8] Train_Time=0.616, Train_Speed=207.933 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [792][8] Train_Time=0.636, Train_Speed=201.187 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [793][8] Train_Time=0.633, Train_Speed=202.267 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [794][8] Train_Time=0.677, Train_Speed=189.069 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [795][8] Train_Time=0.675, Train_Speed=189.629 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [796][8] Train_Time=0.668, Train_Speed=191.606 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [797][8] Train_Time=0.669, Train_Speed=191.370 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [798][8] Train_Time=0.654, Train_Speed=195.639 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [799][8] Train_Time=0.652, Train_Speed=196.329 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [800][8] Train_Time=0.670, Train_Speed=190.953 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.67e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00798  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0216   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00429  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000392 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00668  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0175   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00426  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0015   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000387 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.03e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 800      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00415  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.33e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.99e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.463\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.616\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=28.810\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.428\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.428\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.427\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.963\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [801][8] Train_Time=0.605, Train_Speed=211.578 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [802][8] Train_Time=0.634, Train_Speed=201.829 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [803][8] Train_Time=0.670, Train_Speed=191.047 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [804][8] Train_Time=0.670, Train_Speed=190.919 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [805][8] Train_Time=0.668, Train_Speed=191.569 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [806][8] Train_Time=0.669, Train_Speed=191.319 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [807][8] Train_Time=0.671, Train_Speed=190.681 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [808][8] Train_Time=0.648, Train_Speed=197.582 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [809][8] Train_Time=0.661, Train_Speed=193.565 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [810][8] Train_Time=0.661, Train_Speed=193.655 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.79e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0055   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0176   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00401  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00104  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000403 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00513  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.016    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00398  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00103  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000398 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.04e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 810      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000362 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00155  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.97e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 9.93e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.09e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.442\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.635\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [811][8] Train_Time=0.571, Train_Speed=224.320 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [812][8] Train_Time=0.612, Train_Speed=209.245 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [813][8] Train_Time=0.640, Train_Speed=200.137 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [814][8] Train_Time=0.669, Train_Speed=191.428 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [815][8] Train_Time=0.624, Train_Speed=205.176 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [816][8] Train_Time=0.669, Train_Speed=191.287 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [817][8] Train_Time=0.669, Train_Speed=191.287 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [818][8] Train_Time=0.666, Train_Speed=192.181 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [819][8] Train_Time=0.669, Train_Speed=191.254 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [820][8] Train_Time=0.670, Train_Speed=190.990 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.77e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0258   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.107    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0043   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00167  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000368 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00741  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.025    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00427  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00166  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000364 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.05e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 820      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0184   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0819   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.15e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.46e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.63e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.552\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.571\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [821][8] Train_Time=0.595, Train_Speed=215.063 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [822][8] Train_Time=0.671, Train_Speed=190.873 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [823][8] Train_Time=0.670, Train_Speed=190.927 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [824][8] Train_Time=0.670, Train_Speed=191.009 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [825][8] Train_Time=0.671, Train_Speed=190.793 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [826][8] Train_Time=0.670, Train_Speed=191.142 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [827][8] Train_Time=0.668, Train_Speed=191.617 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [828][8] Train_Time=0.644, Train_Speed=198.676 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [829][8] Train_Time=0.639, Train_Speed=200.370 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [830][8] Train_Time=0.646, Train_Speed=198.119 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.08e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00774  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0214   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00559  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00152  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000391 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00731  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.02     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00555  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000386 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.06e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 830      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000429 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.15e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.37e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.85e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.531\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.536\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [831][8] Train_Time=0.595, Train_Speed=215.237 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [832][8] Train_Time=0.661, Train_Speed=193.544 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [833][8] Train_Time=0.647, Train_Speed=197.696 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [834][8] Train_Time=0.673, Train_Speed=190.065 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [835][8] Train_Time=0.658, Train_Speed=194.549 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [836][8] Train_Time=0.609, Train_Speed=210.106 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [837][8] Train_Time=0.615, Train_Speed=208.004 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [838][8] Train_Time=0.638, Train_Speed=200.485 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [839][8] Train_Time=0.625, Train_Speed=204.929 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [840][8] Train_Time=0.628, Train_Speed=203.778 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.52e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00559  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00434  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00156  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000423 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00549  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0135   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00431  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00155  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000418 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.08e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 840      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000105 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000311 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.34e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.22e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.502\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.617\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [841][8] Train_Time=0.659, Train_Speed=194.111 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [842][8] Train_Time=0.669, Train_Speed=191.386 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [843][8] Train_Time=0.663, Train_Speed=193.192 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [844][8] Train_Time=0.666, Train_Speed=192.060 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [845][8] Train_Time=0.667, Train_Speed=191.919 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [846][8] Train_Time=0.657, Train_Speed=194.968 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [847][8] Train_Time=0.641, Train_Speed=199.769 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [848][8] Train_Time=0.645, Train_Speed=198.564 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [849][8] Train_Time=0.669, Train_Speed=191.244 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [850][8] Train_Time=0.674, Train_Speed=190.013 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.18e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.8     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00492  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.013    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00463  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00149  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000407 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00484  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0127   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0046   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00147  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000402 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.09e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 850      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 8.8e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000298 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.41e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.34e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.15e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.471\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.589\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [851][8] Train_Time=0.583, Train_Speed=219.455 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [852][8] Train_Time=0.664, Train_Speed=192.777 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [853][8] Train_Time=0.666, Train_Speed=192.095 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [854][8] Train_Time=0.663, Train_Speed=192.919 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [855][8] Train_Time=0.649, Train_Speed=197.194 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [856][8] Train_Time=0.635, Train_Speed=201.696 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [857][8] Train_Time=0.649, Train_Speed=197.257 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [858][8] Train_Time=0.653, Train_Speed=195.952 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [859][8] Train_Time=0.630, Train_Speed=203.121 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [860][8] Train_Time=0.663, Train_Speed=193.132 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.05e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00759  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0188   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00448  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00148  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000391 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00717  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0175   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00444  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00147  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000386 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.1e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 860      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000422 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00126  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.33e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.84e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.508\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.547\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [861][8] Train_Time=0.583, Train_Speed=219.633 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [862][8] Train_Time=0.662, Train_Speed=193.490 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [863][8] Train_Time=0.664, Train_Speed=192.821 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [864][8] Train_Time=0.660, Train_Speed=193.853 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [865][8] Train_Time=0.663, Train_Speed=192.979 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [866][8] Train_Time=0.663, Train_Speed=193.149 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [867][8] Train_Time=0.653, Train_Speed=195.903 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [868][8] Train_Time=0.665, Train_Speed=192.536 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [869][8] Train_Time=0.664, Train_Speed=192.751 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [870][8] Train_Time=0.641, Train_Speed=199.821 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.24e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00333  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0123   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00403  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00119  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000388 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00329  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0121   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.004    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00118  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000383 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.11e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 870      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 4.02e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000207 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.97e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.11e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.69e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.451\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.710\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [871][8] Train_Time=0.553, Train_Speed=231.541 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [872][8] Train_Time=0.629, Train_Speed=203.601 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [873][8] Train_Time=0.645, Train_Speed=198.497 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [874][8] Train_Time=0.628, Train_Speed=203.918 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [875][8] Train_Time=0.627, Train_Speed=203.997 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [876][8] Train_Time=0.648, Train_Speed=197.393 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [877][8] Train_Time=0.651, Train_Speed=196.587 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [878][8] Train_Time=0.634, Train_Speed=201.873 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [879][8] Train_Time=0.640, Train_Speed=199.905 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [880][8] Train_Time=0.627, Train_Speed=204.002 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.59e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00914  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0324   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00434  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00152  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000383 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00712  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0235   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00431  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00151  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000378 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.13e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 880      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00202  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00892  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.16e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.35e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.81e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.436\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.482\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [881][8] Train_Time=0.557, Train_Speed=229.636 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [882][8] Train_Time=0.645, Train_Speed=198.321 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [883][8] Train_Time=0.650, Train_Speed=197.023 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [884][8] Train_Time=0.646, Train_Speed=197.995 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [885][8] Train_Time=0.647, Train_Speed=197.684 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [886][8] Train_Time=0.645, Train_Speed=198.339 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [887][8] Train_Time=0.646, Train_Speed=197.991 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [888][8] Train_Time=0.659, Train_Speed=194.150 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [889][8] Train_Time=0.663, Train_Speed=193.082 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [890][8] Train_Time=0.656, Train_Speed=195.088 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.63e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00612  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0141   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00515  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00158  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000485 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00595  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0136   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00511  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00157  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000479 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.14e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 890      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000167 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000492 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.8e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.41e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.98e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.540\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.649\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [891][8] Train_Time=0.558, Train_Speed=229.223 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [892][8] Train_Time=0.662, Train_Speed=193.402 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [893][8] Train_Time=0.664, Train_Speed=192.838 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [894][8] Train_Time=0.664, Train_Speed=192.720 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [895][8] Train_Time=0.653, Train_Speed=196.082 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [896][8] Train_Time=0.664, Train_Speed=192.635 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [897][8] Train_Time=0.672, Train_Speed=190.531 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [898][8] Train_Time=0.624, Train_Speed=205.246 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [899][8] Train_Time=0.632, Train_Speed=202.484 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [900][8] Train_Time=0.669, Train_Speed=191.456 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.58e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00629  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0195   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00369  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00142  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.0004   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00568  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0171   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00367  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00141  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000395 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.15e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 900      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000607 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00238  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.72e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.26e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.09e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.573\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.576\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [901][8] Train_Time=0.595, Train_Speed=214.955 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [902][8] Train_Time=0.627, Train_Speed=204.270 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [903][8] Train_Time=0.669, Train_Speed=191.193 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [904][8] Train_Time=0.670, Train_Speed=191.023 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [905][8] Train_Time=0.668, Train_Speed=191.640 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [906][8] Train_Time=0.654, Train_Speed=195.632 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [907][8] Train_Time=0.612, Train_Speed=209.058 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [908][8] Train_Time=0.669, Train_Speed=191.423 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [909][8] Train_Time=0.666, Train_Speed=192.287 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [910][8] Train_Time=0.667, Train_Speed=191.885 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.22e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00454  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0154   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00455  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00148  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000374 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00441  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0148   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00452  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00147  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000369 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.17e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 910      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000121 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000611 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.35e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.3e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.61e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.510\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.608\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [911][8] Train_Time=0.586, Train_Speed=218.413 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [912][8] Train_Time=0.639, Train_Speed=200.219 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [913][8] Train_Time=0.670, Train_Speed=191.155 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [914][8] Train_Time=0.655, Train_Speed=195.335 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [915][8] Train_Time=0.657, Train_Speed=194.722 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [916][8] Train_Time=0.658, Train_Speed=194.630 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [917][8] Train_Time=0.662, Train_Speed=193.291 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [918][8] Train_Time=0.660, Train_Speed=194.000 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [919][8] Train_Time=0.658, Train_Speed=194.390 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [920][8] Train_Time=0.651, Train_Speed=196.645 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.2e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0442   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.155    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00447  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00132  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000358 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00842  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0247   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00443  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000353 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.18e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 920      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0358   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.13     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.19e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.48e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.422\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.556\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [921][8] Train_Time=0.583, Train_Speed=219.696 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [922][8] Train_Time=0.642, Train_Speed=199.403 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [923][8] Train_Time=0.643, Train_Speed=198.924 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [924][8] Train_Time=0.638, Train_Speed=200.628 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [925][8] Train_Time=0.628, Train_Speed=203.719 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [926][8] Train_Time=0.641, Train_Speed=199.630 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [927][8] Train_Time=0.646, Train_Speed=198.050 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [928][8] Train_Time=0.643, Train_Speed=198.990 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [929][8] Train_Time=0.647, Train_Speed=197.846 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [930][8] Train_Time=0.641, Train_Speed=199.835 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.87e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00462  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0151   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00399  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0015   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000382 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0045   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0146   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00396  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00149  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000377 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.19e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 930      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000113 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000479 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.92e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.35e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.75e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.506\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.508\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [931][8] Train_Time=0.594, Train_Speed=215.634 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [932][8] Train_Time=0.638, Train_Speed=200.493 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [933][8] Train_Time=0.644, Train_Speed=198.866 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [934][8] Train_Time=0.615, Train_Speed=208.256 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [935][8] Train_Time=0.614, Train_Speed=208.462 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [936][8] Train_Time=0.919, Train_Speed=139.292 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [937][8] Train_Time=0.651, Train_Speed=196.714 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [938][8] Train_Time=0.637, Train_Speed=200.840 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [939][8] Train_Time=0.652, Train_Speed=196.421 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [940][8] Train_Time=0.649, Train_Speed=197.077 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 7.32e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00615  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0165   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00492  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00154  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000374 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00596  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0158   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00488  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00153  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000369 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.2e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 940      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000197 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000643 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.62e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.38e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.74e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.607\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.643\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [941][8] Train_Time=0.557, Train_Speed=229.637 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [942][8] Train_Time=0.667, Train_Speed=191.770 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [943][8] Train_Time=0.665, Train_Speed=192.537 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [944][8] Train_Time=0.663, Train_Speed=193.062 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [945][8] Train_Time=0.654, Train_Speed=195.681 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [946][8] Train_Time=0.655, Train_Speed=195.293 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [947][8] Train_Time=0.668, Train_Speed=191.680 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [948][8] Train_Time=0.671, Train_Speed=190.691 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [949][8] Train_Time=0.626, Train_Speed=204.394 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [950][8] Train_Time=0.623, Train_Speed=205.431 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.35e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 20.9     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0265   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.119    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00403  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00129  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000373 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00711  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0278   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.004    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00128  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000369 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.22e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 950      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0194   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0911   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.93e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.16e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.62e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.551\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.564\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [951][8] Train_Time=0.551, Train_Speed=232.200 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [952][8] Train_Time=0.662, Train_Speed=193.392 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [953][8] Train_Time=0.661, Train_Speed=193.777 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [954][8] Train_Time=0.664, Train_Speed=192.637 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [955][8] Train_Time=0.667, Train_Speed=191.945 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [956][8] Train_Time=0.660, Train_Speed=194.022 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [957][8] Train_Time=0.639, Train_Speed=200.433 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [958][8] Train_Time=0.646, Train_Speed=198.163 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [959][8] Train_Time=0.626, Train_Speed=204.601 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [960][8] Train_Time=0.669, Train_Speed=191.271 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.71e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00623  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0193   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00445  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000382 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00594  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0182   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00442  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00129  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000377 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.23e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 960      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000286 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0011   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.28e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.72e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.502\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.573\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [961][8] Train_Time=0.583, Train_Speed=219.451 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [962][8] Train_Time=0.665, Train_Speed=192.385 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [963][8] Train_Time=0.661, Train_Speed=193.560 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [964][8] Train_Time=0.668, Train_Speed=191.751 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [965][8] Train_Time=0.668, Train_Speed=191.567 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [966][8] Train_Time=0.664, Train_Speed=192.846 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [967][8] Train_Time=0.646, Train_Speed=198.090 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [968][8] Train_Time=0.643, Train_Speed=198.927 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [969][8] Train_Time=0.636, Train_Speed=201.104 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [970][8] Train_Time=0.671, Train_Speed=190.649 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 9.76e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00473  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0169   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00472  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00137  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000408 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00459  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0162   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00469  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000403 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.24e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 970      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000136 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000695 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.46e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.04e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.454\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.613\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [971][8] Train_Time=0.590, Train_Speed=217.093 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [972][8] Train_Time=0.663, Train_Speed=192.975 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [973][8] Train_Time=0.639, Train_Speed=200.259 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [974][8] Train_Time=0.649, Train_Speed=197.122 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [975][8] Train_Time=0.667, Train_Speed=191.908 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [976][8] Train_Time=0.666, Train_Speed=192.262 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [977][8] Train_Time=0.664, Train_Speed=192.853 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [978][8] Train_Time=0.665, Train_Speed=192.615 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [979][8] Train_Time=0.673, Train_Speed=190.266 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [980][8] Train_Time=0.648, Train_Speed=197.391 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.98e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00535  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0152   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00475  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0012   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000331 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00515  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0144   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00471  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00119  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000327 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.26e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 980      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0002   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000784 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.52e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.08e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.17e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.565\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.569\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [981][8] Train_Time=0.590, Train_Speed=217.001 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [982][8] Train_Time=0.651, Train_Speed=196.730 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [983][8] Train_Time=0.641, Train_Speed=199.632 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [984][8] Train_Time=0.641, Train_Speed=199.733 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [985][8] Train_Time=0.630, Train_Speed=203.123 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [986][8] Train_Time=0.645, Train_Speed=198.402 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [987][8] Train_Time=0.670, Train_Speed=191.169 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [988][8] Train_Time=0.648, Train_Speed=197.562 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [989][8] Train_Time=0.655, Train_Speed=195.349 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [990][8] Train_Time=0.654, Train_Speed=195.730 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.38e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00547  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0166   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00456  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.000973 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000347 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00515  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0153   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00452  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.000964 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000342 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.27e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 990      |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000314 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00127  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.37e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 9.24e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.42e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.553\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.675\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [991][8] Train_Time=0.559, Train_Speed=229.086 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [992][8] Train_Time=0.632, Train_Speed=202.400 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [993][8] Train_Time=0.644, Train_Speed=198.738 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [994][8] Train_Time=0.636, Train_Speed=201.115 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [995][8] Train_Time=0.631, Train_Speed=202.935 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [996][8] Train_Time=0.669, Train_Speed=191.431 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [997][8] Train_Time=0.668, Train_Speed=191.532 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [998][8] Train_Time=0.674, Train_Speed=189.803 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [999][8] Train_Time=0.671, Train_Speed=190.900 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1000][8] Train_Time=0.666, Train_Speed=192.190 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.4e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00621  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0199   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00447  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00119  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000423 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00573  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.018    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00444  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00118  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000418 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.28e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1e+03    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000475 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00195  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.09e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 5.18e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.630\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.662\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.537\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.536\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.537\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.537\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=28.906\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.538\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.537\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.537\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.538\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.536\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.538\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.538\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.538\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.537\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.874\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.538\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1001][8] Train_Time=0.600, Train_Speed=213.419 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1002][8] Train_Time=0.626, Train_Speed=204.354 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1003][8] Train_Time=0.672, Train_Speed=190.438 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1004][8] Train_Time=0.652, Train_Speed=196.190 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1005][8] Train_Time=0.666, Train_Speed=192.183 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1006][8] Train_Time=0.666, Train_Speed=192.060 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1007][8] Train_Time=0.666, Train_Speed=192.209 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1008][8] Train_Time=0.668, Train_Speed=191.696 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1009][8] Train_Time=0.667, Train_Speed=191.964 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1010][8] Train_Time=0.667, Train_Speed=191.981 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.24e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00465  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0161   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00431  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0012   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000371 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00417  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0136   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00428  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00119  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000367 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.29e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.01e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000479 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00248  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.19e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.1e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.56e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.414\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.546\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1011][8] Train_Time=0.586, Train_Speed=218.323 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1012][8] Train_Time=0.667, Train_Speed=191.902 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1013][8] Train_Time=0.672, Train_Speed=190.414 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1014][8] Train_Time=0.659, Train_Speed=194.159 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1015][8] Train_Time=0.665, Train_Speed=192.537 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1016][8] Train_Time=0.639, Train_Speed=200.224 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1017][8] Train_Time=0.658, Train_Speed=194.412 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1018][8] Train_Time=0.664, Train_Speed=192.659 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1019][8] Train_Time=0.665, Train_Speed=192.536 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1020][8] Train_Time=0.650, Train_Speed=196.900 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 9.21e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00558  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0151   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00356  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00132  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000337 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00542  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0145   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00353  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000333 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.31e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.02e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000162 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000528 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.63e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.21e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.27e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.489\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.569\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1021][8] Train_Time=0.558, Train_Speed=229.305 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1022][8] Train_Time=0.638, Train_Speed=200.584 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1023][8] Train_Time=0.650, Train_Speed=196.772 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1024][8] Train_Time=0.703, Train_Speed=182.077 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1025][8] Train_Time=0.642, Train_Speed=199.295 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1026][8] Train_Time=0.648, Train_Speed=197.673 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1027][8] Train_Time=0.648, Train_Speed=197.423 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1028][8] Train_Time=0.651, Train_Speed=196.525 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1029][8] Train_Time=0.663, Train_Speed=193.079 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1030][8] Train_Time=0.663, Train_Speed=193.109 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.03e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00453  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0129   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00462  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00132  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000311 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00441  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0124   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00459  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000308 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.32e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.03e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000119 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000495 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.39e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.95e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.484\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.513\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1031][8] Train_Time=0.586, Train_Speed=218.253 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1032][8] Train_Time=0.670, Train_Speed=190.928 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1033][8] Train_Time=0.672, Train_Speed=190.483 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1034][8] Train_Time=0.675, Train_Speed=189.608 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1035][8] Train_Time=0.674, Train_Speed=190.050 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1036][8] Train_Time=0.667, Train_Speed=191.961 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1037][8] Train_Time=0.668, Train_Speed=191.483 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1038][8] Train_Time=0.660, Train_Speed=193.897 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1039][8] Train_Time=0.654, Train_Speed=195.796 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1040][8] Train_Time=0.653, Train_Speed=196.072 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.89e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00594  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0286   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00435  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000339 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0053   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0244   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00432  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00135  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000335 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.33e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.04e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000638 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00416  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.21e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.24e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.23e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.500\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.521\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1041][8] Train_Time=0.586, Train_Speed=218.371 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1042][8] Train_Time=0.671, Train_Speed=190.722 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1043][8] Train_Time=0.668, Train_Speed=191.538 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1044][8] Train_Time=0.650, Train_Speed=197.069 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1045][8] Train_Time=0.646, Train_Speed=198.222 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1046][8] Train_Time=0.642, Train_Speed=199.397 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1047][8] Train_Time=0.666, Train_Speed=192.319 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1048][8] Train_Time=0.666, Train_Speed=192.229 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1049][8] Train_Time=0.653, Train_Speed=196.116 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1050][8] Train_Time=0.649, Train_Speed=197.311 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.09e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21       |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00464  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0145   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00386  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00035  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00455  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0142   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00384  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00138  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000346 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.35e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.05e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 9.5e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000373 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.82e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.24e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.46e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.509\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.631\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1051][8] Train_Time=0.577, Train_Speed=221.669 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1052][8] Train_Time=0.668, Train_Speed=191.691 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1053][8] Train_Time=0.670, Train_Speed=190.982 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1054][8] Train_Time=0.666, Train_Speed=192.334 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1055][8] Train_Time=0.667, Train_Speed=191.889 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1056][8] Train_Time=0.651, Train_Speed=196.498 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1057][8] Train_Time=0.640, Train_Speed=200.067 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1058][8] Train_Time=0.669, Train_Speed=191.213 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1059][8] Train_Time=0.666, Train_Speed=192.289 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1060][8] Train_Time=0.666, Train_Speed=192.155 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 9.4e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0238   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0846   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00444  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00119  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000364 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00625  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0179   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0044   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00118  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000359 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.36e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.06e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0175   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0667   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.25e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.09e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.6e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.527\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.652\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1061][8] Train_Time=0.711, Train_Speed=180.077 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1062][8] Train_Time=0.666, Train_Speed=192.224 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1063][8] Train_Time=0.671, Train_Speed=190.656 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1064][8] Train_Time=0.673, Train_Speed=190.134 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1065][8] Train_Time=0.669, Train_Speed=191.207 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1066][8] Train_Time=0.672, Train_Speed=190.529 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1067][8] Train_Time=0.666, Train_Speed=192.072 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1068][8] Train_Time=0.667, Train_Speed=191.811 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1069][8] Train_Time=0.668, Train_Speed=191.712 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1070][8] Train_Time=0.665, Train_Speed=192.618 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.67e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00553  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.018    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0048   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00104  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000327 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00528  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0169   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00476  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00103  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000323 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.37e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.07e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00025  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00111  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.55e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 9.64e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.11e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.621\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.834\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1071][8] Train_Time=0.587, Train_Speed=218.110 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1072][8] Train_Time=0.652, Train_Speed=196.182 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1073][8] Train_Time=0.651, Train_Speed=196.622 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1074][8] Train_Time=0.630, Train_Speed=203.324 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1075][8] Train_Time=0.653, Train_Speed=195.911 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1076][8] Train_Time=0.664, Train_Speed=192.729 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1077][8] Train_Time=0.652, Train_Speed=196.343 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1078][8] Train_Time=0.647, Train_Speed=197.849 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1079][8] Train_Time=0.632, Train_Speed=202.520 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1080][8] Train_Time=0.639, Train_Speed=200.361 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.82e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00506  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0157   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00407  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00127  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000313 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00479  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0146   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00404  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00126  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000309 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.38e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.08e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000266 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00113  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3e-05    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.12e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.93e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.567\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.642\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1081][8] Train_Time=0.542, Train_Speed=236.260 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1082][8] Train_Time=0.651, Train_Speed=196.619 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1083][8] Train_Time=0.607, Train_Speed=210.862 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1084][8] Train_Time=0.644, Train_Speed=198.721 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1085][8] Train_Time=0.634, Train_Speed=202.034 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1086][8] Train_Time=0.631, Train_Speed=203.012 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1087][8] Train_Time=0.634, Train_Speed=201.867 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1088][8] Train_Time=0.629, Train_Speed=203.533 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1089][8] Train_Time=0.631, Train_Speed=202.738 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1090][8] Train_Time=0.618, Train_Speed=207.050 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.71e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00506  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0159   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00426  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00124  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000365 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00492  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0153   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00423  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00122  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000361 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.4e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000148 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000578 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.14e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.14e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.42e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.515\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.629\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1091][8] Train_Time=0.654, Train_Speed=195.787 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1092][8] Train_Time=0.663, Train_Speed=193.197 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1093][8] Train_Time=0.661, Train_Speed=193.513 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1094][8] Train_Time=0.660, Train_Speed=193.975 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1095][8] Train_Time=0.662, Train_Speed=193.308 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1096][8] Train_Time=0.660, Train_Speed=193.938 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1097][8] Train_Time=0.662, Train_Speed=193.498 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1098][8] Train_Time=0.662, Train_Speed=193.353 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1099][8] Train_Time=0.661, Train_Speed=193.613 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1100][8] Train_Time=0.626, Train_Speed=204.419 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.93e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00433  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.013    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00464  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00129  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000375 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00426  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0127   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0046   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00127  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000371 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.41e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.1e+03  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 7.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000297 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.41e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.64e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.624\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.674\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1101][8] Train_Time=0.585, Train_Speed=218.770 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1102][8] Train_Time=0.646, Train_Speed=198.072 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1103][8] Train_Time=0.629, Train_Speed=203.537 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1104][8] Train_Time=0.634, Train_Speed=201.735 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1105][8] Train_Time=0.636, Train_Speed=201.175 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1106][8] Train_Time=0.650, Train_Speed=196.817 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1107][8] Train_Time=0.630, Train_Speed=203.019 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1108][8] Train_Time=0.658, Train_Speed=194.646 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1109][8] Train_Time=0.669, Train_Speed=191.407 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1110][8] Train_Time=0.664, Train_Speed=192.844 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.41e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0233   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.111    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00344  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000327 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00562  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0223   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00341  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00133  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000323 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.42e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.11e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0177   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0883   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.55e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.18e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.1e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.516\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.578\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1111][8] Train_Time=0.580, Train_Speed=220.502 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1112][8] Train_Time=0.664, Train_Speed=192.647 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1113][8] Train_Time=0.670, Train_Speed=191.157 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1114][8] Train_Time=0.666, Train_Speed=192.140 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1115][8] Train_Time=0.657, Train_Speed=194.681 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1116][8] Train_Time=0.610, Train_Speed=209.771 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1117][8] Train_Time=0.610, Train_Speed=209.852 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1118][8] Train_Time=0.634, Train_Speed=201.799 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1119][8] Train_Time=0.637, Train_Speed=200.983 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1120][8] Train_Time=0.671, Train_Speed=190.681 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.55e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0051   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.016    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00376  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00141  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000324 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00499  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0156   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00374  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00032  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.43e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.12e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000109 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000429 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.78e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.25e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.07e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.473\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.485\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1121][8] Train_Time=0.559, Train_Speed=229.082 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1122][8] Train_Time=0.652, Train_Speed=196.265 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1123][8] Train_Time=0.662, Train_Speed=193.229 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1124][8] Train_Time=0.655, Train_Speed=195.376 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1125][8] Train_Time=0.654, Train_Speed=195.614 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1126][8] Train_Time=0.666, Train_Speed=192.134 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1127][8] Train_Time=0.672, Train_Speed=190.564 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1128][8] Train_Time=0.668, Train_Speed=191.588 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1129][8] Train_Time=0.667, Train_Speed=192.007 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1130][8] Train_Time=0.662, Train_Speed=193.213 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.4e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00417  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0126   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00407  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00109  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000361 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00405  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0121   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00404  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00108  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000356 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.45e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.13e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000123 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000523 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.97e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.03e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.44e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.440\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.462\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1131][8] Train_Time=0.600, Train_Speed=213.204 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1132][8] Train_Time=0.662, Train_Speed=193.223 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1133][8] Train_Time=0.666, Train_Speed=192.262 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1134][8] Train_Time=0.667, Train_Speed=192.043 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1135][8] Train_Time=0.668, Train_Speed=191.590 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1136][8] Train_Time=0.667, Train_Speed=191.889 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1137][8] Train_Time=0.666, Train_Speed=192.284 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1138][8] Train_Time=0.663, Train_Speed=193.054 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1139][8] Train_Time=0.662, Train_Speed=193.318 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1140][8] Train_Time=0.664, Train_Speed=192.647 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.17e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00496  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0134   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00411  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00165  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000298 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00477  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0127   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00408  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00164  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000295 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.46e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.14e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000185 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000659 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.01e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.42e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.81e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.450\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.712\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1141][8] Train_Time=0.584, Train_Speed=218.999 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1142][8] Train_Time=0.666, Train_Speed=192.296 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1143][8] Train_Time=0.666, Train_Speed=192.279 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1144][8] Train_Time=0.671, Train_Speed=190.731 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1145][8] Train_Time=0.668, Train_Speed=191.533 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1146][8] Train_Time=0.667, Train_Speed=191.858 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1147][8] Train_Time=0.664, Train_Speed=192.729 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1148][8] Train_Time=0.660, Train_Speed=193.998 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1149][8] Train_Time=0.667, Train_Speed=191.826 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1150][8] Train_Time=0.665, Train_Speed=192.497 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.84e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.1     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00606  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0197   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0047   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0012   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000306 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00582  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0186   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00467  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00119  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000302 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.47e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.15e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000245 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00103  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.44e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.11e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.8e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.516\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.675\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1151][8] Train_Time=0.585, Train_Speed=218.656 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1152][8] Train_Time=0.668, Train_Speed=191.572 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1153][8] Train_Time=0.665, Train_Speed=192.443 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1154][8] Train_Time=0.668, Train_Speed=191.495 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1155][8] Train_Time=0.640, Train_Speed=199.880 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1156][8] Train_Time=0.616, Train_Speed=207.913 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1157][8] Train_Time=0.665, Train_Speed=192.598 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1158][8] Train_Time=0.642, Train_Speed=199.282 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1159][8] Train_Time=0.671, Train_Speed=190.845 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1160][8] Train_Time=0.667, Train_Speed=191.891 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.74e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0255   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0811   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00588  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00137  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000328 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00774  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.022    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00583  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000324 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.49e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.16e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0177   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0591   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 4.35e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.07e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.547\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.577\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1161][8] Train_Time=0.613, Train_Speed=208.767 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1162][8] Train_Time=0.682, Train_Speed=187.575 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1163][8] Train_Time=0.667, Train_Speed=191.768 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1164][8] Train_Time=0.669, Train_Speed=191.385 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1165][8] Train_Time=0.669, Train_Speed=191.262 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1166][8] Train_Time=0.665, Train_Speed=192.569 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1167][8] Train_Time=0.669, Train_Speed=191.384 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1168][8] Train_Time=0.658, Train_Speed=194.633 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1169][8] Train_Time=0.649, Train_Speed=197.366 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1170][8] Train_Time=0.667, Train_Speed=191.768 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.5e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00603  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0175   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00431  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00114  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00035  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.0057   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0163   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00428  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00113  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000346 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.5e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.17e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00033  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00121  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.15e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.05e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.27e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.534\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.559\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1171][8] Train_Time=0.605, Train_Speed=211.411 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1172][8] Train_Time=0.667, Train_Speed=191.809 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1173][8] Train_Time=0.634, Train_Speed=202.026 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1174][8] Train_Time=0.621, Train_Speed=206.214 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1175][8] Train_Time=0.618, Train_Speed=207.284 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1176][8] Train_Time=0.615, Train_Speed=208.286 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1177][8] Train_Time=0.616, Train_Speed=207.912 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1178][8] Train_Time=0.636, Train_Speed=201.234 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1179][8] Train_Time=0.617, Train_Speed=207.299 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1180][8] Train_Time=0.666, Train_Speed=192.167 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.75e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00576  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0147   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00443  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00127  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000307 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00549  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0044   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00126  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000304 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.51e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.18e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000267 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000825 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.24e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.15e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.93e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.406\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.630\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1181][8] Train_Time=0.583, Train_Speed=219.522 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1182][8] Train_Time=0.655, Train_Speed=195.503 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1183][8] Train_Time=0.662, Train_Speed=193.482 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1184][8] Train_Time=0.667, Train_Speed=192.020 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1185][8] Train_Time=0.662, Train_Speed=193.385 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1186][8] Train_Time=0.634, Train_Speed=201.811 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1187][8] Train_Time=0.663, Train_Speed=193.043 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1188][8] Train_Time=0.663, Train_Speed=193.024 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1189][8] Train_Time=0.664, Train_Speed=192.819 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1190][8] Train_Time=0.663, Train_Speed=193.122 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.44e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00735  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0192   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00463  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00155  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000287 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00706  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0182   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0046   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00154  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000284 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.52e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.19e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000287 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000914 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.38e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.37e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.7e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.392\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1191][8] Train_Time=0.581, Train_Speed=220.449 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1192][8] Train_Time=0.655, Train_Speed=195.349 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1193][8] Train_Time=0.628, Train_Speed=203.970 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1194][8] Train_Time=0.648, Train_Speed=197.387 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1195][8] Train_Time=0.633, Train_Speed=202.130 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1196][8] Train_Time=0.667, Train_Speed=191.842 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1197][8] Train_Time=0.649, Train_Speed=197.092 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1198][8] Train_Time=0.646, Train_Speed=198.031 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1199][8] Train_Time=0.667, Train_Speed=191.998 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1200][8] Train_Time=0.665, Train_Speed=192.398 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.28e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00631  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0209   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0038   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00144  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000353 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00592  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0193   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00377  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00143  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000349 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.54e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.2e+03  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000391 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0016   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.82e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.27e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.25e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.475\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.507\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0.9999...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=28.560\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.035\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.034\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.033\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.035\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.036\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.528\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1201][8] Train_Time=0.609, Train_Speed=210.043 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1202][8] Train_Time=0.670, Train_Speed=190.920 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1203][8] Train_Time=0.663, Train_Speed=192.959 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1204][8] Train_Time=0.642, Train_Speed=199.520 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1205][8] Train_Time=0.642, Train_Speed=199.466 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1206][8] Train_Time=0.648, Train_Speed=197.468 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1207][8] Train_Time=0.640, Train_Speed=199.943 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1208][8] Train_Time=0.646, Train_Speed=198.108 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1209][8] Train_Time=0.649, Train_Speed=197.268 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1210][8] Train_Time=0.641, Train_Speed=199.686 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 8.65e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00557  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0145   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00404  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00032  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00536  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00401  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0013   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000316 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.55e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.21e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000217 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000718 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.94e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.15e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.94e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.441\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.615\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1211][8] Train_Time=0.576, Train_Speed=222.122 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1212][8] Train_Time=0.678, Train_Speed=188.824 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1213][8] Train_Time=0.666, Train_Speed=192.296 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1214][8] Train_Time=0.667, Train_Speed=192.013 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1215][8] Train_Time=0.662, Train_Speed=193.227 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1216][8] Train_Time=0.652, Train_Speed=196.449 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1217][8] Train_Time=0.665, Train_Speed=192.425 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1218][8] Train_Time=0.616, Train_Speed=207.852 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1219][8] Train_Time=0.667, Train_Speed=191.786 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1220][8] Train_Time=0.677, Train_Speed=189.086 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.31e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00689  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0193   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00405  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00037  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00658  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0182   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00402  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0013   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000365 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.56e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.22e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00031  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00104  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.97e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.19e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.43e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.451\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.545\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1221][8] Train_Time=0.672, Train_Speed=190.432 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1222][8] Train_Time=0.663, Train_Speed=192.966 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1223][8] Train_Time=0.664, Train_Speed=192.692 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1224][8] Train_Time=0.661, Train_Speed=193.732 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1225][8] Train_Time=0.646, Train_Speed=197.992 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1226][8] Train_Time=0.664, Train_Speed=192.860 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1227][8] Train_Time=0.663, Train_Speed=192.922 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1228][8] Train_Time=0.662, Train_Speed=193.358 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1229][8] Train_Time=0.662, Train_Speed=193.339 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1230][8] Train_Time=0.664, Train_Speed=192.902 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.09e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.0028   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.00953  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00344  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00159  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000372 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00277  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.00942  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00342  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00158  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000367 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.58e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.23e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 2.73e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00011  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.55e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.38e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.59e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.542\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.590\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1231][8] Train_Time=0.590, Train_Speed=216.944 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1232][8] Train_Time=0.667, Train_Speed=192.044 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1233][8] Train_Time=0.649, Train_Speed=197.342 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1234][8] Train_Time=0.644, Train_Speed=198.895 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1235][8] Train_Time=0.647, Train_Speed=197.760 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1236][8] Train_Time=0.614, Train_Speed=208.351 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1237][8] Train_Time=0.616, Train_Speed=207.819 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1238][8] Train_Time=0.609, Train_Speed=210.207 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1239][8] Train_Time=0.638, Train_Speed=200.650 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1240][8] Train_Time=0.654, Train_Speed=195.594 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 9.58e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00645  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0138   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0043   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00146  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000378 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00634  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0135   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00427  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00144  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000373 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.59e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.24e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000117 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000278 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.13e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.29e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.61e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.422\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.588\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1241][8] Train_Time=0.546, Train_Speed=234.286 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1242][8] Train_Time=0.664, Train_Speed=192.728 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1243][8] Train_Time=0.667, Train_Speed=192.000 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1244][8] Train_Time=0.665, Train_Speed=192.544 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1245][8] Train_Time=0.649, Train_Speed=197.279 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1246][8] Train_Time=0.639, Train_Speed=200.329 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1247][8] Train_Time=0.636, Train_Speed=201.252 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1248][8] Train_Time=0.649, Train_Speed=197.169 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1249][8] Train_Time=0.654, Train_Speed=195.595 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1250][8] Train_Time=0.659, Train_Speed=194.215 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 5.97e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.2     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00627  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0169   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.0043   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00123  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000353 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00599  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.016    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00427  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00122  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000349 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.6e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.25e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000279 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00093  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.11e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.26e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.643\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.698\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1251][8] Train_Time=0.599, Train_Speed=213.858 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1252][8] Train_Time=0.671, Train_Speed=190.809 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1253][8] Train_Time=0.672, Train_Speed=190.467 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1254][8] Train_Time=0.670, Train_Speed=191.100 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1255][8] Train_Time=0.667, Train_Speed=191.913 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1256][8] Train_Time=0.664, Train_Speed=192.637 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1257][8] Train_Time=0.669, Train_Speed=191.462 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1258][8] Train_Time=0.669, Train_Speed=191.193 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1259][8] Train_Time=0.670, Train_Speed=191.174 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1260][8] Train_Time=0.666, Train_Speed=192.323 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.34e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00516  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0152   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.004    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00115  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000302 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00501  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0147   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00397  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00114  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000298 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.61e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.26e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000143 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000529 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.94e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.03e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.7e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.423\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.591\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1261][8] Train_Time=0.578, Train_Speed=221.286 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1262][8] Train_Time=0.640, Train_Speed=200.102 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1263][8] Train_Time=0.626, Train_Speed=204.425 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1264][8] Train_Time=0.632, Train_Speed=202.569 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1265][8] Train_Time=0.638, Train_Speed=200.739 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1266][8] Train_Time=0.610, Train_Speed=209.707 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1267][8] Train_Time=0.611, Train_Speed=209.438 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1268][8] Train_Time=0.640, Train_Speed=200.014 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1269][8] Train_Time=0.645, Train_Speed=198.398 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1270][8] Train_Time=0.638, Train_Speed=200.531 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.82e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00493  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0173   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00399  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00111  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000304 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00466  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0159   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00396  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0011   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.0003   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.63e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.27e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000273 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00131  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.95e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.01e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.87e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.418\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.522\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1271][8] Train_Time=0.571, Train_Speed=224.229 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1272][8] Train_Time=0.607, Train_Speed=210.747 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1273][8] Train_Time=0.610, Train_Speed=209.803 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1274][8] Train_Time=0.613, Train_Speed=208.878 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1275][8] Train_Time=0.612, Train_Speed=209.124 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1276][8] Train_Time=0.611, Train_Speed=209.493 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1277][8] Train_Time=0.632, Train_Speed=202.530 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1278][8] Train_Time=0.652, Train_Speed=196.368 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1279][8] Train_Time=0.642, Train_Speed=199.230 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1280][8] Train_Time=0.636, Train_Speed=201.369 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.19e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00608  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0189   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00494  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000307 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00584  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0179   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0049   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00138  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000304 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.64e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.28e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000236 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000984 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.63e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.23e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.79e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.488\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.581\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1281][8] Train_Time=0.578, Train_Speed=221.506 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1282][8] Train_Time=0.666, Train_Speed=192.240 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1283][8] Train_Time=0.665, Train_Speed=192.594 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1284][8] Train_Time=0.666, Train_Speed=192.336 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1285][8] Train_Time=0.644, Train_Speed=198.631 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1286][8] Train_Time=0.601, Train_Speed=213.062 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1287][8] Train_Time=0.602, Train_Speed=212.517 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1288][8] Train_Time=0.625, Train_Speed=204.638 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1289][8] Train_Time=0.640, Train_Speed=200.004 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1290][8] Train_Time=0.611, Train_Speed=209.419 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.39e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00389  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0131   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00433  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000341 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00383  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0129   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.0043   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00133  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000337 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.65e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.29e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 5.99e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000257 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.17e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.2e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.14e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.531\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.579\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1291][8] Train_Time=0.582, Train_Speed=219.901 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1292][8] Train_Time=0.611, Train_Speed=209.441 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1293][8] Train_Time=0.611, Train_Speed=209.469 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1294][8] Train_Time=0.609, Train_Speed=210.053 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1295][8] Train_Time=0.638, Train_Speed=200.636 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1296][8] Train_Time=0.624, Train_Speed=205.105 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1297][8] Train_Time=0.636, Train_Speed=201.146 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1298][8] Train_Time=0.643, Train_Speed=199.124 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1299][8] Train_Time=0.648, Train_Speed=197.527 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1300][8] Train_Time=0.634, Train_Speed=201.746 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 4.1e+04  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00566  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0162   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00375  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000284 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00538  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0152   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00373  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00133  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.00028  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.67e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.3e+03  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000284 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000996 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.75e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.2e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.6e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.435\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.530\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1301][8] Train_Time=0.550, Train_Speed=232.851 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1302][8] Train_Time=0.669, Train_Speed=191.204 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1303][8] Train_Time=0.669, Train_Speed=191.415 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1304][8] Train_Time=0.638, Train_Speed=200.506 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1305][8] Train_Time=0.608, Train_Speed=210.667 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1306][8] Train_Time=0.665, Train_Speed=192.561 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1307][8] Train_Time=0.632, Train_Speed=202.604 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1308][8] Train_Time=0.664, Train_Speed=192.668 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1309][8] Train_Time=0.668, Train_Speed=191.547 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1310][8] Train_Time=0.666, Train_Speed=192.074 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.64e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00579  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0188   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00392  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00127  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000297 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00525  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0165   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00389  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00126  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000293 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.68e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.31e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000545 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00225  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.87e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.13e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.7e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.490\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.563\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1311][8] Train_Time=0.623, Train_Speed=205.461 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1312][8] Train_Time=0.647, Train_Speed=197.908 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1313][8] Train_Time=0.647, Train_Speed=197.978 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1314][8] Train_Time=0.635, Train_Speed=201.604 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1315][8] Train_Time=0.613, Train_Speed=208.931 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1316][8] Train_Time=0.665, Train_Speed=192.484 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1317][8] Train_Time=0.664, Train_Speed=192.855 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1318][8] Train_Time=0.660, Train_Speed=193.812 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1319][8] Train_Time=0.660, Train_Speed=193.915 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1320][8] Train_Time=0.664, Train_Speed=192.846 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 6.69e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00363  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.00925  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00384  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00113  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000331 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00358  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.00912  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00381  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00112  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000327 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.69e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.32e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 4.13e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000129 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 2.83e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 4.2e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.430\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.470\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1321][8] Train_Time=0.578, Train_Speed=221.403 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1322][8] Train_Time=0.658, Train_Speed=194.403 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1323][8] Train_Time=0.648, Train_Speed=197.651 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1324][8] Train_Time=0.649, Train_Speed=197.144 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1325][8] Train_Time=0.638, Train_Speed=200.696 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1326][8] Train_Time=0.640, Train_Speed=200.082 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1327][8] Train_Time=0.629, Train_Speed=203.420 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1328][8] Train_Time=0.664, Train_Speed=192.656 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1329][8] Train_Time=0.665, Train_Speed=192.380 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1330][8] Train_Time=0.637, Train_Speed=201.081 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 3.56e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00547  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0149   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00455  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00118  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000288 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00528  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0143   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00452  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00117  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000285 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.7e+05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.33e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000194 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000641 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.33e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.69e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.318\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.464\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1331][8] Train_Time=0.546, Train_Speed=234.428 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1332][8] Train_Time=0.625, Train_Speed=204.721 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1333][8] Train_Time=0.632, Train_Speed=202.384 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1334][8] Train_Time=0.636, Train_Speed=201.187 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1335][8] Train_Time=0.648, Train_Speed=197.602 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1336][8] Train_Time=0.665, Train_Speed=192.351 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1337][8] Train_Time=0.669, Train_Speed=191.377 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1338][8] Train_Time=0.666, Train_Speed=192.287 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1339][8] Train_Time=0.632, Train_Speed=202.553 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1340][8] Train_Time=0.661, Train_Speed=193.535 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.68e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00607  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0168   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00512  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00135  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000305 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00554  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0148   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00508  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000301 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.72e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.34e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000523 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.00203  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.77e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.2e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.8e-06  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.335\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.494\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1341][8] Train_Time=0.586, Train_Speed=218.245 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1342][8] Train_Time=0.662, Train_Speed=193.452 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1343][8] Train_Time=0.667, Train_Speed=191.968 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1344][8] Train_Time=0.659, Train_Speed=194.333 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1345][8] Train_Time=0.662, Train_Speed=193.473 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1346][8] Train_Time=0.648, Train_Speed=197.434 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1347][8] Train_Time=0.661, Train_Speed=193.686 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1348][8] Train_Time=0.608, Train_Speed=210.496 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1349][8] Train_Time=0.630, Train_Speed=203.075 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1350][8] Train_Time=0.629, Train_Speed=203.624 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.69e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.3     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00436  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0121   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00416  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.000939 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000319 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00429  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0119   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00413  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00093  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000315 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.73e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.35e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 6.5e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000225 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.03e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 8.67e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.94e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.519\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.580\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1351][8] Train_Time=0.639, Train_Speed=200.322 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1352][8] Train_Time=0.648, Train_Speed=197.436 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1353][8] Train_Time=0.652, Train_Speed=196.313 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1354][8] Train_Time=0.659, Train_Speed=194.160 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1355][8] Train_Time=0.643, Train_Speed=198.954 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1356][8] Train_Time=0.623, Train_Speed=205.417 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1357][8] Train_Time=0.625, Train_Speed=204.709 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1358][8] Train_Time=0.660, Train_Speed=193.836 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1359][8] Train_Time=0.656, Train_Speed=195.187 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1360][8] Train_Time=0.643, Train_Speed=199.142 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.91e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00674  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0185   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00443  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00136  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000315 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00649  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0177   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00439  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00135  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000311 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.74e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.36e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000247 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000821 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.26e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.21e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.84e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.488\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.664\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1361][8] Train_Time=0.553, Train_Speed=231.383 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1362][8] Train_Time=0.650, Train_Speed=196.881 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1363][8] Train_Time=0.649, Train_Speed=197.110 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1364][8] Train_Time=0.663, Train_Speed=193.082 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1365][8] Train_Time=0.628, Train_Speed=203.698 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1366][8] Train_Time=0.634, Train_Speed=202.049 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1367][8] Train_Time=0.664, Train_Speed=192.856 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1368][8] Train_Time=0.646, Train_Speed=198.120 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1369][8] Train_Time=0.662, Train_Speed=193.329 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1370][8] Train_Time=0.680, Train_Speed=188.144 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.76e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00672  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0161   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00451  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.0014   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000315 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00654  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0155   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00447  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00139  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000311 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.75e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.37e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.000181 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000536 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.32e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.24e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.96e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.456\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.521\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1371][8] Train_Time=0.553, Train_Speed=231.388 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1372][8] Train_Time=0.630, Train_Speed=203.025 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1373][8] Train_Time=0.613, Train_Speed=208.950 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1374][8] Train_Time=0.662, Train_Speed=193.267 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1375][8] Train_Time=0.617, Train_Speed=207.593 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1376][8] Train_Time=0.663, Train_Speed=193.115 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1377][8] Train_Time=0.617, Train_Speed=207.338 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1378][8] Train_Time=0.611, Train_Speed=209.435 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1379][8] Train_Time=0.612, Train_Speed=209.314 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1380][8] Train_Time=0.609, Train_Speed=210.344 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 1.72e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.024    |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0948   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00451  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00135  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000287 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00642  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0209   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00448  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00134  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000284 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.77e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.38e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.0176   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0739   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.31e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.2e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.65e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.523\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.665\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1381][8] Train_Time=0.574, Train_Speed=223.017 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1382][8] Train_Time=0.643, Train_Speed=199.184 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1383][8] Train_Time=0.662, Train_Speed=193.461 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1384][8] Train_Time=0.662, Train_Speed=193.356 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1385][8] Train_Time=0.658, Train_Speed=194.580 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1386][8] Train_Time=0.655, Train_Speed=195.407 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1387][8] Train_Time=0.657, Train_Speed=194.830 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1388][8] Train_Time=0.657, Train_Speed=194.726 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1389][8] Train_Time=0.645, Train_Speed=198.590 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1390][8] Train_Time=0.666, Train_Speed=192.216 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.33e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00853  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0255   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00426  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00163  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.00032  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00745  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0216   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00423  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.00162  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000316 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.78e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.39e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 0.00108  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.0039   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.13e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.42e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.99e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.464\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.736\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1391][8] Train_Time=0.557, Train_Speed=229.917 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1392][8] Train_Time=0.639, Train_Speed=200.341 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1393][8] Train_Time=0.639, Train_Speed=200.159 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1394][8] Train_Time=0.650, Train_Speed=196.901 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1395][8] Train_Time=0.659, Train_Speed=194.332 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1396][8] Train_Time=0.657, Train_Speed=194.960 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1397][8] Train_Time=0.666, Train_Speed=192.305 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1398][8] Train_Time=0.672, Train_Speed=190.602 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1399][8] Train_Time=0.668, Train_Speed=191.566 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1400][8] Train_Time=0.669, Train_Speed=191.207 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| grad_norm     | 2.42e+04 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| lg_loss_scale | 21.4     |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss          | 0.00394  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q0       | 0.0118   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q1       | 0.00408  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q2       | 0.00121  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| loss_q3       | 0.000291 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse           | 0.00387  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q0        | 0.0116   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q1        | 0.00405  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q2        | 0.0012   |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| mse_q3        | 0.000288 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| param_norm    | 1.09e+03 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| samples       | 1.79e+05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| step          | 1.4e+03  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb            | 6.58e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q0         | 0.000245 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q1         | 3.06e-05 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q2         | 1.1e-05  |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:| vb_q3         | 3.68e-06 |\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:----------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:LOGUpload_Time=0.466\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:LOGUpload_Time=0.489\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:saving model 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Save_Time=28.618\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Save_Time=29.098\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Save_Time=29.103\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Save_Time=28.641\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Save_Time=29.106\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Save_Time=29.107\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1401][8] Train_Time=0.582, Train_Speed=220.073 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1402][8] Train_Time=0.666, Train_Speed=192.066 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1403][8] Train_Time=0.659, Train_Speed=194.189 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1404][8] Train_Time=0.976, Train_Speed=131.086 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1405][8] Train_Time=0.639, Train_Speed=200.304 samples/sec,\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Step: [1406][8] Train_Time=0.637, Train_Speed=201.016 samples/sec,\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/checkpoints [] ['opt000040.pt', 'ema_0.9999_000085.pt', 'model000100.pt', 'ema_0.9999_000005.pt', 'model000090.pt', 'model000040.pt', 'ema_0.9999_000095.pt', 'opt000090.pt', 'opt000030.pt', 'opt000100.pt', 'model.pt', 'ema_0.9999_000040.pt', 'opt000025.pt', 'ema_0.9999_000035.pt', 'model000020.pt', 'model000005.pt', 'ema_0.9999_000015.pt', 'model000070.pt', 'ema_0.9999_000030.pt', 'model000095.pt', 'ema_0.9999_000065.pt', 'model000080.pt', 'model000030.pt', 'ema_0.9999_000100.pt', 'opt000095.pt', 'ema_0.9999_000055.pt', 'model000025.pt', 'opt000080.pt', 'ema_0.9999_000045.pt', 'model000000.pt', 'model000075.pt', 'opt000075.pt', 'opt000020.pt', 'model000065.pt', 'model000045.pt', 'ema_0.9999_000050.pt', 'opt000045.pt', 'model000085.pt', 'model000010.pt', 'ema_0.9999_000010.pt', 'ema_0.9999_000090.pt', 'model000050.pt', 'ema_0.9999_000060.pt', 'model000060.pt', 'opt000035.pt', 'opt000010.pt', 'opt000085.pt', 'opt000055.pt', 'opt000000.pt', 'model000055.pt', 'ema_0.9999_000020.pt', 'opt000065.pt', 'model000035.pt', 'model000015.pt', 'opt000070.pt', 'opt000050.pt', 'ema_0.9999_000070.pt', 'opt000005.pt', 'ema_0.9999_000080.pt', 'ema_0.9999_000075.pt', 'opt000015.pt', 'ema_0.9999_000025.pt', 'opt000060.pt', 'ema_0.9999_000000.pt']\n"
     ]
    }
   ],
   "source": [
    "opt_list = []\n",
    "ema_list = []\n",
    "model_list = []\n",
    "\n",
    "for cktroot, cktdirs, cktfiles in os.walk('/home/ec2-user/SageMaker/checkpoints'):\n",
    "    if len(cktfiles) > 0:\n",
    "        for cktfile in cktfiles:\n",
    "            flag = cktfile[:3]\n",
    "            if flag == 'opt':\n",
    "                opt_list.append(cktfile)\n",
    "            elif flag == 'mod':\n",
    "                model_list.append(cktfile)\n",
    "            elif flag == 'ema':\n",
    "                ema_list.append(cktfile)\n",
    "resume_checkpoint=cktroot + \"/\" + sorted(model_list)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['opt000040.pt',\n",
       " 'ema_0.9999_000085.pt',\n",
       " 'model000100.pt',\n",
       " 'ema_0.9999_000005.pt',\n",
       " 'model000090.pt',\n",
       " 'model000040.pt',\n",
       " 'ema_0.9999_000095.pt',\n",
       " 'opt000090.pt',\n",
       " 'opt000030.pt',\n",
       " 'opt000100.pt',\n",
       " 'model.pt',\n",
       " 'ema_0.9999_000040.pt',\n",
       " 'opt000025.pt',\n",
       " 'ema_0.9999_000035.pt',\n",
       " 'model000020.pt',\n",
       " 'model000005.pt',\n",
       " 'ema_0.9999_000015.pt',\n",
       " 'model000070.pt',\n",
       " 'ema_0.9999_000030.pt',\n",
       " 'model000095.pt',\n",
       " 'ema_0.9999_000065.pt',\n",
       " 'model000080.pt',\n",
       " 'model000030.pt',\n",
       " 'ema_0.9999_000100.pt',\n",
       " 'opt000095.pt',\n",
       " 'ema_0.9999_000055.pt',\n",
       " 'model000025.pt',\n",
       " 'opt000080.pt',\n",
       " 'ema_0.9999_000045.pt',\n",
       " 'model000000.pt',\n",
       " 'model000075.pt',\n",
       " 'opt000075.pt',\n",
       " 'opt000020.pt',\n",
       " 'model000065.pt',\n",
       " 'model000045.pt',\n",
       " 'ema_0.9999_000050.pt',\n",
       " 'opt000045.pt',\n",
       " 'model000085.pt',\n",
       " 'model000010.pt',\n",
       " 'ema_0.9999_000010.pt',\n",
       " 'ema_0.9999_000090.pt',\n",
       " 'model000050.pt',\n",
       " 'ema_0.9999_000060.pt',\n",
       " 'model000060.pt',\n",
       " 'opt000035.pt',\n",
       " 'opt000010.pt',\n",
       " 'opt000085.pt',\n",
       " 'opt000055.pt',\n",
       " 'opt000000.pt',\n",
       " 'model000055.pt',\n",
       " 'ema_0.9999_000020.pt',\n",
       " 'opt000065.pt',\n",
       " 'model000035.pt',\n",
       " 'model000015.pt',\n",
       " 'opt000070.pt',\n",
       " 'opt000050.pt',\n",
       " 'ema_0.9999_000070.pt',\n",
       " 'opt000005.pt',\n",
       " 'ema_0.9999_000080.pt',\n",
       " 'ema_0.9999_000075.pt',\n",
       " 'opt000015.pt',\n",
       " 'ema_0.9999_000025.pt',\n",
       " 'opt000060.pt',\n",
       " 'ema_0.9999_000000.pt']"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cktfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model000100.pt',\n",
       " 'model000090.pt',\n",
       " 'model000040.pt',\n",
       " 'model.pt',\n",
       " 'model000020.pt',\n",
       " 'model000005.pt',\n",
       " 'model000070.pt',\n",
       " 'model000095.pt',\n",
       " 'model000080.pt',\n",
       " 'model000030.pt',\n",
       " 'model000025.pt',\n",
       " 'model000000.pt',\n",
       " 'model000075.pt',\n",
       " 'model000065.pt',\n",
       " 'model000045.pt',\n",
       " 'model000085.pt',\n",
       " 'model000010.pt',\n",
       " 'model000050.pt',\n",
       " 'model000060.pt',\n",
       " 'model000055.pt',\n",
       " 'model000035.pt',\n",
       " 'model000015.pt']"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pt',\n",
       " 'model000000.pt',\n",
       " 'model000005.pt',\n",
       " 'model000010.pt',\n",
       " 'model000015.pt',\n",
       " 'model000020.pt',\n",
       " 'model000025.pt',\n",
       " 'model000030.pt',\n",
       " 'model000035.pt',\n",
       " 'model000040.pt',\n",
       " 'model000045.pt',\n",
       " 'model000050.pt',\n",
       " 'model000055.pt',\n",
       " 'model000060.pt',\n",
       " 'model000065.pt',\n",
       " 'model000070.pt',\n",
       " 'model000075.pt',\n",
       " 'model000080.pt',\n",
       " 'model000085.pt',\n",
       " 'model000090.pt',\n",
       " 'model000095.pt',\n",
       " 'model000100.pt']"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000000.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000005.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000010.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000015.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000020.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000025.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000030.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000035.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000040.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000045.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000050.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000055.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000060.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000065.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000070.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000075.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000080.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000085.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000090.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000095.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/ema_0.9999_000100.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000000.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000005.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000010.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000015.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000020.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000025.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000030.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000035.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000040.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000045.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000050.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000055.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000060.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000065.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000070.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000075.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000080.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000085.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000090.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000095.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/model000100.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000000.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000005.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000010.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000015.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000020.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000025.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000030.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000035.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000040.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000045.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000050.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000055.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000060.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000065.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000070.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000075.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000080.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000085.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000090.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000095.pt',\n",
       " '/home/ec2-user/SageMaker/checkpoints/opt000100.pt']"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ckt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= ['a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['PMI_RANK'] = \"1\"\n",
    "test['OMPI_COMM_WORLD_RANK'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "    for varname in [\"PMI_RANK\", \"OMPI_COMM_WORLD_RANK\"]:\n",
    "        if varname in test:\n",
    "            print(int(test[varname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-rank014\n"
     ]
    }
   ],
   "source": [
    "log_suffix = log_suffix + \"-rank%03i\" % rank\n",
    "print(log_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Amazon SageMaker Experiment Resources\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-cleanup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_boto3(experiment_name):\n",
    "    trials = sm.list_trials(ExperimentName=experiment_name)['TrialSummaries']\n",
    "    print('TrialNames:')\n",
    "    for trial in trials:\n",
    "        trial_name = trial['TrialName']\n",
    "        print(f\"\\n{trial_name}\")\n",
    "\n",
    "        components_in_trial = sm.list_trial_components(TrialName=trial_name)\n",
    "        print('\\tTrialComponentNames:')\n",
    "        for component in components_in_trial['TrialComponentSummaries']:\n",
    "            component_name = component['TrialComponentName']\n",
    "            print(f\"\\t{component_name}\")\n",
    "            sm.disassociate_trial_component(TrialComponentName=component_name, TrialName=trial_name)\n",
    "            try:\n",
    "                # comment out to keep trial components\n",
    "                sm.delete_trial_component(TrialComponentName=component_name)\n",
    "            except:\n",
    "                # component is associated with another trial\n",
    "                continue\n",
    "            # to prevent throttling\n",
    "            time.sleep(.5)\n",
    "        sm.delete_trial(TrialName=trial_name)\n",
    "    sm.delete_experiment(ExperimentName=experiment_name)\n",
    "    print(f\"\\nExperiment {experiment_name} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use experiment name not display name\n",
    "experiment_name = \"dalle-poc-exp4\"\n",
    "cleanup_boto3(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = '/home/ec2-user/SageMaker/lg-ai-research/dalle-sagemaker-dp-mp/test2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform1 = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.RandomResizedCrop(image_size,\n",
    "                        scale=(0.8, 1.),\n",
    "                        ratio=(1., 1.)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    array_img = io.imread(image_file)\n",
    "    image_tensor = image_transform1(array_img)\n",
    "except (PIL.UnidentifiedImageError, OSError, ValueError) as corrupt_image_exceptions:\n",
    "    print(f\"An exception occurred trying to load file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()\n",
    "plt.imshow(trans(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(image_file)\n",
    "rgb_im = im.convert('RGB')\n",
    "rgb_im.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = '/home/ec2-user/SageMaker/lg-ai-research/dalle-sagemaker-dp-mp/test.jpg'\n",
    "image_file = '/home/ec2-user/SageMaker/dataset/BIRDS/CUB_200_2011/images/029.American_Crow/American_Crow_0053_25203.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img = PIL.Image.open(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([\n",
    "    T.RandomResizedCrop(image_size,\n",
    "                        scale=(0.8, 1.),\n",
    "                        ratio=(1., 1.)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "#     piexif.remove(image_file)\n",
    "    array_img = PIL.Image.open(image_file)\n",
    "    array_img = array_img.convert('RGB')\n",
    "    \n",
    "    image_tensor = image_transform(array_img)\n",
    "except (PIL.UnidentifiedImageError, OSError, ValueError) as corrupt_image_exceptions:\n",
    "    print(f\"An exception occurred trying to load file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()\n",
    "plt.imshow(trans(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img.info.get(\"transparency\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if array_img.info.get(\"transparency\", None):\n",
    "    print(f\"[transparency] An exception occurred trying to load file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_img = PIL.Image.open(image_file)\n",
    "            img = self.img_convert(array_img)\n",
    "        except (PIL.UnidentifiedImageError, OSError) as corrupt_image_exceptions:\n",
    "            print(f\"An exception occurred trying to load file {image_file}.\")\n",
    "            print(f\"Skipping index {ind}\")\n",
    "            return self.skip_sample(ind)\n",
    "\n",
    "        try:\n",
    "            if img.info.get(\"transparency\", None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "entt = {\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":True,\"sagemaker_instance_type\":\"local_gpu\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-84g0b\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-84g0b\"],\"hyperparameters\":{\"batch_size\":1024,\"ema_rate\":\"0.9999\",\"fp16_scale_growth\":0.001,\"log_interval\":5,\"lr\":0.0001,\"lr_anneal_steps\":5000,\"microbatch\":16,\"sagemakerdp\":True,\"save_interval\":5,\"schedule_sampler\":\"uniform\",\"use_fp16\":False,\"weight_decay\":0.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":True,\"job_name\":\"diffusion-poc-exp1-test-1-sdp-d-1023-04051634961959\",\"log_level\":20,\"master_hostname\":\"algo-1-84g0b\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"image_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-84g0b\",\"hosts\":[\"algo-1-84g0b\"]},\"user_entry_point\":\"image_train.py\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_framework_parameters': {'sagemaker_distributed_dataparallel_custom_mpi_options': '',\n",
       "  'sagemaker_distributed_dataparallel_enabled': True,\n",
       "  'sagemaker_instance_type': 'local_gpu'},\n",
       " 'channel_input_dirs': {'training': '/opt/ml/input/data/training'},\n",
       " 'current_host': 'algo-1-84g0b',\n",
       " 'framework_module': 'sagemaker_pytorch_container.training:main',\n",
       " 'hosts': ['algo-1-84g0b'],\n",
       " 'hyperparameters': {'batch_size': 1024,\n",
       "  'ema_rate': '0.9999',\n",
       "  'fp16_scale_growth': 0.001,\n",
       "  'log_interval': 5,\n",
       "  'lr': 0.0001,\n",
       "  'lr_anneal_steps': 5000,\n",
       "  'microbatch': 16,\n",
       "  'sagemakerdp': True,\n",
       "  'save_interval': 5,\n",
       "  'schedule_sampler': 'uniform',\n",
       "  'use_fp16': False,\n",
       "  'weight_decay': 0.0},\n",
       " 'input_config_dir': '/opt/ml/input/config',\n",
       " 'input_data_config': {'training': {'TrainingInputMode': 'File'}},\n",
       " 'input_dir': '/opt/ml/input',\n",
       " 'is_master': True,\n",
       " 'job_name': 'diffusion-poc-exp1-test-1-sdp-d-1023-04051634961959',\n",
       " 'log_level': 20,\n",
       " 'master_hostname': 'algo-1-84g0b',\n",
       " 'model_dir': '/opt/ml/model',\n",
       " 'module_dir': '/opt/ml/code',\n",
       " 'module_name': 'image_train',\n",
       " 'network_interface_name': 'eth0',\n",
       " 'num_cpus': 64,\n",
       " 'num_gpus': 8,\n",
       " 'output_data_dir': '/opt/ml/output/data',\n",
       " 'output_dir': '/opt/ml/output',\n",
       " 'output_intermediate_dir': '/opt/ml/output/intermediate',\n",
       " 'resource_config': {'current_host': 'algo-1-84g0b',\n",
       "  'hosts': ['algo-1-84g0b']},\n",
       " 'user_entry_point': 'image_train.py'}"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diffusion-poc-exp1-test-1-sdp-d-1023-04051634961959'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entt['job_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function json.loads(s, *, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
